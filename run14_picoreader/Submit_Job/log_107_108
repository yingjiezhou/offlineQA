Tue Sep  5 01:47:28 PDT 2017
./submitAnaTreePDSF.sh mb 0 107
/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job
Tue Sep  5 01:47:28 PDT 2017
075
076
077
078
079
080
081
082
083
084
085
086
087
088
089
090
091
092
093
094
095
096
097
098
099
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
107
jobs = 6
day = 107 run = 15107005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107005/*.root.log: No such file or directory
210
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:48:12 PDT] Dataset size is 210 files
Removing files not on site LBL
[2017.09.05 01:48:12 PDT] Dataset size is 210 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:48:14 PDT] Dataset size is 210 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:48:14 PDT] Started with 210 files, current size is 210files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:48:14 PDT] Dataset size is 210 files
----------------------------------------------------
validating dataset ....passed
Writting process F19023A25053E64186A911FFE5D84C82_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F19023A25053E64186A911FFE5D84C82_2... done.
Writting process F19023A25053E64186A911FFE5D84C82_1... done.
Writting process F19023A25053E64186A911FFE5D84C82_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF19023A25053E64186A911FFE5D84C82.report
Scheduling successful
submit!!!
jobs = 10
day = 107 run = 15107006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107006/*.root.log: No such file or directory
208
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:49:32 PDT] Dataset size is 208 files
Removing files not on site LBL
[2017.09.05 01:49:33 PDT] Dataset size is 208 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:49:34 PDT] Dataset size is 208 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:49:36 PDT] Started with 208 files, current size is 208files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:49:37 PDT] Dataset size is 208 files
----------------------------------------------------
validating dataset ....passed
Writting process 49AD8298F5C4A0B3A3BF28FAA3D7C163_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 49AD8298F5C4A0B3A3BF28FAA3D7C163_2... done.
Writting process 49AD8298F5C4A0B3A3BF28FAA3D7C163_1... done.
Writting process 49AD8298F5C4A0B3A3BF28FAA3D7C163_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched49AD8298F5C4A0B3A3BF28FAA3D7C163.report
Scheduling successful
submit!!!
jobs = 14
day = 107 run = 15107008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107008/*.root.log: No such file or directory
226
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:50:52 PDT] Dataset size is 226 files
Removing files not on site LBL
[2017.09.05 01:50:53 PDT] Dataset size is 226 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:50:53 PDT] Dataset size is 226 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:50:53 PDT] Started with 226 files, current size is 226files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:50:53 PDT] Dataset size is 226 files
----------------------------------------------------
validating dataset ....passed
Writting process 61A33604B9252D5B1BFD1003FE6ACF52_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 61A33604B9252D5B1BFD1003FE6ACF52_2... done.
Writting process 61A33604B9252D5B1BFD1003FE6ACF52_1... done.
Writting process 61A33604B9252D5B1BFD1003FE6ACF52_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched61A33604B9252D5B1BFD1003FE6ACF52.report
Scheduling successful
submit!!!
jobs = 18
day = 107 run = 15107009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107009/*.root.log: No such file or directory
211
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:52:11 PDT] Dataset size is 211 files
Removing files not on site LBL
[2017.09.05 01:52:12 PDT] Dataset size is 211 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:52:12 PDT] Dataset size is 211 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:52:14 PDT] Started with 211 files, current size is 211files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:52:14 PDT] Dataset size is 211 files
----------------------------------------------------
validating dataset ....passed
Writting process 316811B8FB0BBCFC0B9EC6B9F39762BC_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 316811B8FB0BBCFC0B9EC6B9F39762BC_2... done.
Writting process 316811B8FB0BBCFC0B9EC6B9F39762BC_1... done.
Writting process 316811B8FB0BBCFC0B9EC6B9F39762BC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched316811B8FB0BBCFC0B9EC6B9F39762BC.report
Scheduling successful
submit!!!
jobs = 22
day = 107 run = 15107010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107010/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:53:31 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 01:53:33 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:53:33 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:53:37 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:53:37 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 0039168B696B4E717FFA6B846F153284_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0039168B696B4E717FFA6B846F153284_1... done.
Writting process 0039168B696B4E717FFA6B846F153284_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0039168B696B4E717FFA6B846F153284.report
Scheduling successful
submit!!!
jobs = 25
day = 107 run = 15107011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107011/*.root.log: No such file or directory
192
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:54:56 PDT] Dataset size is 192 files
Removing files not on site LBL
[2017.09.05 01:54:58 PDT] Dataset size is 192 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:54:59 PDT] Dataset size is 192 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:55:02 PDT] Started with 192 files, current size is 192files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:55:03 PDT] Dataset size is 192 files
----------------------------------------------------
validating dataset ....passed
Writting process F842D1171F6F3977B61F7267C1D0656A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F842D1171F6F3977B61F7267C1D0656A_1... done.
Writting process F842D1171F6F3977B61F7267C1D0656A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF842D1171F6F3977B61F7267C1D0656A.report
Scheduling successful
submit!!!
jobs = 28
day = 107 run = 15107013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107013/*.root.log: No such file or directory
142
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:56:17 PDT] Dataset size is 142 files
Removing files not on site LBL
[2017.09.05 01:56:18 PDT] Dataset size is 142 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:56:20 PDT] Dataset size is 142 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:56:20 PDT] Started with 142 files, current size is 142files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:56:20 PDT] Dataset size is 142 files
----------------------------------------------------
validating dataset ....passed
Writting process 7EFC6CB08F4E150C934D9054A5A2435A_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7EFC6CB08F4E150C934D9054A5A2435A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7EFC6CB08F4E150C934D9054A5A2435A.report
Scheduling successful
submit!!!
jobs = 30
day = 107 run = 15107014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107014/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:57:36 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 01:57:36 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:57:37 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:57:38 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:57:38 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process FC8A9DA8FF592BE5739D7D03DB27B298_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FC8A9DA8FF592BE5739D7D03DB27B298_1... done.
Writting process FC8A9DA8FF592BE5739D7D03DB27B298_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFC8A9DA8FF592BE5739D7D03DB27B298.report
Scheduling successful
submit!!!
jobs = 33
day = 107 run = 15107015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107015/*.root.log: No such file or directory
57
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 01:58:47 PDT] Dataset size is 57 files
Removing files not on site LBL
[2017.09.05 01:58:47 PDT] Dataset size is 57 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 01:58:47 PDT] Dataset size is 57 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 01:58:48 PDT] Started with 57 files, current size is 57files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 01:58:48 PDT] Dataset size is 57 files
----------------------------------------------------
validating dataset ....passed
Writting process 9F47EB123CD4A64422F36BD10DBA84B1_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9F47EB123CD4A64422F36BD10DBA84B1.report
Scheduling successful
submit!!!
jobs = 34
day = 107 run = 15107082
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107082/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107082/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:00:13 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 02:00:14 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:00:18 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:00:19 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:00:21 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 83FEF9F7BA50AB1EA87DD85CDF08A83A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 83FEF9F7BA50AB1EA87DD85CDF08A83A_1... done.
Writting process 83FEF9F7BA50AB1EA87DD85CDF08A83A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched83FEF9F7BA50AB1EA87DD85CDF08A83A.report
Scheduling successful
submit!!!
jobs = 35
day = 107 run = 15107083
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107083/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107083/*.root.log: No such file or directory
36
36 36
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:01:36 PDT] Dataset size is 36 files
Removing files not on site LBL
[2017.09.05 02:01:38 PDT] Dataset size is 36 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:01:39 PDT] Dataset size is 36 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:01:41 PDT] Started with 36 files, current size is 36files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=36 ,maxSize=36 )
[2017.09.05 02:01:42 PDT] Dataset size is 36 files
----------------------------------------------------
validating dataset ....passed
Writting process 4F4BF2434350C32FAFAB56284236E4C7_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4F4BF2434350C32FAFAB56284236E4C7.report
Scheduling successful
submit!!!
jobs = 36
day = 107 run = 15107084
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107084/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107084/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:02:59 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 02:03:00 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:03:00 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:03:00 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:03:01 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 90D1FA9D70489851358726629F561EFD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 90D1FA9D70489851358726629F561EFD_1... done.
Writting process 90D1FA9D70489851358726629F561EFD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched90D1FA9D70489851358726629F561EFD.report
Scheduling successful
submit!!!
jobs = 39
day = 107 run = 15107085
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107085/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107085/*.root.log: No such file or directory
197
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:04:37 PDT] Dataset size is 197 files
Removing files not on site LBL
[2017.09.05 02:04:37 PDT] Dataset size is 197 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:04:37 PDT] Dataset size is 197 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:04:39 PDT] Started with 197 files, current size is 197files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:04:39 PDT] Dataset size is 197 files
----------------------------------------------------
validating dataset ....passed
Writting process DFABEF391FEEAD6ACF5CCF0BD33574E2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DFABEF391FEEAD6ACF5CCF0BD33574E2_1... done.
Writting process DFABEF391FEEAD6ACF5CCF0BD33574E2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDFABEF391FEEAD6ACF5CCF0BD33574E2.report
Scheduling successful
submit!!!
jobs = 42
day = 107 run = 15107086
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107086/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107086/*.root.log: No such file or directory
221
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:06:00 PDT] Dataset size is 221 files
Removing files not on site LBL
[2017.09.05 02:06:00 PDT] Dataset size is 221 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:06:00 PDT] Dataset size is 221 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:06:00 PDT] Started with 221 files, current size is 221files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:06:01 PDT] Dataset size is 221 files
----------------------------------------------------
validating dataset ....passed
Writting process 5DA5E841CF7B7E9EB7380CD1BE57C707_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5DA5E841CF7B7E9EB7380CD1BE57C707_2... done.
Writting process 5DA5E841CF7B7E9EB7380CD1BE57C707_1... done.
Writting process 5DA5E841CF7B7E9EB7380CD1BE57C707_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5DA5E841CF7B7E9EB7380CD1BE57C707.report
Scheduling successful
submit!!!
jobs = 46
day = 107 run = 15107087
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107087/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107087/*.root.log: No such file or directory
235
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:07:28 PDT] Dataset size is 235 files
Removing files not on site LBL
[2017.09.05 02:07:28 PDT] Dataset size is 235 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:07:28 PDT] Dataset size is 235 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:07:29 PDT] Started with 235 files, current size is 235files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:07:29 PDT] Dataset size is 235 files
----------------------------------------------------
validating dataset ....passed
Writting process 6A0A182386F264BAC53B383FED8A1295_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6A0A182386F264BAC53B383FED8A1295_2... done.
Writting process 6A0A182386F264BAC53B383FED8A1295_1... done.
Writting process 6A0A182386F264BAC53B383FED8A1295_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6A0A182386F264BAC53B383FED8A1295.report
Scheduling successful
submit!!!
jobs = 49
day = 107 run = 15107088
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107088/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107088/*.root.log: No such file or directory
53
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:08:44 PDT] Dataset size is 53 files
Removing files not on site LBL
[2017.09.05 02:08:45 PDT] Dataset size is 53 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:08:45 PDT] Dataset size is 53 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:08:46 PDT] Started with 53 files, current size is 53files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:08:46 PDT] Dataset size is 53 files
----------------------------------------------------
validating dataset ....passed
Writting process 78E5BDDC2F4DDB3E970D82FACF166D12_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched78E5BDDC2F4DDB3E970D82FACF166D12.report
Scheduling successful
submit!!!
jobs = 49
day = 107 run = 15107089
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107089/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107089/*.root.log: No such file or directory
203
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:10:04 PDT] Dataset size is 203 files
Removing files not on site LBL
[2017.09.05 02:10:05 PDT] Dataset size is 203 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:10:07 PDT] Dataset size is 203 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:10:09 PDT] Started with 203 files, current size is 203files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:10:11 PDT] Dataset size is 203 files
----------------------------------------------------
validating dataset ....passed
Writting process 8D47C1E2522D7B4190D1B632D4D5732A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8D47C1E2522D7B4190D1B632D4D5732A_2... done.
Writting process 8D47C1E2522D7B4190D1B632D4D5732A_1... done.
Writting process 8D47C1E2522D7B4190D1B632D4D5732A_0... done.
Submitting array... done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8D47C1E2522D7B4190D1B632D4D5732A.report
Scheduling successful
submit!!!
jobs = 51
day = 107 run = 15107090
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15107090/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15107090/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:11:33 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.05 02:11:33 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:11:33 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:11:34 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:11:34 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process F1B7FC0CA171AF52544E10983BC34CF7_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F1B7FC0CA171AF52544E10983BC34CF7_2... done.
Writting process F1B7FC0CA171AF52544E10983BC34CF7_1... done.
Writting process F1B7FC0CA171AF52544E10983BC34CF7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF1B7FC0CA171AF52544E10983BC34CF7.report
Scheduling successful
submit!!!
Job submission for day 107 finished!
108
jobs = 54
day = 108 run = 15108001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108001/*.root.log: No such file or directory
222
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:12:54 PDT] Dataset size is 222 files
Removing files not on site LBL
[2017.09.05 02:12:54 PDT] Dataset size is 222 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:12:55 PDT] Dataset size is 222 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:12:55 PDT] Started with 222 files, current size is 222files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:12:55 PDT] Dataset size is 222 files
----------------------------------------------------
validating dataset ....passed
Writting process 7E35F4983FA77CE33067DBC91B34AD34_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7E35F4983FA77CE33067DBC91B34AD34_2... done.
Writting process 7E35F4983FA77CE33067DBC91B34AD34_1... done.
Writting process 7E35F4983FA77CE33067DBC91B34AD34_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7E35F4983FA77CE33067DBC91B34AD34.report
Scheduling successful
submit!!!
jobs = 57
day = 108 run = 15108011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108011/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:14:11 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 02:14:11 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:14:11 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:14:12 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:14:12 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 089FBC02DE04A44FBF51BE7F82D28541_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 089FBC02DE04A44FBF51BE7F82D28541_1... done.
Writting process 089FBC02DE04A44FBF51BE7F82D28541_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched089FBC02DE04A44FBF51BE7F82D28541.report
Scheduling successful
submit!!!
jobs = 57
day = 108 run = 15108012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108012/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:15:28 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 02:15:29 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:15:30 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:15:32 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:15:33 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 2F2ED2C603F46F1FC496BC2860FE5C91_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2F2ED2C603F46F1FC496BC2860FE5C91_1... done.
Writting process 2F2ED2C603F46F1FC496BC2860FE5C91_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2F2ED2C603F46F1FC496BC2860FE5C91.report
Scheduling successful
submit!!!
jobs = 59
day = 108 run = 15108013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108013/*.root.log: No such file or directory
210
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:16:53 PDT] Dataset size is 210 files
Removing files not on site LBL
[2017.09.05 02:16:53 PDT] Dataset size is 210 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:16:53 PDT] Dataset size is 210 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:16:53 PDT] Started with 210 files, current size is 210files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:16:53 PDT] Dataset size is 210 files
----------------------------------------------------
validating dataset ....passed
Writting process E23306238A0368F11A75D73283358900_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E23306238A0368F11A75D73283358900_2... done.
Writting process E23306238A0368F11A75D73283358900_1... done.
Writting process E23306238A0368F11A75D73283358900_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE23306238A0368F11A75D73283358900.report
Scheduling successful
submit!!!
jobs = 63
day = 108 run = 15108014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108014/*.root.log: No such file or directory
215
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:18:10 PDT] Dataset size is 215 files
Removing files not on site LBL
[2017.09.05 02:18:10 PDT] Dataset size is 215 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:18:10 PDT] Dataset size is 215 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:18:11 PDT] Started with 215 files, current size is 215files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:18:12 PDT] Dataset size is 215 files
----------------------------------------------------
validating dataset ....passed
Writting process 589923DC8284D340A919E25C312DA26E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 589923DC8284D340A919E25C312DA26E_2... done.
Writting process 589923DC8284D340A919E25C312DA26E_1... done.
Writting process 589923DC8284D340A919E25C312DA26E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched589923DC8284D340A919E25C312DA26E.report
Scheduling successful
submit!!!
jobs = 67
day = 108 run = 15108015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108015/*.root.log: No such file or directory
209
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:19:33 PDT] Dataset size is 209 files
Removing files not on site LBL
[2017.09.05 02:19:34 PDT] Dataset size is 209 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:19:35 PDT] Dataset size is 209 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:19:37 PDT] Started with 209 files, current size is 209files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:19:37 PDT] Dataset size is 209 files
----------------------------------------------------
validating dataset ....passed
Writting process C937A5A4F9C60967C760573EE6620A1C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C937A5A4F9C60967C760573EE6620A1C_2... done.
Writting process C937A5A4F9C60967C760573EE6620A1C_1... done.
Writting process C937A5A4F9C60967C760573EE6620A1C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC937A5A4F9C60967C760573EE6620A1C.report
Scheduling successful
submit!!!
jobs = 71
day = 108 run = 15108016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108016/*.root.log: No such file or directory
226
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:20:54 PDT] Dataset size is 226 files
Removing files not on site LBL
[2017.09.05 02:20:54 PDT] Dataset size is 226 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:20:54 PDT] Dataset size is 226 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:20:54 PDT] Started with 226 files, current size is 226files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:20:54 PDT] Dataset size is 226 files
----------------------------------------------------
validating dataset ....passed
Writting process 70B7E7527626F839A6BEB1F2FE513406_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 70B7E7527626F839A6BEB1F2FE513406_2... done.
Writting process 70B7E7527626F839A6BEB1F2FE513406_1... done.
Writting process 70B7E7527626F839A6BEB1F2FE513406_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched70B7E7527626F839A6BEB1F2FE513406.report
Scheduling successful
submit!!!
jobs = 75
day = 108 run = 15108017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108017/*.root.log: No such file or directory
73
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:22:06 PDT] Dataset size is 73 files
Removing files not on site LBL
[2017.09.05 02:22:06 PDT] Dataset size is 73 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:22:06 PDT] Dataset size is 73 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:22:06 PDT] Started with 73 files, current size is 73files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:22:06 PDT] Dataset size is 73 files
----------------------------------------------------
validating dataset ....passed
Writting process BBC131CBE3B02C31C11E71907E1BB394_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBBC131CBE3B02C31C11E71907E1BB394.report
Scheduling successful
submit!!!
jobs = 76
day = 108 run = 15108018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108018/*.root.log: No such file or directory
2
2 2
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:23:18 PDT] Dataset size is 2 files
Removing files not on site LBL
[2017.09.05 02:23:20 PDT] Dataset size is 2 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:23:20 PDT] Dataset size is 2 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:23:20 PDT] Started with 2 files, current size is 2files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=2 ,maxSize=2 )
[2017.09.05 02:23:20 PDT] Dataset size is 2 files
----------------------------------------------------
validating dataset ....passed
Writting process FA5090191F5A77DD107840CBAAA60214_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFA5090191F5A77DD107840CBAAA60214.report
Scheduling successful
submit!!!
jobs = 76
day = 108 run = 15108019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108019/*.root.log: No such file or directory
2
2 2
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:24:34 PDT] Dataset size is 2 files
Removing files not on site LBL
[2017.09.05 02:24:36 PDT] Dataset size is 2 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:24:36 PDT] Dataset size is 2 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:24:36 PDT] Started with 2 files, current size is 2files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=2 ,maxSize=2 )
[2017.09.05 02:24:36 PDT] Dataset size is 2 files
----------------------------------------------------
validating dataset ....passed
Writting process 0DC5E97BBC27E2CAB78BBF8304A9D427_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0DC5E97BBC27E2CAB78BBF8304A9D427.report
Scheduling successful
submit!!!
jobs = 74
day = 108 run = 15108022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108022/*.root.log: No such file or directory
214
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:25:52 PDT] Dataset size is 214 files
Removing files not on site LBL
[2017.09.05 02:25:52 PDT] Dataset size is 214 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:25:52 PDT] Dataset size is 214 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:25:52 PDT] Started with 214 files, current size is 214files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:25:52 PDT] Dataset size is 214 files
----------------------------------------------------
validating dataset ....passed
Writting process FAC688E6B3FF8F8C205A993BA7BAAC53_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FAC688E6B3FF8F8C205A993BA7BAAC53_2... done.
Writting process FAC688E6B3FF8F8C205A993BA7BAAC53_1... done.
Writting process FAC688E6B3FF8F8C205A993BA7BAAC53_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFAC688E6B3FF8F8C205A993BA7BAAC53.report
Scheduling successful
submit!!!
jobs = 77
day = 108 run = 15108023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108023/*.root.log: No such file or directory
221
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:27:08 PDT] Dataset size is 221 files
Removing files not on site LBL
[2017.09.05 02:27:10 PDT] Dataset size is 221 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:27:12 PDT] Dataset size is 221 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:27:15 PDT] Started with 221 files, current size is 221files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:27:16 PDT] Dataset size is 221 files
----------------------------------------------------
validating dataset ....passed
Writting process 08EC53D62111AA67B7D532DE27A35C2F_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 08EC53D62111AA67B7D532DE27A35C2F_2... done.
Writting process 08EC53D62111AA67B7D532DE27A35C2F_1... done.
Writting process 08EC53D62111AA67B7D532DE27A35C2F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched08EC53D62111AA67B7D532DE27A35C2F.report
Scheduling successful
submit!!!
jobs = 79
day = 108 run = 15108024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108024/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:28:32 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 02:28:34 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:28:35 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:28:37 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:28:38 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process C3BECA360F845BC69DA42A1F6754DD0E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C3BECA360F845BC69DA42A1F6754DD0E_1... done.
Writting process C3BECA360F845BC69DA42A1F6754DD0E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC3BECA360F845BC69DA42A1F6754DD0E.report
Scheduling successful
submit!!!
jobs = 81
day = 108 run = 15108025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108025/*.root.log: No such file or directory
137
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:29:52 PDT] Dataset size is 137 files
Removing files not on site LBL
[2017.09.05 02:29:52 PDT] Dataset size is 137 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:29:52 PDT] Dataset size is 137 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:29:53 PDT] Started with 137 files, current size is 137files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:29:53 PDT] Dataset size is 137 files
----------------------------------------------------
validating dataset ....passed
Writting process 1E912481E6101E0D99C268F1D1D06512_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1E912481E6101E0D99C268F1D1D06512_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1E912481E6101E0D99C268F1D1D06512.report
Scheduling successful
submit!!!
jobs = 83
day = 108 run = 15108027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108027/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:31:09 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 02:31:10 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:31:10 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:31:10 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:31:10 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process 1CB490A330182B84B5B067F6A4BAA26F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1CB490A330182B84B5B067F6A4BAA26F_1... done.
Writting process 1CB490A330182B84B5B067F6A4BAA26F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1CB490A330182B84B5B067F6A4BAA26F.report
Scheduling successful
submit!!!
jobs = 85
day = 108 run = 15108028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108028/*.root.log: No such file or directory
61
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:32:27 PDT] Dataset size is 61 files
Removing files not on site LBL
[2017.09.05 02:32:28 PDT] Dataset size is 61 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:32:29 PDT] Dataset size is 61 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:32:31 PDT] Started with 61 files, current size is 61files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:32:32 PDT] Dataset size is 61 files
----------------------------------------------------
validating dataset ....passed
Writting process 739491D676FC1E664CE7450665AB1DE3_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched739491D676FC1E664CE7450665AB1DE3.report
Scheduling successful
submit!!!
jobs = 84
day = 108 run = 15108078
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108078/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108078/*.root.log: No such file or directory
126
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:33:47 PDT] Dataset size is 126 files
Removing files not on site LBL
[2017.09.05 02:33:47 PDT] Dataset size is 126 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:33:47 PDT] Dataset size is 126 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:33:49 PDT] Started with 126 files, current size is 126files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:33:49 PDT] Dataset size is 126 files
----------------------------------------------------
validating dataset ....passed
Writting process 84901F474FDB7F973292BC1165A3B07C_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 84901F474FDB7F973292BC1165A3B07C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched84901F474FDB7F973292BC1165A3B07C.report
Scheduling successful
submit!!!
jobs = 84
day = 108 run = 15108079
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108079/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108079/*.root.log: No such file or directory
54
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:35:05 PDT] Dataset size is 54 files
Removing files not on site LBL
[2017.09.05 02:35:06 PDT] Dataset size is 54 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:35:08 PDT] Dataset size is 54 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:35:09 PDT] Started with 54 files, current size is 54files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:35:09 PDT] Dataset size is 54 files
----------------------------------------------------
validating dataset ....passed
Writting process F3F050C442CCF1A197AC165F3DB6FAFA_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF3F050C442CCF1A197AC165F3DB6FAFA.report
Scheduling successful
submit!!!
jobs = 81
day = 108 run = 15108080
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15108080/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15108080/*.root.log: No such file or directory
194
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:36:25 PDT] Dataset size is 194 files
Removing files not on site LBL
[2017.09.05 02:36:27 PDT] Dataset size is 194 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:36:27 PDT] Dataset size is 194 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:36:28 PDT] Started with 194 files, current size is 194files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:36:28 PDT] Dataset size is 194 files
----------------------------------------------------
validating dataset ....passed
Writting process 69DB4AE505C3DE60A995BAF6C842098C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 69DB4AE505C3DE60A995BAF6C842098C_1... done.
Writting process 69DB4AE505C3DE60A995BAF6C842098C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched69DB4AE505C3DE60A995BAF6C842098C.report
Scheduling successful
submit!!!
Job submission for day 108 finished!
109
jobs = 81
day = 109 run = 15109001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109001/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:37:43 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.05 02:37:44 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:37:44 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:37:46 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:37:46 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process 85726BA94E0CBE981D82973B286BB600_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 85726BA94E0CBE981D82973B286BB600_2... done.
Writting process 85726BA94E0CBE981D82973B286BB600_1... done.
Writting process 85726BA94E0CBE981D82973B286BB600_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched85726BA94E0CBE981D82973B286BB600.report
Scheduling successful
submit!!!
jobs = 83
day = 109 run = 15109002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109002/*.root.log: No such file or directory
163
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:38:58 PDT] Dataset size is 163 files
Removing files not on site LBL
[2017.09.05 02:38:58 PDT] Dataset size is 163 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:38:59 PDT] Dataset size is 163 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:38:59 PDT] Started with 163 files, current size is 163files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:38:59 PDT] Dataset size is 163 files
----------------------------------------------------
validating dataset ....passed
Writting process 392D1E91DC7A116B48711FB6B499B9B8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 392D1E91DC7A116B48711FB6B499B9B8_1... done.
Writting process 392D1E91DC7A116B48711FB6B499B9B8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched392D1E91DC7A116B48711FB6B499B9B8.report
Scheduling successful
submit!!!
jobs = 85
day = 109 run = 15109006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109006/*.root.log: No such file or directory
210
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:40:16 PDT] Dataset size is 210 files
Removing files not on site LBL
[2017.09.05 02:40:16 PDT] Dataset size is 210 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:40:16 PDT] Dataset size is 210 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:40:17 PDT] Started with 210 files, current size is 210files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:40:18 PDT] Dataset size is 210 files
----------------------------------------------------
validating dataset ....passed
Writting process 3003428900D3C76D9832DEB662505A39_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3003428900D3C76D9832DEB662505A39_2... done.
Writting process 3003428900D3C76D9832DEB662505A39_1... done.
Writting process 3003428900D3C76D9832DEB662505A39_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3003428900D3C76D9832DEB662505A39.report
Scheduling successful
submit!!!
jobs = 87
day = 109 run = 15109007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109007/*.root.log: No such file or directory
220
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:41:34 PDT] Dataset size is 220 files
Removing files not on site LBL
[2017.09.05 02:41:35 PDT] Dataset size is 220 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:41:36 PDT] Dataset size is 220 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:41:37 PDT] Started with 220 files, current size is 220files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:41:38 PDT] Dataset size is 220 files
----------------------------------------------------
validating dataset ....passed
Writting process 43A22FF7CE816A0BD2A1E32D63D3F30A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 43A22FF7CE816A0BD2A1E32D63D3F30A_2... done.
Writting process 43A22FF7CE816A0BD2A1E32D63D3F30A_1... done.
Writting process 43A22FF7CE816A0BD2A1E32D63D3F30A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched43A22FF7CE816A0BD2A1E32D63D3F30A.report
Scheduling successful
submit!!!
jobs = 89
day = 109 run = 15109008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109008/*.root.log: No such file or directory
212
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:43:00 PDT] Dataset size is 212 files
Removing files not on site LBL
[2017.09.05 02:43:01 PDT] Dataset size is 212 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:43:02 PDT] Dataset size is 212 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:43:02 PDT] Started with 212 files, current size is 212files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:43:02 PDT] Dataset size is 212 files
----------------------------------------------------
validating dataset ....passed
Writting process 1B405F7058794D688E3F8D4C3C5A583D_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1B405F7058794D688E3F8D4C3C5A583D_2... done.
Writting process 1B405F7058794D688E3F8D4C3C5A583D_1... done.
Writting process 1B405F7058794D688E3F8D4C3C5A583D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1B405F7058794D688E3F8D4C3C5A583D.report
Scheduling successful
submit!!!
jobs = 90
day = 109 run = 15109009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109009/*.root.log: No such file or directory
229
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:44:19 PDT] Dataset size is 229 files
Removing files not on site LBL
[2017.09.05 02:44:21 PDT] Dataset size is 229 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:44:23 PDT] Dataset size is 229 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:44:25 PDT] Started with 229 files, current size is 229files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:44:25 PDT] Dataset size is 229 files
----------------------------------------------------
validating dataset ....passed
Writting process EEB0F0CB325AF8F6D34BF093C83C4F07_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EEB0F0CB325AF8F6D34BF093C83C4F07_2... done.
Writting process EEB0F0CB325AF8F6D34BF093C83C4F07_1... done.
Writting process EEB0F0CB325AF8F6D34BF093C83C4F07_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEEB0F0CB325AF8F6D34BF093C83C4F07.report
Scheduling successful
submit!!!
jobs = 89
day = 109 run = 15109010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109010/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:45:44 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 02:45:45 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:45:49 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:45:50 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:45:50 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process 6D77D37798BA5D97B283B3F30E63E7B7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6D77D37798BA5D97B283B3F30E63E7B7_1... done.
Writting process 6D77D37798BA5D97B283B3F30E63E7B7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6D77D37798BA5D97B283B3F30E63E7B7.report
Scheduling successful
submit!!!
jobs = 87
day = 109 run = 15109011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109011/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:47:10 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 02:47:10 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:47:11 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:47:12 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:47:13 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process 6798D8FD51466F035579AF44D63B2715_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6798D8FD51466F035579AF44D63B2715_1... done.
Writting process 6798D8FD51466F035579AF44D63B2715_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6798D8FD51466F035579AF44D63B2715.report
Scheduling successful
submit!!!
jobs = 85
day = 109 run = 15109012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109012/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:48:36 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 02:48:37 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:48:41 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:48:42 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:48:42 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 48815707A67AE3391B2F2DAFFC909CB4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 48815707A67AE3391B2F2DAFFC909CB4_1... done.
Writting process 48815707A67AE3391B2F2DAFFC909CB4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched48815707A67AE3391B2F2DAFFC909CB4.report
Scheduling successful
submit!!!
jobs = 84
day = 109 run = 15109013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109013/*.root.log: No such file or directory
157
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:49:57 PDT] Dataset size is 157 files
Removing files not on site LBL
[2017.09.05 02:49:58 PDT] Dataset size is 157 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:49:58 PDT] Dataset size is 157 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:50:00 PDT] Started with 157 files, current size is 157files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:50:01 PDT] Dataset size is 157 files
----------------------------------------------------
validating dataset ....passed
Writting process BB388B6298522AC4712DE6F37EB29AF4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BB388B6298522AC4712DE6F37EB29AF4_1... done.
Writting process BB388B6298522AC4712DE6F37EB29AF4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBB388B6298522AC4712DE6F37EB29AF4.report
Scheduling successful
submit!!!
jobs = 85
day = 109 run = 15109031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109031/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:51:23 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 02:51:24 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:51:25 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:51:27 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:51:29 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 840A6F55288C808205E5881C349339DD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 840A6F55288C808205E5881C349339DD_1... done.
Writting process 840A6F55288C808205E5881C349339DD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched840A6F55288C808205E5881C349339DD.report
Scheduling successful
submit!!!
jobs = 87
day = 109 run = 15109032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109032/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:53:06 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 02:53:06 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:53:07 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:53:07 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:53:07 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process 72F4C5AD7C4B2EF8FEC21BB5A8CBC5D8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 72F4C5AD7C4B2EF8FEC21BB5A8CBC5D8_1... done.
Writting process 72F4C5AD7C4B2EF8FEC21BB5A8CBC5D8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched72F4C5AD7C4B2EF8FEC21BB5A8CBC5D8.report
Scheduling successful
submit!!!
jobs = 81
day = 109 run = 15109035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109035/*.root.log: No such file or directory
160
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:54:23 PDT] Dataset size is 160 files
Removing files not on site LBL
[2017.09.05 02:54:23 PDT] Dataset size is 160 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:54:23 PDT] Dataset size is 160 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:54:24 PDT] Started with 160 files, current size is 160files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:54:24 PDT] Dataset size is 160 files
----------------------------------------------------
validating dataset ....passed
Writting process F57DA75B6C65FFFA44622675EF9FACAE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F57DA75B6C65FFFA44622675EF9FACAE_1... done.
Writting process F57DA75B6C65FFFA44622675EF9FACAE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF57DA75B6C65FFFA44622675EF9FACAE.report
Scheduling successful
submit!!!
jobs = 80
day = 109 run = 15109036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109036/*.root.log: No such file or directory
51
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:55:34 PDT] Dataset size is 51 files
Removing files not on site LBL
[2017.09.05 02:55:34 PDT] Dataset size is 51 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:55:35 PDT] Dataset size is 51 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:55:36 PDT] Started with 51 files, current size is 51files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:55:36 PDT] Dataset size is 51 files
----------------------------------------------------
validating dataset ....passed
Writting process 44E810B0D64DD270CBFF8692ED10B060_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched44E810B0D64DD270CBFF8692ED10B060.report
Scheduling successful
submit!!!
jobs = 78
day = 109 run = 15109037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109037/*.root.log: No such file or directory
89
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:56:57 PDT] Dataset size is 89 files
Removing files not on site LBL
[2017.09.05 02:56:57 PDT] Dataset size is 89 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:56:57 PDT] Dataset size is 89 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:56:58 PDT] Started with 89 files, current size is 89files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:56:58 PDT] Dataset size is 89 files
----------------------------------------------------
validating dataset ....passed
Writting process B9C813009891D1EAE6174BE39926D964_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB9C813009891D1EAE6174BE39926D964.report
Scheduling successful
submit!!!
jobs = 78
day = 109 run = 15109038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109038/*.root.log: No such file or directory
142
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:58:12 PDT] Dataset size is 142 files
Removing files not on site LBL
[2017.09.05 02:58:12 PDT] Dataset size is 142 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:58:12 PDT] Dataset size is 142 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:58:12 PDT] Started with 142 files, current size is 142files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:58:12 PDT] Dataset size is 142 files
----------------------------------------------------
validating dataset ....passed
Writting process BCF80B168BC35E5F5BD2DB0BE79E3EAE_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BCF80B168BC35E5F5BD2DB0BE79E3EAE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBCF80B168BC35E5F5BD2DB0BE79E3EAE.report
Scheduling successful
submit!!!
jobs = 78
day = 109 run = 15109039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109039/*.root.log: No such file or directory
155
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 02:59:26 PDT] Dataset size is 155 files
Removing files not on site LBL
[2017.09.05 02:59:26 PDT] Dataset size is 155 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 02:59:26 PDT] Dataset size is 155 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 02:59:27 PDT] Started with 155 files, current size is 155files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 02:59:28 PDT] Dataset size is 155 files
----------------------------------------------------
validating dataset ....passed
Writting process 98ADAC96E9F3C3AE54AE34EE761C670A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 98ADAC96E9F3C3AE54AE34EE761C670A_1... done.
Writting process 98ADAC96E9F3C3AE54AE34EE761C670A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched98ADAC96E9F3C3AE54AE34EE761C670A.report
Scheduling successful
submit!!!
jobs = 76
day = 109 run = 15109040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109040/*.root.log: No such file or directory
11
11 11
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:00:39 PDT] Dataset size is 11 files
Removing files not on site LBL
[2017.09.05 03:00:39 PDT] Dataset size is 11 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:00:39 PDT] Dataset size is 11 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:00:39 PDT] Started with 11 files, current size is 11files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=11 ,maxSize=11 )
[2017.09.05 03:00:39 PDT] Dataset size is 11 files
----------------------------------------------------
validating dataset ....passed
Writting process 08C99C3AAD52C78CF2A0C9FDF4961E16_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched08C99C3AAD52C78CF2A0C9FDF4961E16.report
Scheduling successful
submit!!!
jobs = 74
day = 109 run = 15109041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109041/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:01:58 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 03:01:59 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:02:00 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:02:01 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:02:01 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 68C2326A530FAD534697B28D7CA47330_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 68C2326A530FAD534697B28D7CA47330_1... done.
Writting process 68C2326A530FAD534697B28D7CA47330_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched68C2326A530FAD534697B28D7CA47330.report
Scheduling successful
submit!!!
jobs = 74
day = 109 run = 15109042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109042/*.root.log: No such file or directory
37
37 37
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:03:12 PDT] Dataset size is 37 files
Removing files not on site LBL
[2017.09.05 03:03:12 PDT] Dataset size is 37 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:03:12 PDT] Dataset size is 37 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:03:12 PDT] Started with 37 files, current size is 37files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=37 ,maxSize=37 )
[2017.09.05 03:03:12 PDT] Dataset size is 37 files
----------------------------------------------------
validating dataset ....passed
Writting process 0FDA3AE4BDE4B093012DC7CA425E9927_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0FDA3AE4BDE4B093012DC7CA425E9927.report
Scheduling successful
submit!!!
jobs = 72
day = 109 run = 15109043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109043/*.root.log: No such file or directory
121
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:04:30 PDT] Dataset size is 121 files
Removing files not on site LBL
[2017.09.05 03:04:30 PDT] Dataset size is 121 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:04:30 PDT] Dataset size is 121 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:04:30 PDT] Started with 121 files, current size is 121files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:04:30 PDT] Dataset size is 121 files
----------------------------------------------------
validating dataset ....passed
Writting process CAC4E39CEEB226F532483B7FA93CC440_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CAC4E39CEEB226F532483B7FA93CC440_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCAC4E39CEEB226F532483B7FA93CC440.report
Scheduling successful
submit!!!
jobs = 69
day = 109 run = 15109045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109045/*.root.log: No such file or directory
52
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:05:44 PDT] Dataset size is 52 files
Removing files not on site LBL
[2017.09.05 03:05:45 PDT] Dataset size is 52 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:05:45 PDT] Dataset size is 52 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:05:45 PDT] Started with 52 files, current size is 52files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:05:45 PDT] Dataset size is 52 files
----------------------------------------------------
validating dataset ....passed
Writting process 76FFCBA0E816AE6AA8F7BA28786DDB7F_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched76FFCBA0E816AE6AA8F7BA28786DDB7F.report
Scheduling successful
submit!!!
jobs = 67
day = 109 run = 15109046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109046/*.root.log: No such file or directory
149
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:07:00 PDT] Dataset size is 149 files
Removing files not on site LBL
[2017.09.05 03:07:00 PDT] Dataset size is 149 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:07:00 PDT] Dataset size is 149 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:07:00 PDT] Started with 149 files, current size is 149files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:07:00 PDT] Dataset size is 149 files
----------------------------------------------------
validating dataset ....passed
Writting process 6358532E2E33E7FC5A1D0C1AE6296865_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6358532E2E33E7FC5A1D0C1AE6296865_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6358532E2E33E7FC5A1D0C1AE6296865.report
Scheduling successful
submit!!!
jobs = 66
day = 109 run = 15109061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109061/*.root.log: No such file or directory
68
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:08:12 PDT] Dataset size is 68 files
Removing files not on site LBL
[2017.09.05 03:08:13 PDT] Dataset size is 68 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:08:14 PDT] Dataset size is 68 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:08:16 PDT] Started with 68 files, current size is 68files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:08:17 PDT] Dataset size is 68 files
----------------------------------------------------
validating dataset ....passed
Writting process 024E48E0EA1AD337DAB336FFD774081F_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched024E48E0EA1AD337DAB336FFD774081F.report
Scheduling successful
submit!!!
jobs = 66
day = 109 run = 15109062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109062/*.root.log: No such file or directory
76
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:09:32 PDT] Dataset size is 76 files
Removing files not on site LBL
[2017.09.05 03:09:33 PDT] Dataset size is 76 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:09:34 PDT] Dataset size is 76 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:09:35 PDT] Started with 76 files, current size is 76files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:09:35 PDT] Dataset size is 76 files
----------------------------------------------------
validating dataset ....passed
Writting process 3B755BF1BA865D6AFDF9F5D8B93EA819_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3B755BF1BA865D6AFDF9F5D8B93EA819.report
Scheduling successful
submit!!!
jobs = 67
day = 109 run = 15109063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109063/*.root.log: No such file or directory
53
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:10:48 PDT] Dataset size is 53 files
Removing files not on site LBL
[2017.09.05 03:10:49 PDT] Dataset size is 53 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:10:49 PDT] Dataset size is 53 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:10:49 PDT] Started with 53 files, current size is 53files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:10:49 PDT] Dataset size is 53 files
----------------------------------------------------
validating dataset ....passed
Writting process 215396EDCF081B6D2BB589793B7F5095_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched215396EDCF081B6D2BB589793B7F5095.report
Scheduling successful
submit!!!
jobs = 66
day = 109 run = 15109065
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15109065/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15109065/*.root.log: No such file or directory
57
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:12:03 PDT] Dataset size is 57 files
Removing files not on site LBL
[2017.09.05 03:12:04 PDT] Dataset size is 57 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:12:04 PDT] Dataset size is 57 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:12:04 PDT] Started with 57 files, current size is 57files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:12:04 PDT] Dataset size is 57 files
----------------------------------------------------
validating dataset ....passed
Writting process 5D3222E91DDC44699CE55DA54F1B36A5_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5D3222E91DDC44699CE55DA54F1B36A5.report
Scheduling successful
submit!!!
Job submission for day 109 finished!
110
jobs = 64
day = 110 run = 15110001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110001/*.root.log: No such file or directory
74
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:13:17 PDT] Dataset size is 74 files
Removing files not on site LBL
[2017.09.05 03:13:18 PDT] Dataset size is 74 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:13:18 PDT] Dataset size is 74 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:13:18 PDT] Started with 74 files, current size is 74files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:13:19 PDT] Dataset size is 74 files
----------------------------------------------------
validating dataset ....passed
Writting process 9E60867FF74E22636FCDD424FF190AFE_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9E60867FF74E22636FCDD424FF190AFE.report
Scheduling successful
submit!!!
jobs = 64
day = 110 run = 15110002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110002/*.root.log: No such file or directory
78
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:14:30 PDT] Dataset size is 78 files
Removing files not on site LBL
[2017.09.05 03:14:30 PDT] Dataset size is 78 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:14:30 PDT] Dataset size is 78 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:14:30 PDT] Started with 78 files, current size is 78files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:14:30 PDT] Dataset size is 78 files
----------------------------------------------------
validating dataset ....passed
Writting process 2F5B387EBED2C77C311433C3A10AD1B6_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2F5B387EBED2C77C311433C3A10AD1B6.report
Scheduling successful
submit!!!
jobs = 62
day = 110 run = 15110003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110003/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:15:47 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 03:15:47 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:15:47 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:15:48 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:15:49 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process 11C0BE738D60F7AEBBA18F19906DD9F8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 11C0BE738D60F7AEBBA18F19906DD9F8_1... done.
Writting process 11C0BE738D60F7AEBBA18F19906DD9F8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched11C0BE738D60F7AEBBA18F19906DD9F8.report
Scheduling successful
submit!!!
jobs = 61
day = 110 run = 15110004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110004/*.root.log: No such file or directory
198
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:17:06 PDT] Dataset size is 198 files
Removing files not on site LBL
[2017.09.05 03:17:07 PDT] Dataset size is 198 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:17:07 PDT] Dataset size is 198 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:17:10 PDT] Started with 198 files, current size is 198files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:17:10 PDT] Dataset size is 198 files
----------------------------------------------------
validating dataset ....passed
Writting process CD238E8D30C26F90BE56C8F755A14179_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CD238E8D30C26F90BE56C8F755A14179_1... done.
Writting process CD238E8D30C26F90BE56C8F755A14179_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCD238E8D30C26F90BE56C8F755A14179.report
Scheduling successful
submit!!!
jobs = 59
day = 110 run = 15110005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110005/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:18:24 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 03:18:24 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:18:24 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:18:25 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:18:25 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process 26C9CBEC3AC34DECC57BEA7A031BDCD6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 26C9CBEC3AC34DECC57BEA7A031BDCD6_1... done.
Writting process 26C9CBEC3AC34DECC57BEA7A031BDCD6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched26C9CBEC3AC34DECC57BEA7A031BDCD6.report
Scheduling successful
submit!!!
jobs = 58
day = 110 run = 15110008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110008/*.root.log: No such file or directory
207
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:19:43 PDT] Dataset size is 207 files
Removing files not on site LBL
[2017.09.05 03:19:44 PDT] Dataset size is 207 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:19:46 PDT] Dataset size is 207 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:19:48 PDT] Started with 207 files, current size is 207files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:19:49 PDT] Dataset size is 207 files
----------------------------------------------------
validating dataset ....passed
Writting process 5EDD2C3D55E77FED2915BB7DED7086FA_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5EDD2C3D55E77FED2915BB7DED7086FA_2... done.
Writting process 5EDD2C3D55E77FED2915BB7DED7086FA_1... done.
Writting process 5EDD2C3D55E77FED2915BB7DED7086FA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5EDD2C3D55E77FED2915BB7DED7086FA.report
Scheduling successful
submit!!!
jobs = 56
day = 110 run = 15110009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110009/*.root.log: No such file or directory
215
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:21:04 PDT] Dataset size is 215 files
Removing files not on site LBL
[2017.09.05 03:21:04 PDT] Dataset size is 215 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:21:04 PDT] Dataset size is 215 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:21:04 PDT] Started with 215 files, current size is 215files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:21:04 PDT] Dataset size is 215 files
----------------------------------------------------
validating dataset ....passed
Writting process 78BE3A6B0AAF6EAF27F579A89E907011_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 78BE3A6B0AAF6EAF27F579A89E907011_2... done.
Writting process 78BE3A6B0AAF6EAF27F579A89E907011_1... done.
Writting process 78BE3A6B0AAF6EAF27F579A89E907011_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched78BE3A6B0AAF6EAF27F579A89E907011.report
Scheduling successful
submit!!!
jobs = 57
day = 110 run = 15110010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110010/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:22:18 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.05 03:22:18 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:22:18 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:22:18 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:22:18 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 6BD183B91D4BF74E1826EA1D0DFFE703_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6BD183B91D4BF74E1826EA1D0DFFE703_2... done.
Writting process 6BD183B91D4BF74E1826EA1D0DFFE703_1... done.
Writting process 6BD183B91D4BF74E1826EA1D0DFFE703_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6BD183B91D4BF74E1826EA1D0DFFE703.report
Scheduling successful
submit!!!
jobs = 60
day = 110 run = 15110011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110011/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:23:33 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.05 03:23:34 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:23:34 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:23:36 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:23:37 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process B6A929E2E1732E9FAFD4787BB07F5143_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B6A929E2E1732E9FAFD4787BB07F5143_2... done.
Writting process B6A929E2E1732E9FAFD4787BB07F5143_1... done.
Writting process B6A929E2E1732E9FAFD4787BB07F5143_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB6A929E2E1732E9FAFD4787BB07F5143.report
Scheduling successful
submit!!!
jobs = 63
day = 110 run = 15110012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110012/*.root.log: No such file or directory
207
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:24:55 PDT] Dataset size is 207 files
Removing files not on site LBL
[2017.09.05 03:24:55 PDT] Dataset size is 207 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:24:55 PDT] Dataset size is 207 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:24:58 PDT] Started with 207 files, current size is 207files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:24:59 PDT] Dataset size is 207 files
----------------------------------------------------
validating dataset ....passed
Writting process D6CAA9661CED1C8B26C5056DCF521B52_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D6CAA9661CED1C8B26C5056DCF521B52_2... done.
Writting process D6CAA9661CED1C8B26C5056DCF521B52_1... done.
Writting process D6CAA9661CED1C8B26C5056DCF521B52_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD6CAA9661CED1C8B26C5056DCF521B52.report
Scheduling successful
submit!!!
jobs = 65
day = 110 run = 15110013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110013/*.root.log: No such file or directory
93
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:26:11 PDT] Dataset size is 93 files
Removing files not on site LBL
[2017.09.05 03:26:11 PDT] Dataset size is 93 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:26:12 PDT] Dataset size is 93 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:26:14 PDT] Started with 93 files, current size is 93files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:26:16 PDT] Dataset size is 93 files
----------------------------------------------------
validating dataset ....passed
Writting process 06FE11126DE2FC7BC0DDB0D908F1DA09_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched06FE11126DE2FC7BC0DDB0D908F1DA09.report
Scheduling successful
submit!!!
jobs = 66
day = 110 run = 15110026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110026/*.root.log: No such file or directory
78
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:27:25 PDT] Dataset size is 78 files
Removing files not on site LBL
[2017.09.05 03:27:25 PDT] Dataset size is 78 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:27:25 PDT] Dataset size is 78 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:27:26 PDT] Started with 78 files, current size is 78files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:27:27 PDT] Dataset size is 78 files
----------------------------------------------------
validating dataset ....passed
Writting process A02C6C6EC0560A215C792DF3B3CEE9FD_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA02C6C6EC0560A215C792DF3B3CEE9FD.report
Scheduling successful
submit!!!
jobs = 67
day = 110 run = 15110027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110027/*.root.log: No such file or directory
197
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:28:42 PDT] Dataset size is 197 files
Removing files not on site LBL
[2017.09.05 03:28:42 PDT] Dataset size is 197 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:28:42 PDT] Dataset size is 197 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:28:43 PDT] Started with 197 files, current size is 197files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:28:43 PDT] Dataset size is 197 files
----------------------------------------------------
validating dataset ....passed
Writting process F549D4193D235438687FAFAA8F55F31A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F549D4193D235438687FAFAA8F55F31A_1... done.
Writting process F549D4193D235438687FAFAA8F55F31A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF549D4193D235438687FAFAA8F55F31A.report
Scheduling successful
submit!!!
jobs = 68
day = 110 run = 15110028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110028/*.root.log: No such file or directory
207
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:29:58 PDT] Dataset size is 207 files
Removing files not on site LBL
[2017.09.05 03:29:58 PDT] Dataset size is 207 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:29:58 PDT] Dataset size is 207 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:29:59 PDT] Started with 207 files, current size is 207files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:29:59 PDT] Dataset size is 207 files
----------------------------------------------------
validating dataset ....passed
Writting process 71F082F45C97111AADE0D98EA5150170_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 71F082F45C97111AADE0D98EA5150170_2... done.
Writting process 71F082F45C97111AADE0D98EA5150170_1... done.
Writting process 71F082F45C97111AADE0D98EA5150170_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched71F082F45C97111AADE0D98EA5150170.report
Scheduling successful
submit!!!
jobs = 70
day = 110 run = 15110029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110029/*.root.log: No such file or directory
218
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:31:17 PDT] Dataset size is 218 files
Removing files not on site LBL
[2017.09.05 03:31:17 PDT] Dataset size is 218 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:31:17 PDT] Dataset size is 218 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:31:17 PDT] Started with 218 files, current size is 218files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:31:17 PDT] Dataset size is 218 files
----------------------------------------------------
validating dataset ....passed
Writting process B1EE8C4E99260F5C50177D2457838200_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B1EE8C4E99260F5C50177D2457838200_2... done.
Writting process B1EE8C4E99260F5C50177D2457838200_1... done.
Writting process B1EE8C4E99260F5C50177D2457838200_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB1EE8C4E99260F5C50177D2457838200.report
Scheduling successful
submit!!!
jobs = 72
day = 110 run = 15110030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110030/*.root.log: No such file or directory
208
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:32:31 PDT] Dataset size is 208 files
Removing files not on site LBL
[2017.09.05 03:32:32 PDT] Dataset size is 208 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:32:32 PDT] Dataset size is 208 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:32:34 PDT] Started with 208 files, current size is 208files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:32:35 PDT] Dataset size is 208 files
----------------------------------------------------
validating dataset ....passed
Writting process 8F047C4732435A39A0546AA78814CEE4_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8F047C4732435A39A0546AA78814CEE4_2... done.
Writting process 8F047C4732435A39A0546AA78814CEE4_1... done.
Writting process 8F047C4732435A39A0546AA78814CEE4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8F047C4732435A39A0546AA78814CEE4.report
Scheduling successful
submit!!!
jobs = 73
day = 110 run = 15110031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110031/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:33:47 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 03:33:47 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:33:47 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:33:47 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:33:47 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process 46EB16C33590C426728616963316A269_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 46EB16C33590C426728616963316A269_1... done.
Writting process 46EB16C33590C426728616963316A269_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched46EB16C33590C426728616963316A269.report
Scheduling successful
submit!!!
jobs = 73
day = 110 run = 15110032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110032/*.root.log: No such file or directory
2
2 2
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:34:56 PDT] Dataset size is 2 files
Removing files not on site LBL
[2017.09.05 03:34:57 PDT] Dataset size is 2 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:34:58 PDT] Dataset size is 2 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:35:00 PDT] Started with 2 files, current size is 2files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=2 ,maxSize=2 )
[2017.09.05 03:35:01 PDT] Dataset size is 2 files
----------------------------------------------------
validating dataset ....passed
Writting process 943FACC8D17E9CB7BFBAAB7DD8AA5D8B_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched943FACC8D17E9CB7BFBAAB7DD8AA5D8B.report
Scheduling successful
submit!!!
jobs = 70
day = 110 run = 15110033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110033/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:36:15 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.05 03:36:15 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:36:15 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:36:16 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:36:17 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 448D3344F03E362F56B84479865A142C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 448D3344F03E362F56B84479865A142C_2... done.
Writting process 448D3344F03E362F56B84479865A142C_1... done.
Writting process 448D3344F03E362F56B84479865A142C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched448D3344F03E362F56B84479865A142C.report
Scheduling successful
submit!!!
jobs = 71
day = 110 run = 15110034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110034/*.root.log: No such file or directory
130
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:37:32 PDT] Dataset size is 130 files
Removing files not on site LBL
[2017.09.05 03:37:33 PDT] Dataset size is 130 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:37:34 PDT] Dataset size is 130 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:37:35 PDT] Started with 130 files, current size is 130files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:37:36 PDT] Dataset size is 130 files
----------------------------------------------------
validating dataset ....passed
Writting process BD15F87C2C18A8025D45B59BC56B8E3A_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BD15F87C2C18A8025D45B59BC56B8E3A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBD15F87C2C18A8025D45B59BC56B8E3A.report
Scheduling successful
submit!!!
jobs = 71
day = 110 run = 15110035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110035/*.root.log: No such file or directory
93
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:38:49 PDT] Dataset size is 93 files
Removing files not on site LBL
[2017.09.05 03:38:49 PDT] Dataset size is 93 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:38:49 PDT] Dataset size is 93 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:38:49 PDT] Started with 93 files, current size is 93files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:38:49 PDT] Dataset size is 93 files
----------------------------------------------------
validating dataset ....passed
Writting process 10F08A41E9796774FAD8511AD108EA35_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched10F08A41E9796774FAD8511AD108EA35.report
Scheduling successful
submit!!!
jobs = 70
day = 110 run = 15110050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110050/*.root.log: No such file or directory
148
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:40:03 PDT] Dataset size is 148 files
Removing files not on site LBL
[2017.09.05 03:40:05 PDT] Dataset size is 148 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:40:06 PDT] Dataset size is 148 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:40:08 PDT] Started with 148 files, current size is 148files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:40:08 PDT] Dataset size is 148 files
----------------------------------------------------
validating dataset ....passed
Writting process AC0730524E000786C79E8D291227D9FB_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AC0730524E000786C79E8D291227D9FB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAC0730524E000786C79E8D291227D9FB.report
Scheduling successful
submit!!!
jobs = 72
day = 110 run = 15110051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110051/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:41:24 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 03:41:24 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:41:25 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:41:27 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:41:27 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 96C3E3BEAD93B9EA86FBD011B838D5AE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 96C3E3BEAD93B9EA86FBD011B838D5AE_1... done.
Writting process 96C3E3BEAD93B9EA86FBD011B838D5AE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched96C3E3BEAD93B9EA86FBD011B838D5AE.report
Scheduling successful
submit!!!
jobs = 74
day = 110 run = 15110052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110052/*.root.log: No such file or directory
219
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:42:44 PDT] Dataset size is 219 files
Removing files not on site LBL
[2017.09.05 03:42:45 PDT] Dataset size is 219 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:42:45 PDT] Dataset size is 219 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:42:46 PDT] Started with 219 files, current size is 219files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:42:46 PDT] Dataset size is 219 files
----------------------------------------------------
validating dataset ....passed
Writting process 75006A15B1C905828B175CF44B206AC1_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 75006A15B1C905828B175CF44B206AC1_2... done.
Writting process 75006A15B1C905828B175CF44B206AC1_1... done.
Writting process 75006A15B1C905828B175CF44B206AC1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched75006A15B1C905828B175CF44B206AC1.report
Scheduling successful
submit!!!
jobs = 78
day = 110 run = 15110053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15110053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15110053/*.root.log: No such file or directory
71
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:43:54 PDT] Dataset size is 71 files
Removing files not on site LBL
[2017.09.05 03:43:55 PDT] Dataset size is 71 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:43:55 PDT] Dataset size is 71 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:43:55 PDT] Started with 71 files, current size is 71files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:43:55 PDT] Dataset size is 71 files
----------------------------------------------------
validating dataset ....passed
Writting process 4E5FDABE1AF4D287AF41FEA45886A1DE_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4E5FDABE1AF4D287AF41FEA45886A1DE.report
Scheduling successful
submit!!!
Job submission for day 110 finished!
111
jobs = 79
day = 111 run = 15111067
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15111067/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15111067/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:45:10 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 03:45:11 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:45:11 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:45:11 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:45:11 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process ED899D6F00B8B6153E86F9D9C7BDC0EE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ED899D6F00B8B6153E86F9D9C7BDC0EE_1... done.
Writting process ED899D6F00B8B6153E86F9D9C7BDC0EE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedED899D6F00B8B6153E86F9D9C7BDC0EE.report
Scheduling successful
submit!!!
jobs = 81
day = 111 run = 15111068
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15111068/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15111068/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:48:53 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 03:48:54 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:48:55 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:48:56 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:48:56 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process BCAAD1828D0FF577D7143051F27EC322_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BCAAD1828D0FF577D7143051F27EC322_1... done.
Writting process BCAAD1828D0FF577D7143051F27EC322_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBCAAD1828D0FF577D7143051F27EC322.report
Scheduling successful
submit!!!
Job submission for day 111 finished!
112
jobs = 82
day = 112 run = 15112001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112001/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:50:12 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 03:50:12 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:50:12 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:50:13 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:50:13 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process 8C8B9EE80692BFD22147B85FE3344752_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8C8B9EE80692BFD22147B85FE3344752_1... done.
Writting process 8C8B9EE80692BFD22147B85FE3344752_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8C8B9EE80692BFD22147B85FE3344752.report
Scheduling successful
submit!!!
jobs = 83
day = 112 run = 15112003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112003/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:51:26 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 03:51:26 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:51:27 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:51:27 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:51:27 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process F4C00E056D07EA672D0B9BE1F30BA2DE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F4C00E056D07EA672D0B9BE1F30BA2DE_1... done.
Writting process F4C00E056D07EA672D0B9BE1F30BA2DE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF4C00E056D07EA672D0B9BE1F30BA2DE.report
Scheduling successful
submit!!!
jobs = 85
day = 112 run = 15112004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112004/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:52:42 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 03:52:42 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:52:42 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:52:43 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:52:43 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 596C44F79CDCB59154EFBCB10090E373_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 596C44F79CDCB59154EFBCB10090E373_1... done.
Writting process 596C44F79CDCB59154EFBCB10090E373_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched596C44F79CDCB59154EFBCB10090E373.report
Scheduling successful
submit!!!
jobs = 86
day = 112 run = 15112005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112005/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:53:58 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 03:53:58 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:53:58 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:53:59 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:54:00 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process 99FBB055F662B764659DC64E00536182_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 99FBB055F662B764659DC64E00536182_1... done.
Writting process 99FBB055F662B764659DC64E00536182_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched99FBB055F662B764659DC64E00536182.report
Scheduling successful
submit!!!
jobs = 85
day = 112 run = 15112006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112006/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:55:17 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 03:55:18 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:55:18 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:55:19 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:55:19 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process F14CF352E6DC257F8B9AC217CC08EEA0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F14CF352E6DC257F8B9AC217CC08EEA0_1... done.
Writting process F14CF352E6DC257F8B9AC217CC08EEA0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF14CF352E6DC257F8B9AC217CC08EEA0.report
Scheduling successful
submit!!!
jobs = 87
day = 112 run = 15112007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112007/*.root.log: No such file or directory
46
46 46
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:56:29 PDT] Dataset size is 46 files
Removing files not on site LBL
[2017.09.05 03:56:29 PDT] Dataset size is 46 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:56:29 PDT] Dataset size is 46 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:56:31 PDT] Started with 46 files, current size is 46files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=46 ,maxSize=46 )
[2017.09.05 03:56:31 PDT] Dataset size is 46 files
----------------------------------------------------
validating dataset ....passed
Writting process D35EBAA29D4049DDA14EA533DA3AD92B_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD35EBAA29D4049DDA14EA533DA3AD92B.report
Scheduling successful
submit!!!
jobs = 87
day = 112 run = 15112023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112023/*.root.log: No such file or directory
108
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:57:45 PDT] Dataset size is 108 files
Removing files not on site LBL
[2017.09.05 03:57:47 PDT] Dataset size is 108 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:57:48 PDT] Dataset size is 108 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:57:50 PDT] Started with 108 files, current size is 108files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:57:51 PDT] Dataset size is 108 files
----------------------------------------------------
validating dataset ....passed
Writting process 5FE1853BFEFA3C3DE7D0957420942CA6_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5FE1853BFEFA3C3DE7D0957420942CA6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5FE1853BFEFA3C3DE7D0957420942CA6.report
Scheduling successful
submit!!!
jobs = 88
day = 112 run = 15112024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112024/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 03:59:06 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 03:59:07 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 03:59:08 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 03:59:09 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 03:59:10 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process F9BD9D2CADDBECCA12A9110E27086BAF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F9BD9D2CADDBECCA12A9110E27086BAF_1... done.
Writting process F9BD9D2CADDBECCA12A9110E27086BAF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF9BD9D2CADDBECCA12A9110E27086BAF.report
Scheduling successful
submit!!!
jobs = 90
day = 112 run = 15112025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112025/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:00:25 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 04:00:25 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:00:25 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:00:26 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:00:26 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 6FC312BED9A262BD24826CB978E3CEE8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6FC312BED9A262BD24826CB978E3CEE8_1... done.
Writting process 6FC312BED9A262BD24826CB978E3CEE8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6FC312BED9A262BD24826CB978E3CEE8.report
Scheduling successful
submit!!!
jobs = 90
day = 112 run = 15112026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112026/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:01:45 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 04:01:45 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:01:45 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:01:45 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:01:45 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 88F42A1C11D969E4AB69F59B454B9941_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 88F42A1C11D969E4AB69F59B454B9941_1... done.
Writting process 88F42A1C11D969E4AB69F59B454B9941_0... done.
Submitting array... done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched88F42A1C11D969E4AB69F59B454B9941.report
Scheduling successful
submit!!!
jobs = 90
day = 112 run = 15112027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112027/*.root.log: No such file or directory
163
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:03:02 PDT] Dataset size is 163 files
Removing files not on site LBL
[2017.09.05 04:03:02 PDT] Dataset size is 163 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:03:03 PDT] Dataset size is 163 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:03:04 PDT] Started with 163 files, current size is 163files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:03:06 PDT] Dataset size is 163 files
----------------------------------------------------
validating dataset ....passed
Writting process 0FDCFA4CCE316E880D3643D2F6846079_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0FDCFA4CCE316E880D3643D2F6846079_1... done.
Writting process 0FDCFA4CCE316E880D3643D2F6846079_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0FDCFA4CCE316E880D3643D2F6846079.report
Scheduling successful
submit!!!
jobs = 92
day = 112 run = 15112028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112028/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:04:25 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 04:04:26 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:04:27 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:04:29 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:04:30 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 400E7E4D3392BB379B4FD6DFA3CDF98D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 400E7E4D3392BB379B4FD6DFA3CDF98D_1... done.
Writting process 400E7E4D3392BB379B4FD6DFA3CDF98D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched400E7E4D3392BB379B4FD6DFA3CDF98D.report
Scheduling successful
submit!!!
jobs = 90
day = 112 run = 15112029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112029/*.root.log: No such file or directory
169
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:05:50 PDT] Dataset size is 169 files
Removing files not on site LBL
[2017.09.05 04:05:52 PDT] Dataset size is 169 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:05:53 PDT] Dataset size is 169 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:05:56 PDT] Started with 169 files, current size is 169files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:05:56 PDT] Dataset size is 169 files
----------------------------------------------------
validating dataset ....passed
Writting process E6E407F12AD662850CA178CDF2E593AD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E6E407F12AD662850CA178CDF2E593AD_1... done.
Writting process E6E407F12AD662850CA178CDF2E593AD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE6E407F12AD662850CA178CDF2E593AD.report
Scheduling successful
submit!!!
jobs = 89
day = 112 run = 15112030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112030/*.root.log: No such file or directory
132
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:07:46 PDT] Dataset size is 132 files
Removing files not on site LBL
[2017.09.05 04:07:48 PDT] Dataset size is 132 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:07:48 PDT] Dataset size is 132 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:07:48 PDT] Started with 132 files, current size is 132files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:07:48 PDT] Dataset size is 132 files
----------------------------------------------------
validating dataset ....passed
Writting process 8916E08A7B753F0D8AD5D4D933A366D2_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8916E08A7B753F0D8AD5D4D933A366D2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8916E08A7B753F0D8AD5D4D933A366D2.report
Scheduling successful
submit!!!
jobs = 87
day = 112 run = 15112031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112031/*.root.log: No such file or directory
143
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:09:37 PDT] Dataset size is 143 files
Removing files not on site LBL
[2017.09.05 04:09:38 PDT] Dataset size is 143 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:09:39 PDT] Dataset size is 143 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:09:41 PDT] Started with 143 files, current size is 143files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:09:42 PDT] Dataset size is 143 files
----------------------------------------------------
validating dataset ....passed
Writting process 15CBB1D92BC079282E8A4465B33F3332_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 15CBB1D92BC079282E8A4465B33F3332_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched15CBB1D92BC079282E8A4465B33F3332.report
Scheduling successful
submit!!!
jobs = 86
day = 112 run = 15112046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112046/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:11:13 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 04:11:16 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:11:17 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:11:20 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:11:21 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 773672EEF6C52DD98764E1C91D29A24B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 773672EEF6C52DD98764E1C91D29A24B_1... done.
Writting process 773672EEF6C52DD98764E1C91D29A24B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched773672EEF6C52DD98764E1C91D29A24B.report
Scheduling successful
submit!!!
jobs = 87
day = 112 run = 15112047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112047/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:12:37 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 04:12:37 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:12:37 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:12:37 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:12:37 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process 2EE069ED281FA6500A40ABDEF6F3F204_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2EE069ED281FA6500A40ABDEF6F3F204_1... done.
Writting process 2EE069ED281FA6500A40ABDEF6F3F204_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2EE069ED281FA6500A40ABDEF6F3F204.report
Scheduling successful
submit!!!
jobs = 88
day = 112 run = 15112048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112048/*.root.log: No such file or directory
134
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:13:54 PDT] Dataset size is 134 files
Removing files not on site LBL
[2017.09.05 04:13:55 PDT] Dataset size is 134 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:13:55 PDT] Dataset size is 134 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:13:56 PDT] Started with 134 files, current size is 134files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:13:56 PDT] Dataset size is 134 files
----------------------------------------------------
validating dataset ....passed
Writting process C8966F43786BEFB96E40CF89610E0BC8_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C8966F43786BEFB96E40CF89610E0BC8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC8966F43786BEFB96E40CF89610E0BC8.report
Scheduling successful
submit!!!
jobs = 85
day = 112 run = 15112049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112049/*.root.log: No such file or directory
34
34 34
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:15:07 PDT] Dataset size is 34 files
Removing files not on site LBL
[2017.09.05 04:15:07 PDT] Dataset size is 34 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:15:07 PDT] Dataset size is 34 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:15:07 PDT] Started with 34 files, current size is 34files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=34 ,maxSize=34 )
[2017.09.05 04:15:07 PDT] Dataset size is 34 files
----------------------------------------------------
validating dataset ....passed
Writting process 14306909744B5DC48EA274C6F7E00556_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched14306909744B5DC48EA274C6F7E00556.report
Scheduling successful
submit!!!
jobs = 82
day = 112 run = 15112050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112050/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:16:24 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 04:16:24 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:16:25 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:16:26 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:16:26 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process D477A3D877F02F619B13ABE1755DE517_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D477A3D877F02F619B13ABE1755DE517_1... done.
Writting process D477A3D877F02F619B13ABE1755DE517_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD477A3D877F02F619B13ABE1755DE517.report
Scheduling successful
submit!!!
jobs = 82
day = 112 run = 15112051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15112051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15112051/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:17:42 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 04:17:42 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:17:42 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:17:43 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:17:43 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 65EB2C9D107CF10AC0145E80DBC91562_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 65EB2C9D107CF10AC0145E80DBC91562_1... done.
Writting process 65EB2C9D107CF10AC0145E80DBC91562_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched65EB2C9D107CF10AC0145E80DBC91562.report
Scheduling successful
submit!!!
Job submission for day 112 finished!
113
jobs = 83
day = 113 run = 15113001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15113001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15113001/*.root.log: No such file or directory
124
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:18:59 PDT] Dataset size is 124 files
Removing files not on site LBL
[2017.09.05 04:19:00 PDT] Dataset size is 124 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:19:00 PDT] Dataset size is 124 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:19:00 PDT] Started with 124 files, current size is 124files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:19:00 PDT] Dataset size is 124 files
----------------------------------------------------
validating dataset ....passed
Writting process B393F6D3E62CD7378ADDA7EADD53A30F_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B393F6D3E62CD7378ADDA7EADD53A30F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB393F6D3E62CD7378ADDA7EADD53A30F.report
Scheduling successful
submit!!!
Job submission for day 113 finished!
114
jobs = 80
day = 114 run = 15114046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114046/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:20:16 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 04:20:17 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:20:17 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:20:17 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:20:17 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process BF60FBED127EA25F2437E1901B805F78_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BF60FBED127EA25F2437E1901B805F78_1... done.
Writting process BF60FBED127EA25F2437E1901B805F78_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBF60FBED127EA25F2437E1901B805F78.report
Scheduling successful
submit!!!
jobs = 81
day = 114 run = 15114047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114047/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:21:31 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 04:21:31 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:21:31 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:21:32 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:21:33 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 44558B2694DBC7CEBD58F3F13FD126D9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 44558B2694DBC7CEBD58F3F13FD126D9_1... done.
Writting process 44558B2694DBC7CEBD58F3F13FD126D9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched44558B2694DBC7CEBD58F3F13FD126D9.report
Scheduling successful
submit!!!
jobs = 81
day = 114 run = 15114048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114048/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:22:50 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 04:22:51 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:22:53 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:22:56 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:22:58 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process 49BB5A1A8EA0B99E54173D6154E28C27_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 49BB5A1A8EA0B99E54173D6154E28C27_1... done.
Writting process 49BB5A1A8EA0B99E54173D6154E28C27_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched49BB5A1A8EA0B99E54173D6154E28C27.report
Scheduling successful
submit!!!
jobs = 83
day = 114 run = 15114050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114050/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:24:15 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 04:24:17 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:24:18 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:24:18 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:24:18 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 62393A8A79F914683C40A0523A728EB2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 62393A8A79F914683C40A0523A728EB2_1... done.
Writting process 62393A8A79F914683C40A0523A728EB2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched62393A8A79F914683C40A0523A728EB2.report
Scheduling successful
submit!!!
jobs = 84
day = 114 run = 15114051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114051/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:25:32 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 04:25:32 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:25:32 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:25:32 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:25:32 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 1552BAB1A05504FE47FA7E00D669E53E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1552BAB1A05504FE47FA7E00D669E53E_1... done.
Writting process 1552BAB1A05504FE47FA7E00D669E53E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1552BAB1A05504FE47FA7E00D669E53E.report
Scheduling successful
submit!!!
jobs = 84
day = 114 run = 15114052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114052/*.root.log: No such file or directory
99
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:26:50 PDT] Dataset size is 99 files
Removing files not on site LBL
[2017.09.05 04:26:52 PDT] Dataset size is 99 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:26:53 PDT] Dataset size is 99 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:26:57 PDT] Started with 99 files, current size is 99files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:26:59 PDT] Dataset size is 99 files
----------------------------------------------------
validating dataset ....passed
Writting process 4AE0EF542DE6E09012566B8CB1365FFE_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4AE0EF542DE6E09012566B8CB1365FFE.report
Scheduling successful
submit!!!
jobs = 79
day = 114 run = 15114053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114053/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:28:14 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 04:28:14 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:28:14 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:28:14 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:28:14 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process EADBDECD053A70A0D2A73267F9B937C3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EADBDECD053A70A0D2A73267F9B937C3_1... done.
Writting process EADBDECD053A70A0D2A73267F9B937C3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEADBDECD053A70A0D2A73267F9B937C3.report
Scheduling successful
submit!!!
jobs = 79
day = 114 run = 15114054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114054/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:29:31 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 04:29:31 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:29:31 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:29:32 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:29:32 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process AD5FBF53063473AE36A555603360B770_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AD5FBF53063473AE36A555603360B770_1... done.
Writting process AD5FBF53063473AE36A555603360B770_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD5FBF53063473AE36A555603360B770.report
Scheduling successful
submit!!!
jobs = 81
day = 114 run = 15114055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114055/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:30:47 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 04:30:47 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:30:48 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:30:50 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:30:51 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 14F9CC80BDE7ADC430E9F237A59F316C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 14F9CC80BDE7ADC430E9F237A59F316C_1... done.
Writting process 14F9CC80BDE7ADC430E9F237A59F316C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched14F9CC80BDE7ADC430E9F237A59F316C.report
Scheduling successful
submit!!!
jobs = 81
day = 114 run = 15114056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114056/*.root.log: No such file or directory
72
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:32:03 PDT] Dataset size is 72 files
Removing files not on site LBL
[2017.09.05 04:32:04 PDT] Dataset size is 72 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:32:05 PDT] Dataset size is 72 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:32:06 PDT] Started with 72 files, current size is 72files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:32:06 PDT] Dataset size is 72 files
----------------------------------------------------
validating dataset ....passed
Writting process 0F53E591FBB47DB4348BC4642CCEF85D_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0F53E591FBB47DB4348BC4642CCEF85D.report
Scheduling successful
submit!!!
jobs = 81
day = 114 run = 15114057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114057/*.root.log: No such file or directory
136
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:33:26 PDT] Dataset size is 136 files
Removing files not on site LBL
[2017.09.05 04:33:26 PDT] Dataset size is 136 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:33:27 PDT] Dataset size is 136 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:33:27 PDT] Started with 136 files, current size is 136files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:33:27 PDT] Dataset size is 136 files
----------------------------------------------------
validating dataset ....passed
Writting process A20DE32DB99699771596E135E8CF82E3_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A20DE32DB99699771596E135E8CF82E3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA20DE32DB99699771596E135E8CF82E3.report
Scheduling successful
submit!!!
jobs = 78
day = 114 run = 15114058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15114058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15114058/*.root.log: No such file or directory
60
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:34:39 PDT] Dataset size is 60 files
Removing files not on site LBL
[2017.09.05 04:34:40 PDT] Dataset size is 60 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:34:40 PDT] Dataset size is 60 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:34:42 PDT] Started with 60 files, current size is 60files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:34:42 PDT] Dataset size is 60 files
----------------------------------------------------
validating dataset ....passed
Writting process 59C54E0392432D5CF06DB3AF9F1622BF_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched59C54E0392432D5CF06DB3AF9F1622BF.report
Scheduling successful
submit!!!
Job submission for day 114 finished!
115
jobs = 77
day = 115 run = 15115079
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115079/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115079/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:36:00 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 04:36:02 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:36:03 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:36:05 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:36:05 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process CCED52D4A2AA857B1BAEE2ED2660CE89_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CCED52D4A2AA857B1BAEE2ED2660CE89_1... done.
Writting process CCED52D4A2AA857B1BAEE2ED2660CE89_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCCED52D4A2AA857B1BAEE2ED2660CE89.report
Scheduling successful
submit!!!
jobs = 79
day = 115 run = 15115080
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115080/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115080/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:37:24 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 04:37:27 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:37:30 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:37:34 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:37:35 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process E9EC264B75514FBD0BAD32D023103E1F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E9EC264B75514FBD0BAD32D023103E1F_1... done.
Writting process E9EC264B75514FBD0BAD32D023103E1F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE9EC264B75514FBD0BAD32D023103E1F.report
Scheduling successful
submit!!!
jobs = 80
day = 115 run = 15115082
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115082/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115082/*.root.log: No such file or directory
229
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:38:57 PDT] Dataset size is 229 files
Removing files not on site LBL
[2017.09.05 04:38:57 PDT] Dataset size is 229 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:38:57 PDT] Dataset size is 229 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:38:58 PDT] Started with 229 files, current size is 229files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:38:59 PDT] Dataset size is 229 files
----------------------------------------------------
validating dataset ....passed
Writting process 81D5D1591B64F83660B0B34DF4236E1E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 81D5D1591B64F83660B0B34DF4236E1E_2... done.
Writting process 81D5D1591B64F83660B0B34DF4236E1E_1... done.
Writting process 81D5D1591B64F83660B0B34DF4236E1E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched81D5D1591B64F83660B0B34DF4236E1E.report
Scheduling successful
submit!!!
jobs = 79
day = 115 run = 15115083
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115083/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115083/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:40:32 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 04:40:35 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:40:37 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:40:39 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:40:40 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process AB13C85B54B8D3E60B6E7B1CA2AB3650_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AB13C85B54B8D3E60B6E7B1CA2AB3650_1... done.
Writting process AB13C85B54B8D3E60B6E7B1CA2AB3650_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAB13C85B54B8D3E60B6E7B1CA2AB3650.report
Scheduling successful
submit!!!
jobs = 81
day = 115 run = 15115084
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115084/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115084/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:41:53 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 04:41:54 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:41:56 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:41:59 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:42:00 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 4CD38EF7B0FD53EA98F67B9A4ACC69AD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4CD38EF7B0FD53EA98F67B9A4ACC69AD_1... done.
Writting process 4CD38EF7B0FD53EA98F67B9A4ACC69AD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4CD38EF7B0FD53EA98F67B9A4ACC69AD.report
Scheduling successful
submit!!!
jobs = 84
day = 115 run = 15115085
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115085/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115085/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:43:14 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 04:43:15 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:43:16 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:43:18 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:43:18 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 88CCB0BCCF6A31D5C5BE4E8F7780D4AE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 88CCB0BCCF6A31D5C5BE4E8F7780D4AE_1... done.
Writting process 88CCB0BCCF6A31D5C5BE4E8F7780D4AE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched88CCB0BCCF6A31D5C5BE4E8F7780D4AE.report
Scheduling successful
submit!!!
jobs = 85
day = 115 run = 15115086
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115086/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115086/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:44:37 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 04:44:38 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:44:38 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:44:39 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:44:40 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process AD9E744462FCE7D1DB6859AA6B4BD69C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AD9E744462FCE7D1DB6859AA6B4BD69C_1... done.
Writting process AD9E744462FCE7D1DB6859AA6B4BD69C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD9E744462FCE7D1DB6859AA6B4BD69C.report
Scheduling successful
submit!!!
jobs = 85
day = 115 run = 15115087
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115087/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115087/*.root.log: No such file or directory
105
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:45:56 PDT] Dataset size is 105 files
Removing files not on site LBL
[2017.09.05 04:45:57 PDT] Dataset size is 105 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:45:57 PDT] Dataset size is 105 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:45:57 PDT] Started with 105 files, current size is 105files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:45:57 PDT] Dataset size is 105 files
----------------------------------------------------
validating dataset ....passed
Writting process F720994E59656D48D7E983E9874397CC_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F720994E59656D48D7E983E9874397CC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF720994E59656D48D7E983E9874397CC.report
Scheduling successful
submit!!!
jobs = 86
day = 115 run = 15115088
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15115088/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15115088/*.root.log: No such file or directory
42
42 42
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:47:09 PDT] Dataset size is 42 files
Removing files not on site LBL
[2017.09.05 04:47:10 PDT] Dataset size is 42 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:47:11 PDT] Dataset size is 42 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:47:12 PDT] Started with 42 files, current size is 42files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=42 ,maxSize=42 )
[2017.09.05 04:47:13 PDT] Dataset size is 42 files
----------------------------------------------------
validating dataset ....passed
Writting process FC3FDDC88D90C76CA932F6AC173BE7FA_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFC3FDDC88D90C76CA932F6AC173BE7FA.report
Scheduling successful
submit!!!
Job submission for day 115 finished!
116
jobs = 83
day = 116 run = 15116032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116032/*.root.log: No such file or directory
159
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:48:52 PDT] Dataset size is 159 files
Removing files not on site LBL
[2017.09.05 04:48:54 PDT] Dataset size is 159 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:48:57 PDT] Dataset size is 159 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:49:00 PDT] Started with 159 files, current size is 159files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:49:00 PDT] Dataset size is 159 files
----------------------------------------------------
validating dataset ....passed
Writting process DA9D79BC209D3D749DACE7CDE961E407_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DA9D79BC209D3D749DACE7CDE961E407_1... done.
Writting process DA9D79BC209D3D749DACE7CDE961E407_0... done.
Submitting array... done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDA9D79BC209D3D749DACE7CDE961E407.report
Scheduling successful
submit!!!
jobs = 79
day = 116 run = 15116033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116033/*.root.log: No such file or directory
155
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:50:20 PDT] Dataset size is 155 files
Removing files not on site LBL
[2017.09.05 04:50:21 PDT] Dataset size is 155 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:50:22 PDT] Dataset size is 155 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:50:23 PDT] Started with 155 files, current size is 155files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:50:24 PDT] Dataset size is 155 files
----------------------------------------------------
validating dataset ....passed
Writting process A5E7D149ED61895CAE207139944DDCF1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A5E7D149ED61895CAE207139944DDCF1_1... done.
Writting process A5E7D149ED61895CAE207139944DDCF1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA5E7D149ED61895CAE207139944DDCF1.report
Scheduling successful
submit!!!
jobs = 80
day = 116 run = 15116034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116034/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:51:40 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 04:51:41 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:51:42 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:51:42 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:51:43 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process 68500618E818464EC825B028AD56FE7B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 68500618E818464EC825B028AD56FE7B_1... done.
Writting process 68500618E818464EC825B028AD56FE7B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched68500618E818464EC825B028AD56FE7B.report
Scheduling successful
submit!!!
jobs = 79
day = 116 run = 15116035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116035/*.root.log: No such file or directory
54
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:52:56 PDT] Dataset size is 54 files
Removing files not on site LBL
[2017.09.05 04:52:56 PDT] Dataset size is 54 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:52:56 PDT] Dataset size is 54 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:52:56 PDT] Started with 54 files, current size is 54files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:52:56 PDT] Dataset size is 54 files
----------------------------------------------------
validating dataset ....passed
Writting process C2E09A1679E167A74DF5624204C0EFC9_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC2E09A1679E167A74DF5624204C0EFC9.report
Scheduling successful
submit!!!
jobs = 78
day = 116 run = 15116036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116036/*.root.log: No such file or directory
154
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:54:10 PDT] Dataset size is 154 files
Removing files not on site LBL
[2017.09.05 04:54:10 PDT] Dataset size is 154 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:54:11 PDT] Dataset size is 154 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:54:13 PDT] Started with 154 files, current size is 154files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:54:13 PDT] Dataset size is 154 files
----------------------------------------------------
validating dataset ....passed
Writting process DFBD3964713D2D59A601BDF0B7930206_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DFBD3964713D2D59A601BDF0B7930206_1... done.
Writting process DFBD3964713D2D59A601BDF0B7930206_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDFBD3964713D2D59A601BDF0B7930206.report
Scheduling successful
submit!!!
jobs = 79
day = 116 run = 15116037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116037/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:55:28 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 04:55:29 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:55:29 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:55:31 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:55:31 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 6C1E5A6782B290908CE3AACF5F312673_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6C1E5A6782B290908CE3AACF5F312673_1... done.
Writting process 6C1E5A6782B290908CE3AACF5F312673_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6C1E5A6782B290908CE3AACF5F312673.report
Scheduling successful
submit!!!
jobs = 81
day = 116 run = 15116039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116039/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:56:46 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 04:56:46 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:56:46 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:56:46 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:56:47 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 3268141E68BFF4C2363EA36A71164874_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3268141E68BFF4C2363EA36A71164874_1... done.
Writting process 3268141E68BFF4C2363EA36A71164874_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3268141E68BFF4C2363EA36A71164874.report
Scheduling successful
submit!!!
jobs = 83
day = 116 run = 15116040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116040/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:58:05 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 04:58:05 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:58:05 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:58:06 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:58:06 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process EDCA3E6328E221934420E5D197B65446_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EDCA3E6328E221934420E5D197B65446_1... done.
Writting process EDCA3E6328E221934420E5D197B65446_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEDCA3E6328E221934420E5D197B65446.report
Scheduling successful
submit!!!
jobs = 85
day = 116 run = 15116041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116041/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 04:59:24 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 04:59:24 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 04:59:24 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 04:59:25 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 04:59:25 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process B3524A799FFE9F4443E1812697CE90D1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B3524A799FFE9F4443E1812697CE90D1_1... done.
Writting process B3524A799FFE9F4443E1812697CE90D1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB3524A799FFE9F4443E1812697CE90D1.report
Scheduling successful
submit!!!
jobs = 87
day = 116 run = 15116042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116042/*.root.log: No such file or directory
138
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:00:50 PDT] Dataset size is 138 files
Removing files not on site LBL
[2017.09.05 05:00:51 PDT] Dataset size is 138 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:00:52 PDT] Dataset size is 138 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:00:52 PDT] Started with 138 files, current size is 138files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:00:53 PDT] Dataset size is 138 files
----------------------------------------------------
validating dataset ....passed
Writting process BD1EA1164E72B02AC1D505F5C1920A37_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BD1EA1164E72B02AC1D505F5C1920A37_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBD1EA1164E72B02AC1D505F5C1920A37.report
Scheduling successful
submit!!!
jobs = 88
day = 116 run = 15116059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116059/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:02:10 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 05:02:11 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:02:11 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:02:11 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:02:11 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process CB73CD141C3D4A214FB3936C1C5B924B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CB73CD141C3D4A214FB3936C1C5B924B_1... done.
Writting process CB73CD141C3D4A214FB3936C1C5B924B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCB73CD141C3D4A214FB3936C1C5B924B.report
Scheduling successful
submit!!!
jobs = 88
day = 116 run = 15116060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116060/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:03:27 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 05:03:27 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:03:27 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:03:27 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:03:27 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 3401B31D02AF329AD897C897B57BF752_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3401B31D02AF329AD897C897B57BF752_1... done.
Writting process 3401B31D02AF329AD897C897B57BF752_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3401B31D02AF329AD897C897B57BF752.report
Scheduling successful
submit!!!
jobs = 89
day = 116 run = 15116061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116061/*.root.log: No such file or directory
194
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:04:56 PDT] Dataset size is 194 files
Removing files not on site LBL
[2017.09.05 05:04:57 PDT] Dataset size is 194 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:04:57 PDT] Dataset size is 194 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:04:59 PDT] Started with 194 files, current size is 194files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:04:59 PDT] Dataset size is 194 files
----------------------------------------------------
validating dataset ....passed
Writting process CB25C751559FDBFE6879B97104C43C35_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CB25C751559FDBFE6879B97104C43C35_1... done.
Writting process CB25C751559FDBFE6879B97104C43C35_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCB25C751559FDBFE6879B97104C43C35.report
Scheduling successful
submit!!!
jobs = 90
day = 116 run = 15116062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116062/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:06:15 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 05:06:15 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:06:15 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:06:16 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:06:16 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 0ADBFCA9CF2BADDEFC956637ADA031A4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0ADBFCA9CF2BADDEFC956637ADA031A4_1... done.
Writting process 0ADBFCA9CF2BADDEFC956637ADA031A4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0ADBFCA9CF2BADDEFC956637ADA031A4.report
Scheduling successful
submit!!!
jobs = 87
day = 116 run = 15116068
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15116068/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15116068/*.root.log: No such file or directory
130
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:07:37 PDT] Dataset size is 130 files
Removing files not on site LBL
[2017.09.05 05:07:37 PDT] Dataset size is 130 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:07:37 PDT] Dataset size is 130 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:07:38 PDT] Started with 130 files, current size is 130files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:07:38 PDT] Dataset size is 130 files
----------------------------------------------------
validating dataset ....passed
Writting process C729E5C769B06BF8607FC06CADE4AF71_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C729E5C769B06BF8607FC06CADE4AF71_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC729E5C769B06BF8607FC06CADE4AF71.report
Scheduling successful
submit!!!
Job submission for day 116 finished!
117
jobs = 86
day = 117 run = 15117003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117003/*.root.log: No such file or directory
163
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:08:56 PDT] Dataset size is 163 files
Removing files not on site LBL
[2017.09.05 05:08:57 PDT] Dataset size is 163 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:08:57 PDT] Dataset size is 163 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:08:57 PDT] Started with 163 files, current size is 163files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:08:57 PDT] Dataset size is 163 files
----------------------------------------------------
validating dataset ....passed
Writting process 40DA43FFDA95BB132C80F5E66E38B2B2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 40DA43FFDA95BB132C80F5E66E38B2B2_1... done.
Writting process 40DA43FFDA95BB132C80F5E66E38B2B2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched40DA43FFDA95BB132C80F5E66E38B2B2.report
Scheduling successful
submit!!!
jobs = 88
day = 117 run = 15117004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117004/*.root.log: No such file or directory
155
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:10:26 PDT] Dataset size is 155 files
Removing files not on site LBL
[2017.09.05 05:10:27 PDT] Dataset size is 155 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:10:28 PDT] Dataset size is 155 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:10:29 PDT] Started with 155 files, current size is 155files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:10:30 PDT] Dataset size is 155 files
----------------------------------------------------
validating dataset ....passed
Writting process 3C8C1DB93E2BFAA386430160D9FAEB3E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3C8C1DB93E2BFAA386430160D9FAEB3E_1... done.
Writting process 3C8C1DB93E2BFAA386430160D9FAEB3E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3C8C1DB93E2BFAA386430160D9FAEB3E.report
Scheduling successful
submit!!!
jobs = 90
day = 117 run = 15117005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117005/*.root.log: No such file or directory
92
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:13:48 PDT] Dataset size is 92 files
Removing files not on site LBL
[2017.09.05 05:13:50 PDT] Dataset size is 92 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:13:51 PDT] Dataset size is 92 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:13:52 PDT] Started with 92 files, current size is 92files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:13:53 PDT] Dataset size is 92 files
----------------------------------------------------
validating dataset ....passed
Writting process D0CDAFFFD138DDB36770729B1D7A11D2_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD0CDAFFFD138DDB36770729B1D7A11D2.report
Scheduling successful
submit!!!
jobs = 91
day = 117 run = 15117058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117058/*.root.log: No such file or directory
196
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:15:09 PDT] Dataset size is 196 files
Removing files not on site LBL
[2017.09.05 05:15:11 PDT] Dataset size is 196 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:15:11 PDT] Dataset size is 196 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:15:12 PDT] Started with 196 files, current size is 196files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:15:12 PDT] Dataset size is 196 files
----------------------------------------------------
validating dataset ....passed
Writting process 71B2D5ACA71045C75849996A65F38319_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 71B2D5ACA71045C75849996A65F38319_1... done.
Writting process 71B2D5ACA71045C75849996A65F38319_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched71B2D5ACA71045C75849996A65F38319.report
Scheduling successful
submit!!!
jobs = 94
day = 117 run = 15117059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117059/*.root.log: No such file or directory
196
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:16:29 PDT] Dataset size is 196 files
Removing files not on site LBL
[2017.09.05 05:16:31 PDT] Dataset size is 196 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:16:33 PDT] Dataset size is 196 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:16:38 PDT] Started with 196 files, current size is 196files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:16:39 PDT] Dataset size is 196 files
----------------------------------------------------
validating dataset ....passed
Writting process FC744840CB21FD37E3EFFD9015F431CA_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FC744840CB21FD37E3EFFD9015F431CA_1... done.
Writting process FC744840CB21FD37E3EFFD9015F431CA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFC744840CB21FD37E3EFFD9015F431CA.report
Scheduling successful
submit!!!
jobs = 96
day = 117 run = 15117060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117060/*.root.log: No such file or directory
210
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:17:56 PDT] Dataset size is 210 files
Removing files not on site LBL
[2017.09.05 05:17:59 PDT] Dataset size is 210 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:18:00 PDT] Dataset size is 210 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:18:00 PDT] Started with 210 files, current size is 210files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:18:00 PDT] Dataset size is 210 files
----------------------------------------------------
validating dataset ....passed
Writting process 28D2DE676568E23D036F331A9D9D4E45_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 28D2DE676568E23D036F331A9D9D4E45_2... done.
Writting process 28D2DE676568E23D036F331A9D9D4E45_1... done.
Writting process 28D2DE676568E23D036F331A9D9D4E45_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched28D2DE676568E23D036F331A9D9D4E45.report
Scheduling successful
submit!!!
jobs = 100
day = 117 run = 15117061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117061/*.root.log: No such file or directory
214
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:19:29 PDT] Dataset size is 214 files
Removing files not on site LBL
[2017.09.05 05:19:30 PDT] Dataset size is 214 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:19:31 PDT] Dataset size is 214 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:19:33 PDT] Started with 214 files, current size is 214files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:19:33 PDT] Dataset size is 214 files
----------------------------------------------------
validating dataset ....passed
Writting process A6226C8A91190285A6B80965590411D3_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A6226C8A91190285A6B80965590411D3_2... done.
Writting process A6226C8A91190285A6B80965590411D3_1... done.
Writting process A6226C8A91190285A6B80965590411D3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA6226C8A91190285A6B80965590411D3.report
Scheduling successful
submit!!!
jobs = 104
day = 117 run = 15117062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117062/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:20:47 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 05:20:47 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:20:48 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:20:48 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:20:48 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 19EFEB3FABA60029C9A2235EF7E19626_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 19EFEB3FABA60029C9A2235EF7E19626_1... done.
Writting process 19EFEB3FABA60029C9A2235EF7E19626_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched19EFEB3FABA60029C9A2235EF7E19626.report
Scheduling successful
submit!!!
jobs = 106
day = 117 run = 15117063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117063/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:22:13 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 05:22:16 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:22:17 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:22:21 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:22:23 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process E05C223608117692A84E3255581A712C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E05C223608117692A84E3255581A712C_1... done.
Writting process E05C223608117692A84E3255581A712C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE05C223608117692A84E3255581A712C.report
Scheduling successful
submit!!!
jobs = 107
day = 117 run = 15117064
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117064/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117064/*.root.log: No such file or directory
202
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:23:46 PDT] Dataset size is 202 files
Removing files not on site LBL
[2017.09.05 05:23:46 PDT] Dataset size is 202 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:23:46 PDT] Dataset size is 202 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:23:47 PDT] Started with 202 files, current size is 202files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:23:47 PDT] Dataset size is 202 files
----------------------------------------------------
validating dataset ....passed
Writting process A2A8DE9ED7893741BB6E74B03676BA84_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A2A8DE9ED7893741BB6E74B03676BA84_2... done.
Writting process A2A8DE9ED7893741BB6E74B03676BA84_1... done.
Writting process A2A8DE9ED7893741BB6E74B03676BA84_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA2A8DE9ED7893741BB6E74B03676BA84.report
Scheduling successful
submit!!!
jobs = 108
day = 117 run = 15117065
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117065/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117065/*.root.log: No such file or directory
219
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:25:00 PDT] Dataset size is 219 files
Removing files not on site LBL
[2017.09.05 05:25:00 PDT] Dataset size is 219 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:25:00 PDT] Dataset size is 219 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:25:00 PDT] Started with 219 files, current size is 219files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:25:00 PDT] Dataset size is 219 files
----------------------------------------------------
validating dataset ....passed
Writting process 3C35BCC3E01A11E91804EE116567A29B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3C35BCC3E01A11E91804EE116567A29B_2... done.
Writting process 3C35BCC3E01A11E91804EE116567A29B_1... done.
Writting process 3C35BCC3E01A11E91804EE116567A29B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3C35BCC3E01A11E91804EE116567A29B.report
Scheduling successful
submit!!!
jobs = 112
day = 117 run = 15117066
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117066/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117066/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:26:19 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.05 05:26:20 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:26:22 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:26:26 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:26:26 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process 1A2111CCFD285C62BE820C12B4B3197E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1A2111CCFD285C62BE820C12B4B3197E_2... done.
Writting process 1A2111CCFD285C62BE820C12B4B3197E_1... done.
Writting process 1A2111CCFD285C62BE820C12B4B3197E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1A2111CCFD285C62BE820C12B4B3197E.report
Scheduling successful
submit!!!
jobs = 114
day = 117 run = 15117067
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117067/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117067/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:27:43 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 05:27:43 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:27:44 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:27:45 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:27:45 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process 0D3FA2F198EB1BABAA723A0AF50932CE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0D3FA2F198EB1BABAA723A0AF50932CE_1... done.
Writting process 0D3FA2F198EB1BABAA723A0AF50932CE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0D3FA2F198EB1BABAA723A0AF50932CE.report
Scheduling successful
submit!!!
jobs = 116
day = 117 run = 15117068
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117068/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117068/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:29:00 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 05:29:01 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:29:01 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:29:03 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:29:04 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process B09379A6C6AA701FF207F8BC8CCBE4A5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B09379A6C6AA701FF207F8BC8CCBE4A5_1... done.
Writting process B09379A6C6AA701FF207F8BC8CCBE4A5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB09379A6C6AA701FF207F8BC8CCBE4A5.report
Scheduling successful
submit!!!
jobs = 117
day = 117 run = 15117069
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117069/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117069/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:30:21 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.05 05:30:22 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:30:23 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:30:25 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:30:25 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process 15A5D196E58B9A3AE82AB3977D19A22D_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 15A5D196E58B9A3AE82AB3977D19A22D_2... done.
Writting process 15A5D196E58B9A3AE82AB3977D19A22D_1... done.
Writting process 15A5D196E58B9A3AE82AB3977D19A22D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched15A5D196E58B9A3AE82AB3977D19A22D.report
Scheduling successful
submit!!!
jobs = 119
day = 117 run = 15117070
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15117070/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15117070/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:31:45 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 05:31:46 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:31:49 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:31:50 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:31:50 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process 7FA2A378F8237BF5EB88F981D9D8AD1B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7FA2A378F8237BF5EB88F981D9D8AD1B_1... done.
Writting process 7FA2A378F8237BF5EB88F981D9D8AD1B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7FA2A378F8237BF5EB88F981D9D8AD1B.report
Scheduling successful
submit!!!
Job submission for day 117 finished!
118
jobs = 119
day = 118 run = 15118015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118015/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:33:07 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 05:33:08 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:33:08 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:33:10 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:33:10 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 641BA9A9072CCD263183EF3007BC7FFD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 641BA9A9072CCD263183EF3007BC7FFD_1... done.
Writting process 641BA9A9072CCD263183EF3007BC7FFD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched641BA9A9072CCD263183EF3007BC7FFD.report
Scheduling successful
submit!!!
jobs = 117
day = 118 run = 15118016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118016/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:34:29 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 05:34:29 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:34:29 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:34:29 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:34:29 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process A8FA0FADDB7D6CE1D55A7CC0D8C108C8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A8FA0FADDB7D6CE1D55A7CC0D8C108C8_1... done.
Writting process A8FA0FADDB7D6CE1D55A7CC0D8C108C8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA8FA0FADDB7D6CE1D55A7CC0D8C108C8.report
Scheduling successful
submit!!!
jobs = 117
day = 118 run = 15118017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118017/*.root.log: No such file or directory
192
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:35:45 PDT] Dataset size is 192 files
Removing files not on site LBL
[2017.09.05 05:35:46 PDT] Dataset size is 192 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:35:46 PDT] Dataset size is 192 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:35:49 PDT] Started with 192 files, current size is 192files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:35:49 PDT] Dataset size is 192 files
----------------------------------------------------
validating dataset ....passed
Writting process 9005A1A772B37ABDB452FA34313A8E99_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9005A1A772B37ABDB452FA34313A8E99_1... done.
Writting process 9005A1A772B37ABDB452FA34313A8E99_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9005A1A772B37ABDB452FA34313A8E99.report
Scheduling successful
submit!!!
jobs = 120
day = 118 run = 15118018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118018/*.root.log: No such file or directory
218
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:37:07 PDT] Dataset size is 218 files
Removing files not on site LBL
[2017.09.05 05:37:08 PDT] Dataset size is 218 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:37:10 PDT] Dataset size is 218 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:37:13 PDT] Started with 218 files, current size is 218files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:37:14 PDT] Dataset size is 218 files
----------------------------------------------------
validating dataset ....passed
Writting process 3F0EC09908CF88C87193E50A56CB0455_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3F0EC09908CF88C87193E50A56CB0455_2... done.
Writting process 3F0EC09908CF88C87193E50A56CB0455_1... done.
Writting process 3F0EC09908CF88C87193E50A56CB0455_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3F0EC09908CF88C87193E50A56CB0455.report
Scheduling successful
submit!!!
jobs = 123
day = 118 run = 15118019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118019/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:38:36 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 05:38:38 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:38:39 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:38:42 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:38:42 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process B2E58A59E7C07601765147D2031D1594_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B2E58A59E7C07601765147D2031D1594_1... done.
Writting process B2E58A59E7C07601765147D2031D1594_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB2E58A59E7C07601765147D2031D1594.report
Scheduling successful
submit!!!
jobs = 125
day = 118 run = 15118020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118020/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:39:59 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 05:40:01 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:40:02 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:40:04 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:40:05 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 5B6790D659183A8B1774B93C9D4675F0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5B6790D659183A8B1774B93C9D4675F0_1... done.
Writting process 5B6790D659183A8B1774B93C9D4675F0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5B6790D659183A8B1774B93C9D4675F0.report
Scheduling successful
submit!!!
jobs = 126
day = 118 run = 15118021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118021/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:41:23 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 05:41:23 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:41:24 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:41:25 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:41:25 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process ECD3B72F8A05B45B29C9D981384F635E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ECD3B72F8A05B45B29C9D981384F635E_1... done.
Writting process ECD3B72F8A05B45B29C9D981384F635E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedECD3B72F8A05B45B29C9D981384F635E.report
Scheduling successful
submit!!!
jobs = 125
day = 118 run = 15118022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118022/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:43:02 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 05:43:03 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:43:03 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:43:05 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:43:05 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 9927DE23603FCDBBEE1CB45F42680941_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9927DE23603FCDBBEE1CB45F42680941_1... done.
Writting process 9927DE23603FCDBBEE1CB45F42680941_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9927DE23603FCDBBEE1CB45F42680941.report
Scheduling successful
submit!!!
jobs = 126
day = 118 run = 15118023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118023/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:44:19 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 05:44:21 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:44:21 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:44:22 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:44:23 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 050CA025F3D75C38F604DB4F45FCB8F0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 050CA025F3D75C38F604DB4F45FCB8F0_1... done.
Writting process 050CA025F3D75C38F604DB4F45FCB8F0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched050CA025F3D75C38F604DB4F45FCB8F0.report
Scheduling successful
submit!!!
jobs = 127
day = 118 run = 15118024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118024/*.root.log: No such file or directory
83
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:45:37 PDT] Dataset size is 83 files
Removing files not on site LBL
[2017.09.05 05:45:39 PDT] Dataset size is 83 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:45:40 PDT] Dataset size is 83 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:45:42 PDT] Started with 83 files, current size is 83files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:45:44 PDT] Dataset size is 83 files
----------------------------------------------------
validating dataset ....passed
Writting process F00D90E26E33009596D8ACDBCFCD4D74_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF00D90E26E33009596D8ACDBCFCD4D74.report
Scheduling successful
submit!!!
jobs = 127
day = 118 run = 15118064
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118064/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118064/*.root.log: No such file or directory
113
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:47:02 PDT] Dataset size is 113 files
Removing files not on site LBL
[2017.09.05 05:47:03 PDT] Dataset size is 113 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:47:04 PDT] Dataset size is 113 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:47:06 PDT] Started with 113 files, current size is 113files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:47:07 PDT] Dataset size is 113 files
----------------------------------------------------
validating dataset ....passed
Writting process 2EE6C90EF9826ED0BD0548B05D170CD8_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2EE6C90EF9826ED0BD0548B05D170CD8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2EE6C90EF9826ED0BD0548B05D170CD8.report
Scheduling successful
submit!!!
jobs = 128
day = 118 run = 15118065
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118065/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118065/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:48:21 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 05:48:22 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:48:22 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:48:24 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:48:25 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process 1DAC04E87DF6A51338B87ACBF84D5EB5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1DAC04E87DF6A51338B87ACBF84D5EB5_1... done.
Writting process 1DAC04E87DF6A51338B87ACBF84D5EB5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1DAC04E87DF6A51338B87ACBF84D5EB5.report
Scheduling successful
submit!!!
jobs = 129
day = 118 run = 15118066
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15118066/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15118066/*.root.log: No such file or directory
196
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:49:41 PDT] Dataset size is 196 files
Removing files not on site LBL
[2017.09.05 05:49:42 PDT] Dataset size is 196 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:49:43 PDT] Dataset size is 196 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:49:47 PDT] Started with 196 files, current size is 196files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:49:48 PDT] Dataset size is 196 files
----------------------------------------------------
validating dataset ....passed
Writting process AD39F710DEB896D8501495D32C0FC956_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AD39F710DEB896D8501495D32C0FC956_1... done.
Writting process AD39F710DEB896D8501495D32C0FC956_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD39F710DEB896D8501495D32C0FC956.report
Scheduling successful
submit!!!
Job submission for day 118 finished!
119
jobs = 127
day = 119 run = 15119008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119008/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:51:15 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 05:51:15 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:51:16 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:51:17 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:51:18 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 071CF6F7DF58BEBA5AA65AFC706EC09A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 071CF6F7DF58BEBA5AA65AFC706EC09A_1... done.
Writting process 071CF6F7DF58BEBA5AA65AFC706EC09A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched071CF6F7DF58BEBA5AA65AFC706EC09A.report
Scheduling successful
submit!!!
jobs = 126
day = 119 run = 15119009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119009/*.root.log: No such file or directory
123
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:52:35 PDT] Dataset size is 123 files
Removing files not on site LBL
[2017.09.05 05:52:37 PDT] Dataset size is 123 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:52:38 PDT] Dataset size is 123 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:52:42 PDT] Started with 123 files, current size is 123files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:52:43 PDT] Dataset size is 123 files
----------------------------------------------------
validating dataset ....passed
Writting process 7275947B841A22F6BCF14D111B69078B_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7275947B841A22F6BCF14D111B69078B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7275947B841A22F6BCF14D111B69078B.report
Scheduling successful
submit!!!
jobs = 126
day = 119 run = 15119011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119011/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:54:03 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 05:54:05 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:54:07 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:54:10 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:54:11 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 02EAE9B14FF57E519835EDE67FB222DF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 02EAE9B14FF57E519835EDE67FB222DF_1... done.
Writting process 02EAE9B14FF57E519835EDE67FB222DF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched02EAE9B14FF57E519835EDE67FB222DF.report
Scheduling successful
submit!!!
jobs = 124
day = 119 run = 15119012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119012/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:55:27 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 05:55:28 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:55:29 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:55:31 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:55:31 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process EFE474F66C51233E221AA8FCBFA78637_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EFE474F66C51233E221AA8FCBFA78637_1... done.
Writting process EFE474F66C51233E221AA8FCBFA78637_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEFE474F66C51233E221AA8FCBFA78637.report
Scheduling successful
submit!!!
jobs = 123
day = 119 run = 15119013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119013/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:56:47 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 05:56:47 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:56:47 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:56:47 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:56:47 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process C5DA9BC29C1F79C39175333FD220879C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C5DA9BC29C1F79C39175333FD220879C_1... done.
Writting process C5DA9BC29C1F79C39175333FD220879C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC5DA9BC29C1F79C39175333FD220879C.report
Scheduling successful
submit!!!
jobs = 122
day = 119 run = 15119014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119014/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:58:00 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 05:58:00 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:58:01 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:58:02 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:58:02 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 65CFD50BD23EBD90B2A61E027727F5F7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 65CFD50BD23EBD90B2A61E027727F5F7_1... done.
Writting process 65CFD50BD23EBD90B2A61E027727F5F7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched65CFD50BD23EBD90B2A61E027727F5F7.report
Scheduling successful
submit!!!
jobs = 123
day = 119 run = 15119015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119015/*.root.log: No such file or directory
78
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 05:59:13 PDT] Dataset size is 78 files
Removing files not on site LBL
[2017.09.05 05:59:14 PDT] Dataset size is 78 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 05:59:15 PDT] Dataset size is 78 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 05:59:16 PDT] Started with 78 files, current size is 78files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 05:59:18 PDT] Dataset size is 78 files
----------------------------------------------------
validating dataset ....passed
Writting process A64D89523ED5F9CDD51940CF21388BB3_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA64D89523ED5F9CDD51940CF21388BB3.report
Scheduling successful
submit!!!
jobs = 123
day = 119 run = 15119025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119025/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:00:32 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.05 06:00:33 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:00:34 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:00:36 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:00:37 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process 8A67E59AEDAAEAB777A98673D6850351_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8A67E59AEDAAEAB777A98673D6850351_2... done.
Writting process 8A67E59AEDAAEAB777A98673D6850351_1... done.
Writting process 8A67E59AEDAAEAB777A98673D6850351_0... done.
Submitting array... done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8A67E59AEDAAEAB777A98673D6850351.report
Scheduling successful
submit!!!
jobs = 125
day = 119 run = 15119026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119026/*.root.log: No such file or directory
220
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:01:54 PDT] Dataset size is 220 files
Removing files not on site LBL
[2017.09.05 06:01:54 PDT] Dataset size is 220 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:01:55 PDT] Dataset size is 220 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:01:55 PDT] Started with 220 files, current size is 220files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:01:56 PDT] Dataset size is 220 files
----------------------------------------------------
validating dataset ....passed
Writting process FFDEE03858E43BD6CC6D16439B78C37A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FFDEE03858E43BD6CC6D16439B78C37A_2... done.
Writting process FFDEE03858E43BD6CC6D16439B78C37A_1... done.
Writting process FFDEE03858E43BD6CC6D16439B78C37A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFFDEE03858E43BD6CC6D16439B78C37A.report
Scheduling successful
submit!!!
jobs = 128
day = 119 run = 15119027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119027/*.root.log: No such file or directory
236
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:03:16 PDT] Dataset size is 236 files
Removing files not on site LBL
[2017.09.05 06:03:17 PDT] Dataset size is 236 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:03:17 PDT] Dataset size is 236 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:03:18 PDT] Started with 236 files, current size is 236files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:03:18 PDT] Dataset size is 236 files
----------------------------------------------------
validating dataset ....passed
Writting process E0408543A8D77FF5A2BC23D8591F257E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E0408543A8D77FF5A2BC23D8591F257E_2... done.
Writting process E0408543A8D77FF5A2BC23D8591F257E_1... done.
Writting process E0408543A8D77FF5A2BC23D8591F257E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE0408543A8D77FF5A2BC23D8591F257E.report
Scheduling successful
submit!!!
jobs = 130
day = 119 run = 15119028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119028/*.root.log: No such file or directory
60
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:04:30 PDT] Dataset size is 60 files
Removing files not on site LBL
[2017.09.05 06:04:30 PDT] Dataset size is 60 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:04:30 PDT] Dataset size is 60 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:04:31 PDT] Started with 60 files, current size is 60files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:04:31 PDT] Dataset size is 60 files
----------------------------------------------------
validating dataset ....passed
Writting process E0C154D3E617F9CA10EC6F0307401205_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE0C154D3E617F9CA10EC6F0307401205.report
Scheduling successful
submit!!!
jobs = 130
day = 119 run = 15119029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119029/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:05:51 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 06:05:51 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:05:51 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:05:51 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:05:51 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process B09A98243F618A864DAED1A3F4FE0E10_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B09A98243F618A864DAED1A3F4FE0E10_1... done.
Writting process B09A98243F618A864DAED1A3F4FE0E10_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB09A98243F618A864DAED1A3F4FE0E10.report
Scheduling successful
submit!!!
jobs = 131
day = 119 run = 15119031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119031/*.root.log: No such file or directory
236
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:07:15 PDT] Dataset size is 236 files
Removing files not on site LBL
[2017.09.05 06:07:17 PDT] Dataset size is 236 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:07:18 PDT] Dataset size is 236 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:07:19 PDT] Started with 236 files, current size is 236files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:07:19 PDT] Dataset size is 236 files
----------------------------------------------------
validating dataset ....passed
Writting process BF15FAF1CD12164F439972E2597825B9_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BF15FAF1CD12164F439972E2597825B9_2... done.
Writting process BF15FAF1CD12164F439972E2597825B9_1... done.
Writting process BF15FAF1CD12164F439972E2597825B9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBF15FAF1CD12164F439972E2597825B9.report
Scheduling successful
submit!!!
jobs = 135
day = 119 run = 15119034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119034/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:08:48 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 06:08:48 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:08:48 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:08:48 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:08:49 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 3839555B328E97C2699376E8AAE3C9B5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3839555B328E97C2699376E8AAE3C9B5_1... done.
Writting process 3839555B328E97C2699376E8AAE3C9B5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3839555B328E97C2699376E8AAE3C9B5.report
Scheduling successful
submit!!!
jobs = 135
day = 119 run = 15119035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119035/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:10:39 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 06:10:40 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:10:41 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:10:41 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:10:41 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process F9F3A32BB3CF7226AC3B082A41725D39_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F9F3A32BB3CF7226AC3B082A41725D39_1... done.
Writting process F9F3A32BB3CF7226AC3B082A41725D39_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF9F3A32BB3CF7226AC3B082A41725D39.report
Scheduling successful
submit!!!
jobs = 134
day = 119 run = 15119036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119036/*.root.log: No such file or directory
157
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:12:03 PDT] Dataset size is 157 files
Removing files not on site LBL
[2017.09.05 06:12:05 PDT] Dataset size is 157 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:12:06 PDT] Dataset size is 157 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:12:09 PDT] Started with 157 files, current size is 157files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:12:10 PDT] Dataset size is 157 files
----------------------------------------------------
validating dataset ....passed
Writting process 59AB6348CD0BB892638C04B5E8B9D087_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 59AB6348CD0BB892638C04B5E8B9D087_1... done.
Writting process 59AB6348CD0BB892638C04B5E8B9D087_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched59AB6348CD0BB892638C04B5E8B9D087.report
Scheduling successful
submit!!!
jobs = 136
day = 119 run = 15119057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119057/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:13:28 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 06:13:29 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:13:30 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:13:31 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:13:32 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 1051403F841D80DD13132D45860C3A21_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1051403F841D80DD13132D45860C3A21_1... done.
Writting process 1051403F841D80DD13132D45860C3A21_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1051403F841D80DD13132D45860C3A21.report
Scheduling successful
submit!!!
jobs = 138
day = 119 run = 15119058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119058/*.root.log: No such file or directory
198
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:14:50 PDT] Dataset size is 198 files
Removing files not on site LBL
[2017.09.05 06:14:50 PDT] Dataset size is 198 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:14:50 PDT] Dataset size is 198 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:14:50 PDT] Started with 198 files, current size is 198files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:14:50 PDT] Dataset size is 198 files
----------------------------------------------------
validating dataset ....passed
Writting process 721E117A91A174E1BF4311DD2F01CFA3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 721E117A91A174E1BF4311DD2F01CFA3_1... done.
Writting process 721E117A91A174E1BF4311DD2F01CFA3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched721E117A91A174E1BF4311DD2F01CFA3.report
Scheduling successful
submit!!!
jobs = 139
day = 119 run = 15119059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119059/*.root.log: No such file or directory
54
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:16:01 PDT] Dataset size is 54 files
Removing files not on site LBL
[2017.09.05 06:16:02 PDT] Dataset size is 54 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:16:03 PDT] Dataset size is 54 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:16:03 PDT] Started with 54 files, current size is 54files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:16:04 PDT] Dataset size is 54 files
----------------------------------------------------
validating dataset ....passed
Writting process C16D218F2CFAD24799A46B6AFD0B8991_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC16D218F2CFAD24799A46B6AFD0B8991.report
Scheduling successful
submit!!!
jobs = 134
day = 119 run = 15119063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119063/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:17:17 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.05 06:17:17 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:17:17 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:17:18 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:17:18 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process D60A7ED72C8740EC2C9C6D1A299E96FD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D60A7ED72C8740EC2C9C6D1A299E96FD_2... done.
Writting process D60A7ED72C8740EC2C9C6D1A299E96FD_1... done.
Writting process D60A7ED72C8740EC2C9C6D1A299E96FD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD60A7ED72C8740EC2C9C6D1A299E96FD.report
Scheduling successful
submit!!!
jobs = 135
day = 119 run = 15119064
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119064/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119064/*.root.log: No such file or directory
140
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:18:34 PDT] Dataset size is 140 files
Removing files not on site LBL
[2017.09.05 06:18:35 PDT] Dataset size is 140 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:18:35 PDT] Dataset size is 140 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:18:36 PDT] Started with 140 files, current size is 140files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:18:36 PDT] Dataset size is 140 files
----------------------------------------------------
validating dataset ....passed
Writting process 335C8EA37A69CBA2F270FAEC930641F9_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 335C8EA37A69CBA2F270FAEC930641F9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched335C8EA37A69CBA2F270FAEC930641F9.report
Scheduling successful
submit!!!
jobs = 131
day = 119 run = 15119065
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15119065/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15119065/*.root.log: No such file or directory
192
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:19:49 PDT] Dataset size is 192 files
Removing files not on site LBL
[2017.09.05 06:19:49 PDT] Dataset size is 192 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:19:50 PDT] Dataset size is 192 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:19:51 PDT] Started with 192 files, current size is 192files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:19:52 PDT] Dataset size is 192 files
----------------------------------------------------
validating dataset ....passed
Writting process 4F3FB32DF3998FB47257770969CB085C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4F3FB32DF3998FB47257770969CB085C_1... done.
Writting process 4F3FB32DF3998FB47257770969CB085C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4F3FB32DF3998FB47257770969CB085C.report
Scheduling successful
submit!!!
Job submission for day 119 finished!
120
jobs = 130
day = 120 run = 15120001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120001/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:21:04 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 06:21:04 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:21:05 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:21:06 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:21:06 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process B03576037C055FAA6C5F496BE26EA7E7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B03576037C055FAA6C5F496BE26EA7E7_1... done.
Writting process B03576037C055FAA6C5F496BE26EA7E7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB03576037C055FAA6C5F496BE26EA7E7.report
Scheduling successful
submit!!!
jobs = 128
day = 120 run = 15120002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120002/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:22:20 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 06:22:21 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:22:22 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:22:23 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:22:24 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process 298F98F38904B30BC9790036FC2BF152_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 298F98F38904B30BC9790036FC2BF152_1... done.
Writting process 298F98F38904B30BC9790036FC2BF152_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched298F98F38904B30BC9790036FC2BF152.report
Scheduling successful
submit!!!
jobs = 129
day = 120 run = 15120004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120004/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:24:08 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 06:24:10 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:24:13 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:24:13 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:24:13 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process 7C4EA3F797CE504954A6E8FB7C164585_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7C4EA3F797CE504954A6E8FB7C164585_1... done.
Writting process 7C4EA3F797CE504954A6E8FB7C164585_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7C4EA3F797CE504954A6E8FB7C164585.report
Scheduling successful
submit!!!
jobs = 131
day = 120 run = 15120005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120005/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:25:32 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 06:25:32 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:25:32 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:25:34 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:25:34 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 45F986FE99C7A3074EDAF81B2EBE577F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 45F986FE99C7A3074EDAF81B2EBE577F_1... done.
Writting process 45F986FE99C7A3074EDAF81B2EBE577F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched45F986FE99C7A3074EDAF81B2EBE577F.report
Scheduling successful
submit!!!
jobs = 131
day = 120 run = 15120006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120006/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:26:54 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 06:26:54 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:26:57 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:26:58 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:26:58 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process AFF4501DB8BF2A1141E1C489CE8F896A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AFF4501DB8BF2A1141E1C489CE8F896A_1... done.
Writting process AFF4501DB8BF2A1141E1C489CE8F896A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAFF4501DB8BF2A1141E1C489CE8F896A.report
Scheduling successful
submit!!!
jobs = 129
day = 120 run = 15120007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120007/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:28:14 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 06:28:15 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:28:17 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:28:18 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:28:18 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process E43AF40829FCFE2641193BAC7B6DC82C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E43AF40829FCFE2641193BAC7B6DC82C_1... done.
Writting process E43AF40829FCFE2641193BAC7B6DC82C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE43AF40829FCFE2641193BAC7B6DC82C.report
Scheduling successful
submit!!!
jobs = 129
day = 120 run = 15120008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120008/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:29:31 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 06:29:32 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:29:32 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:29:32 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:29:35 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process F41922B28A7934A4C9054F40CC6FD451_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F41922B28A7934A4C9054F40CC6FD451_1... done.
Writting process F41922B28A7934A4C9054F40CC6FD451_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF41922B28A7934A4C9054F40CC6FD451.report
Scheduling successful
submit!!!
jobs = 129
day = 120 run = 15120009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120009/*.root.log: No such file or directory
161
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:30:48 PDT] Dataset size is 161 files
Removing files not on site LBL
[2017.09.05 06:30:49 PDT] Dataset size is 161 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:30:50 PDT] Dataset size is 161 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:30:51 PDT] Started with 161 files, current size is 161files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:30:52 PDT] Dataset size is 161 files
----------------------------------------------------
validating dataset ....passed
Writting process 9F75327E661BB45B77E5265667594662_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9F75327E661BB45B77E5265667594662_1... done.
Writting process 9F75327E661BB45B77E5265667594662_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9F75327E661BB45B77E5265667594662.report
Scheduling successful
submit!!!
jobs = 130
day = 120 run = 15120011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120011/*.root.log: No such file or directory
80
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:32:06 PDT] Dataset size is 80 files
Removing files not on site LBL
[2017.09.05 06:32:07 PDT] Dataset size is 80 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:32:08 PDT] Dataset size is 80 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:32:10 PDT] Started with 80 files, current size is 80files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:32:11 PDT] Dataset size is 80 files
----------------------------------------------------
validating dataset ....passed
Writting process 14F81AFE370CFACA1B2FCB45C72BBABC_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched14F81AFE370CFACA1B2FCB45C72BBABC.report
Scheduling successful
submit!!!
jobs = 127
day = 120 run = 15120117
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15120117/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15120117/*.root.log: No such file or directory
96
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:33:21 PDT] Dataset size is 96 files
Removing files not on site LBL
[2017.09.05 06:33:22 PDT] Dataset size is 96 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:33:22 PDT] Dataset size is 96 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:33:23 PDT] Started with 96 files, current size is 96files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:33:23 PDT] Dataset size is 96 files
----------------------------------------------------
validating dataset ....passed
Writting process B036D60442F6AB621BD0BF7FCCCD4D59_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB036D60442F6AB621BD0BF7FCCCD4D59.report
Scheduling successful
submit!!!
Job submission for day 120 finished!
121
jobs = 123
day = 121 run = 15121001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121001/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:34:47 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 06:34:48 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:34:49 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:34:52 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:34:54 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 2FF8640F89E3A59E30C34FFC72AEB441_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2FF8640F89E3A59E30C34FFC72AEB441_1... done.
Writting process 2FF8640F89E3A59E30C34FFC72AEB441_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2FF8640F89E3A59E30C34FFC72AEB441.report
Scheduling successful
submit!!!
jobs = 124
day = 121 run = 15121002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121002/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:36:13 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 06:36:14 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:36:15 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:36:18 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:36:19 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 5DB6632ACEDD9174381DC1EDB4BC340B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5DB6632ACEDD9174381DC1EDB4BC340B_1... done.
Writting process 5DB6632ACEDD9174381DC1EDB4BC340B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5DB6632ACEDD9174381DC1EDB4BC340B.report
Scheduling successful
submit!!!
jobs = 126
day = 121 run = 15121003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121003/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:37:34 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 06:37:35 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:37:36 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:37:37 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:37:37 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process C24D4A86431B9D60DD29A3663F20F71A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C24D4A86431B9D60DD29A3663F20F71A_1... done.
Writting process C24D4A86431B9D60DD29A3663F20F71A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC24D4A86431B9D60DD29A3663F20F71A.report
Scheduling successful
submit!!!
jobs = 127
day = 121 run = 15121004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121004/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:38:50 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 06:38:50 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:38:50 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:38:50 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:38:50 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 584437029D06293E698979E9C2B60951_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 584437029D06293E698979E9C2B60951_1... done.
Writting process 584437029D06293E698979E9C2B60951_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched584437029D06293E698979E9C2B60951.report
Scheduling successful
submit!!!
jobs = 126
day = 121 run = 15121005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121005/*.root.log: No such file or directory
62
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:40:06 PDT] Dataset size is 62 files
Removing files not on site LBL
[2017.09.05 06:40:06 PDT] Dataset size is 62 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:40:07 PDT] Dataset size is 62 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:40:08 PDT] Started with 62 files, current size is 62files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:40:09 PDT] Dataset size is 62 files
----------------------------------------------------
validating dataset ....passed
Writting process F62D9185B644250A505877DD228B66B0_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF62D9185B644250A505877DD228B66B0.report
Scheduling successful
submit!!!
jobs = 124
day = 121 run = 15121006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121006/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:41:26 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 06:41:27 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:41:28 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:41:28 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:41:29 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process A82358019D68291D90A228A1F993A36A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A82358019D68291D90A228A1F993A36A_1... done.
Writting process A82358019D68291D90A228A1F993A36A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA82358019D68291D90A228A1F993A36A.report
Scheduling successful
submit!!!
jobs = 125
day = 121 run = 15121007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121007/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:42:52 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 06:42:53 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:42:53 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:42:55 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:42:56 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process 7327F5D664BA5FC1F68F3B4F979E55F8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7327F5D664BA5FC1F68F3B4F979E55F8_1... done.
Writting process 7327F5D664BA5FC1F68F3B4F979E55F8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7327F5D664BA5FC1F68F3B4F979E55F8.report
Scheduling successful
submit!!!
jobs = 127
day = 121 run = 15121008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121008/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:44:18 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 06:44:18 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:44:19 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:44:19 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:44:19 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process C2D2F54F3F3C1FFA7421453C8CA5A78A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C2D2F54F3F3C1FFA7421453C8CA5A78A_1... done.
Writting process C2D2F54F3F3C1FFA7421453C8CA5A78A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC2D2F54F3F3C1FFA7421453C8CA5A78A.report
Scheduling successful
submit!!!
jobs = 127
day = 121 run = 15121009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121009/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:45:35 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 06:45:36 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:45:36 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:45:36 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:45:36 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process C146BBA2302ECB604B5160856154CB1B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C146BBA2302ECB604B5160856154CB1B_1... done.
Writting process C146BBA2302ECB604B5160856154CB1B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC146BBA2302ECB604B5160856154CB1B.report
Scheduling successful
submit!!!
jobs = 130
day = 121 run = 15121012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121012/*.root.log: No such file or directory
163
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:46:49 PDT] Dataset size is 163 files
Removing files not on site LBL
[2017.09.05 06:46:49 PDT] Dataset size is 163 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:46:49 PDT] Dataset size is 163 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:46:50 PDT] Started with 163 files, current size is 163files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:46:50 PDT] Dataset size is 163 files
----------------------------------------------------
validating dataset ....passed
Writting process 2F9844D45B179A69B39CC721C50360D8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2F9844D45B179A69B39CC721C50360D8_1... done.
Writting process 2F9844D45B179A69B39CC721C50360D8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2F9844D45B179A69B39CC721C50360D8.report
Scheduling successful
submit!!!
jobs = 129
day = 121 run = 15121013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121013/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:48:04 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 06:48:05 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:48:06 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:48:07 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:48:08 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process BB2661AB1D0F8B56DB98EDF4279BD429_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BB2661AB1D0F8B56DB98EDF4279BD429_1... done.
Writting process BB2661AB1D0F8B56DB98EDF4279BD429_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBB2661AB1D0F8B56DB98EDF4279BD429.report
Scheduling successful
submit!!!
jobs = 128
day = 121 run = 15121015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121015/*.root.log: No such file or directory
133
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:49:33 PDT] Dataset size is 133 files
Removing files not on site LBL
[2017.09.05 06:49:34 PDT] Dataset size is 133 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:49:36 PDT] Dataset size is 133 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:49:41 PDT] Started with 133 files, current size is 133files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:49:42 PDT] Dataset size is 133 files
----------------------------------------------------
validating dataset ....passed
Writting process 7E25E9B7530B0A02EE27F171E207FCE0_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7E25E9B7530B0A02EE27F171E207FCE0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7E25E9B7530B0A02EE27F171E207FCE0.report
Scheduling successful
submit!!!
jobs = 128
day = 121 run = 15121016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121016/*.root.log: No such file or directory
150
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:51:00 PDT] Dataset size is 150 files
Removing files not on site LBL
[2017.09.05 06:51:01 PDT] Dataset size is 150 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:51:01 PDT] Dataset size is 150 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:51:03 PDT] Started with 150 files, current size is 150files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:51:04 PDT] Dataset size is 150 files
----------------------------------------------------
validating dataset ....passed
Writting process B033D66FCF361E0A591330D94464CC07_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B033D66FCF361E0A591330D94464CC07_1... done.
Writting process B033D66FCF361E0A591330D94464CC07_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB033D66FCF361E0A591330D94464CC07.report
Scheduling successful
submit!!!
jobs = 130
day = 121 run = 15121017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121017/*.root.log: No such file or directory
157
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:52:21 PDT] Dataset size is 157 files
Removing files not on site LBL
[2017.09.05 06:52:24 PDT] Dataset size is 157 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:52:27 PDT] Dataset size is 157 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:52:30 PDT] Started with 157 files, current size is 157files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:52:30 PDT] Dataset size is 157 files
----------------------------------------------------
validating dataset ....passed
Writting process 31E00782F44A9BD32356CAD29B6D0BD7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 31E00782F44A9BD32356CAD29B6D0BD7_1... done.
Writting process 31E00782F44A9BD32356CAD29B6D0BD7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched31E00782F44A9BD32356CAD29B6D0BD7.report
Scheduling successful
submit!!!
jobs = 130
day = 121 run = 15121018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121018/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:53:45 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 06:53:45 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:53:45 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:53:45 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:53:45 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 561B079E1D5D479461708DCE72AF61CA_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 561B079E1D5D479461708DCE72AF61CA_1... done.
Writting process 561B079E1D5D479461708DCE72AF61CA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched561B079E1D5D479461708DCE72AF61CA.report
Scheduling successful
submit!!!
jobs = 131
day = 121 run = 15121062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121062/*.root.log: No such file or directory
2
2 2
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:54:52 PDT] Dataset size is 2 files
Removing files not on site LBL
[2017.09.05 06:54:53 PDT] Dataset size is 2 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:54:55 PDT] Dataset size is 2 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:54:58 PDT] Started with 2 files, current size is 2files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=2 ,maxSize=2 )
[2017.09.05 06:54:58 PDT] Dataset size is 2 files
----------------------------------------------------
validating dataset ....passed
Writting process A9E6D1D731EC38A020ED300435A1AE0C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA9E6D1D731EC38A020ED300435A1AE0C.report
Scheduling successful
submit!!!
jobs = 128
day = 121 run = 15121063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121063/*.root.log: No such file or directory
153
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:56:18 PDT] Dataset size is 153 files
Removing files not on site LBL
[2017.09.05 06:56:19 PDT] Dataset size is 153 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:56:19 PDT] Dataset size is 153 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:56:21 PDT] Started with 153 files, current size is 153files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:56:22 PDT] Dataset size is 153 files
----------------------------------------------------
validating dataset ....passed
Writting process E4707821EA4FE82DC7A838E3DDF88077_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E4707821EA4FE82DC7A838E3DDF88077_1... done.
Writting process E4707821EA4FE82DC7A838E3DDF88077_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE4707821EA4FE82DC7A838E3DDF88077.report
Scheduling successful
submit!!!
jobs = 125
day = 121 run = 15121065
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121065/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121065/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:57:40 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 06:57:41 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:57:41 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:57:42 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:57:43 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 3B6FF5A58803C613936C85F10CF792BE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3B6FF5A58803C613936C85F10CF792BE_1... done.
Writting process 3B6FF5A58803C613936C85F10CF792BE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3B6FF5A58803C613936C85F10CF792BE.report
Scheduling successful
submit!!!
jobs = 125
day = 121 run = 15121066
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121066/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121066/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 06:58:58 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 06:58:59 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 06:58:59 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 06:59:00 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 06:59:01 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process A13A5DAB7C4F4F8C4550132105B539D2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A13A5DAB7C4F4F8C4550132105B539D2_1... done.
Writting process A13A5DAB7C4F4F8C4550132105B539D2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA13A5DAB7C4F4F8C4550132105B539D2.report
Scheduling successful
submit!!!
jobs = 122
day = 121 run = 15121067
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121067/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121067/*.root.log: No such file or directory
154
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:00:17 PDT] Dataset size is 154 files
Removing files not on site LBL
[2017.09.05 07:00:20 PDT] Dataset size is 154 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:00:22 PDT] Dataset size is 154 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:00:24 PDT] Started with 154 files, current size is 154files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:00:25 PDT] Dataset size is 154 files
----------------------------------------------------
validating dataset ....passed
Writting process 2489905EE51CFCE2AED75DE8B0D5457B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2489905EE51CFCE2AED75DE8B0D5457B_1... done.
Writting process 2489905EE51CFCE2AED75DE8B0D5457B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2489905EE51CFCE2AED75DE8B0D5457B.report
Scheduling successful
submit!!!
jobs = 117
day = 121 run = 15121068
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121068/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121068/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:01:48 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 07:01:49 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:01:50 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:01:52 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:01:54 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process 1D9117141EA9EBDF0C97346E3F025592_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1D9117141EA9EBDF0C97346E3F025592_1... done.
Writting process 1D9117141EA9EBDF0C97346E3F025592_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1D9117141EA9EBDF0C97346E3F025592.report
Scheduling successful
submit!!!
jobs = 115
day = 121 run = 15121070
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121070/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121070/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:03:12 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 07:03:13 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:03:13 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:03:13 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:03:13 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process D3D53BF226E15815F0E2C53FB07D30B6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D3D53BF226E15815F0E2C53FB07D30B6_1... done.
Writting process D3D53BF226E15815F0E2C53FB07D30B6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD3D53BF226E15815F0E2C53FB07D30B6.report
Scheduling successful
submit!!!
jobs = 114
day = 121 run = 15121071
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121071/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121071/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:04:27 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 07:04:28 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:04:30 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:04:35 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:04:36 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process 5AF59315D5EFF05D2713998F433AF8D6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5AF59315D5EFF05D2713998F433AF8D6_1... done.
Writting process 5AF59315D5EFF05D2713998F433AF8D6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5AF59315D5EFF05D2713998F433AF8D6.report
Scheduling successful
submit!!!
jobs = 121
day = 121 run = 15121072
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121072/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121072/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:06:00 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 07:06:01 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:06:03 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:06:07 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:06:09 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 4C52B2655EC7F7DE1699B108FE07150C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4C52B2655EC7F7DE1699B108FE07150C_1... done.
Writting process 4C52B2655EC7F7DE1699B108FE07150C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4C52B2655EC7F7DE1699B108FE07150C.report
Scheduling successful
submit!!!
jobs = 125
day = 121 run = 15121076
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121076/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121076/*.root.log: No such file or directory
202
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:07:36 PDT] Dataset size is 202 files
Removing files not on site LBL
[2017.09.05 07:07:38 PDT] Dataset size is 202 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:07:39 PDT] Dataset size is 202 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:07:43 PDT] Started with 202 files, current size is 202files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:07:44 PDT] Dataset size is 202 files
----------------------------------------------------
validating dataset ....passed
Writting process 7DF4B50523420FD213B802D6496F123C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7DF4B50523420FD213B802D6496F123C_2... done.
Writting process 7DF4B50523420FD213B802D6496F123C_1... done.
Writting process 7DF4B50523420FD213B802D6496F123C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7DF4B50523420FD213B802D6496F123C.report
Scheduling successful
submit!!!
jobs = 129
day = 121 run = 15121077
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121077/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121077/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:09:07 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 07:09:07 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:09:08 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:09:09 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:09:10 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process 3251CAE82D5110467926B72B47E96E38_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3251CAE82D5110467926B72B47E96E38_1... done.
Writting process 3251CAE82D5110467926B72B47E96E38_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3251CAE82D5110467926B72B47E96E38.report
Scheduling successful
submit!!!
jobs = 129
day = 121 run = 15121078
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15121078/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15121078/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:10:31 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 07:10:31 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:10:31 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:10:32 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:10:32 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process 651F5DBDED8F87FD462AFCB9779BE2A1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 651F5DBDED8F87FD462AFCB9779BE2A1_1... done.
Writting process 651F5DBDED8F87FD462AFCB9779BE2A1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched651F5DBDED8F87FD462AFCB9779BE2A1.report
Scheduling successful
submit!!!
Job submission for day 121 finished!
122
jobs = 132
day = 122 run = 15122003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122003/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:11:52 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 07:11:52 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:11:52 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:11:53 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:11:53 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process 2C1929466318A51FDADB90AFF9D4D304_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2C1929466318A51FDADB90AFF9D4D304_1... done.
Writting process 2C1929466318A51FDADB90AFF9D4D304_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2C1929466318A51FDADB90AFF9D4D304.report
Scheduling successful
submit!!!
jobs = 134
day = 122 run = 15122004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122004/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:13:12 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 07:13:13 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:13:13 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:13:14 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:13:15 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process FCF4924C34762E4A97F520B8A8CA6BD4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FCF4924C34762E4A97F520B8A8CA6BD4_1... done.
Writting process FCF4924C34762E4A97F520B8A8CA6BD4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFCF4924C34762E4A97F520B8A8CA6BD4.report
Scheduling successful
submit!!!
jobs = 134
day = 122 run = 15122006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122006/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:14:33 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 07:14:34 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:14:35 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:14:39 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:14:44 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 1FF6739970E617F3FC44DAE6D6796F19_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1FF6739970E617F3FC44DAE6D6796F19_1... done.
Writting process 1FF6739970E617F3FC44DAE6D6796F19_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1FF6739970E617F3FC44DAE6D6796F19.report
Scheduling successful
submit!!!
jobs = 134
day = 122 run = 15122008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122008/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:16:02 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 07:16:03 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:16:04 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:16:06 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:16:07 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process BD8714B0EB7AE9A09309ADA8BDF1F588_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BD8714B0EB7AE9A09309ADA8BDF1F588_1... done.
Writting process BD8714B0EB7AE9A09309ADA8BDF1F588_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBD8714B0EB7AE9A09309ADA8BDF1F588.report
Scheduling successful
submit!!!
jobs = 136
day = 122 run = 15122010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122010/*.root.log: No such file or directory
157
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:17:27 PDT] Dataset size is 157 files
Removing files not on site LBL
[2017.09.05 07:17:28 PDT] Dataset size is 157 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:17:31 PDT] Dataset size is 157 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:17:34 PDT] Started with 157 files, current size is 157files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:17:36 PDT] Dataset size is 157 files
----------------------------------------------------
validating dataset ....passed
Writting process E9FFC5D98C68DF0E6710B79AE879043D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E9FFC5D98C68DF0E6710B79AE879043D_1... done.
Writting process E9FFC5D98C68DF0E6710B79AE879043D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE9FFC5D98C68DF0E6710B79AE879043D.report
Scheduling successful
submit!!!
jobs = 137
day = 122 run = 15122011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122011/*.root.log: No such file or directory
96
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:18:51 PDT] Dataset size is 96 files
Removing files not on site LBL
[2017.09.05 07:18:51 PDT] Dataset size is 96 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:18:52 PDT] Dataset size is 96 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:18:55 PDT] Started with 96 files, current size is 96files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:18:55 PDT] Dataset size is 96 files
----------------------------------------------------
validating dataset ....passed
Writting process BB5EC30E006869A254D2F5F890BC50C4_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBB5EC30E006869A254D2F5F890BC50C4.report
Scheduling successful
submit!!!
jobs = 138
day = 122 run = 15122030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122030/*.root.log: No such file or directory
37
37 37
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:20:07 PDT] Dataset size is 37 files
Removing files not on site LBL
[2017.09.05 07:20:08 PDT] Dataset size is 37 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:20:08 PDT] Dataset size is 37 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:20:11 PDT] Started with 37 files, current size is 37files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=37 ,maxSize=37 )
[2017.09.05 07:20:11 PDT] Dataset size is 37 files
----------------------------------------------------
validating dataset ....passed
Writting process 32758132A5B379C8F78BD595E293C8D1_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched32758132A5B379C8F78BD595E293C8D1.report
Scheduling successful
submit!!!
jobs = 138
day = 122 run = 15122031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122031/*.root.log: No such file or directory
208
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:21:31 PDT] Dataset size is 208 files
Removing files not on site LBL
[2017.09.05 07:21:32 PDT] Dataset size is 208 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:21:33 PDT] Dataset size is 208 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:21:35 PDT] Started with 208 files, current size is 208files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:21:36 PDT] Dataset size is 208 files
----------------------------------------------------
validating dataset ....passed
Writting process 6C45BA1DA6920518B9288C832CFBF1E2_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6C45BA1DA6920518B9288C832CFBF1E2_2... done.
Writting process 6C45BA1DA6920518B9288C832CFBF1E2_1... done.
Writting process 6C45BA1DA6920518B9288C832CFBF1E2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6C45BA1DA6920518B9288C832CFBF1E2.report
Scheduling successful
submit!!!
jobs = 139
day = 122 run = 15122034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122034/*.root.log: No such file or directory
194
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:22:51 PDT] Dataset size is 194 files
Removing files not on site LBL
[2017.09.05 07:22:53 PDT] Dataset size is 194 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:22:55 PDT] Dataset size is 194 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:23:04 PDT] Started with 194 files, current size is 194files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:23:07 PDT] Dataset size is 194 files
----------------------------------------------------
validating dataset ....passed
Writting process E07D6AA50CA22615C1D626C1AD5D9995_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E07D6AA50CA22615C1D626C1AD5D9995_1... done.
Writting process E07D6AA50CA22615C1D626C1AD5D9995_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE07D6AA50CA22615C1D626C1AD5D9995.report
Scheduling successful
submit!!!
jobs = 140
day = 122 run = 15122039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122039/*.root.log: No such file or directory
254
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:24:33 PDT] Dataset size is 254 files
Removing files not on site LBL
[2017.09.05 07:24:36 PDT] Dataset size is 254 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:24:38 PDT] Dataset size is 254 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:24:42 PDT] Started with 254 files, current size is 254files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:24:44 PDT] Dataset size is 254 files
----------------------------------------------------
validating dataset ....passed
Writting process 52232A1BE243A524D847E265035B4409_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 52232A1BE243A524D847E265035B4409_3... done.
Writting process 52232A1BE243A524D847E265035B4409_2... done.
Writting process 52232A1BE243A524D847E265035B4409_1... done.
Writting process 52232A1BE243A524D847E265035B4409_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched52232A1BE243A524D847E265035B4409.report
Scheduling successful
submit!!!
jobs = 138
day = 122 run = 15122041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122041/*.root.log: No such file or directory
243
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:26:05 PDT] Dataset size is 243 files
Removing files not on site LBL
[2017.09.05 07:26:06 PDT] Dataset size is 243 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:26:07 PDT] Dataset size is 243 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:26:10 PDT] Started with 243 files, current size is 243files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:26:14 PDT] Dataset size is 243 files
----------------------------------------------------
validating dataset ....passed
Writting process 0E23A7EE00E349DD449128BA9F68797B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0E23A7EE00E349DD449128BA9F68797B_2... done.
Writting process 0E23A7EE00E349DD449128BA9F68797B_1... done.
Writting process 0E23A7EE00E349DD449128BA9F68797B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0E23A7EE00E349DD449128BA9F68797B.report
Scheduling successful
submit!!!
jobs = 139
day = 122 run = 15122042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122042/*.root.log: No such file or directory
257
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:27:34 PDT] Dataset size is 257 files
Removing files not on site LBL
[2017.09.05 07:27:36 PDT] Dataset size is 257 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:27:37 PDT] Dataset size is 257 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:27:41 PDT] Started with 257 files, current size is 257files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:27:42 PDT] Dataset size is 257 files
----------------------------------------------------
validating dataset ....passed
Writting process 72AD763E47844273E40CEF78B0CF5AF2_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 72AD763E47844273E40CEF78B0CF5AF2_3... done.
Writting process 72AD763E47844273E40CEF78B0CF5AF2_2... done.
Writting process 72AD763E47844273E40CEF78B0CF5AF2_1... done.
Writting process 72AD763E47844273E40CEF78B0CF5AF2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched72AD763E47844273E40CEF78B0CF5AF2.report
Scheduling successful
submit!!!
jobs = 144
day = 122 run = 15122043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122043/*.root.log: No such file or directory
33
33 33
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:28:53 PDT] Dataset size is 33 files
Removing files not on site LBL
[2017.09.05 07:28:54 PDT] Dataset size is 33 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:28:55 PDT] Dataset size is 33 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:29:02 PDT] Started with 33 files, current size is 33files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=33 ,maxSize=33 )
[2017.09.05 07:29:03 PDT] Dataset size is 33 files
----------------------------------------------------
validating dataset ....passed
Writting process 62826FE2E7C287DC150F12C555DD6602_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched62826FE2E7C287DC150F12C555DD6602.report
Scheduling successful
submit!!!
jobs = 140
day = 122 run = 15122044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122044/*.root.log: No such file or directory
201
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:30:22 PDT] Dataset size is 201 files
Removing files not on site LBL
[2017.09.05 07:30:22 PDT] Dataset size is 201 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:30:24 PDT] Dataset size is 201 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:30:25 PDT] Started with 201 files, current size is 201files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:30:25 PDT] Dataset size is 201 files
----------------------------------------------------
validating dataset ....passed
Writting process C2123171E5D539972E82B6E935A90CF7_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C2123171E5D539972E82B6E935A90CF7_2... done.
Writting process C2123171E5D539972E82B6E935A90CF7_1... done.
Writting process C2123171E5D539972E82B6E935A90CF7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC2123171E5D539972E82B6E935A90CF7.report
Scheduling successful
submit!!!
jobs = 142
day = 122 run = 15122045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122045/*.root.log: No such file or directory
15
15 15
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:31:36 PDT] Dataset size is 15 files
Removing files not on site LBL
[2017.09.05 07:31:36 PDT] Dataset size is 15 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:31:36 PDT] Dataset size is 15 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:31:37 PDT] Started with 15 files, current size is 15files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=15 ,maxSize=15 )
[2017.09.05 07:31:37 PDT] Dataset size is 15 files
----------------------------------------------------
validating dataset ....passed
Writting process 1B63367B9DD6391ACFB0AE9897EE2067_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1B63367B9DD6391ACFB0AE9897EE2067.report
Scheduling successful
submit!!!
jobs = 141
day = 122 run = 15122049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122049/*.root.log: No such file or directory
55
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:32:49 PDT] Dataset size is 55 files
Removing files not on site LBL
[2017.09.05 07:32:50 PDT] Dataset size is 55 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:32:50 PDT] Dataset size is 55 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:32:51 PDT] Started with 55 files, current size is 55files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:32:52 PDT] Dataset size is 55 files
----------------------------------------------------
validating dataset ....passed
Writting process B48BDAFFD7A69A82D80AC7956903367B_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB48BDAFFD7A69A82D80AC7956903367B.report
Scheduling successful
submit!!!
jobs = 140
day = 122 run = 15122062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122062/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:34:10 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 07:34:11 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:34:13 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:34:15 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:34:17 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process 07EE92DBED9872642C9ACB2841778606_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 07EE92DBED9872642C9ACB2841778606_1... done.
Writting process 07EE92DBED9872642C9ACB2841778606_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched07EE92DBED9872642C9ACB2841778606.report
Scheduling successful
submit!!!
jobs = 139
day = 122 run = 15122063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122063/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:35:33 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 07:35:34 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:35:34 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:35:36 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:35:37 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process 83F7543A85A7C18BDBB43593D2FC3185_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 83F7543A85A7C18BDBB43593D2FC3185_1... done.
Writting process 83F7543A85A7C18BDBB43593D2FC3185_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched83F7543A85A7C18BDBB43593D2FC3185.report
Scheduling successful
submit!!!
jobs = 136
day = 122 run = 15122064
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122064/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122064/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:36:58 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.05 07:37:00 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:37:02 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:37:05 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:37:05 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process 582047217906F3165E44331A51A70BCA_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 582047217906F3165E44331A51A70BCA_1... done.
Writting process 582047217906F3165E44331A51A70BCA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched582047217906F3165E44331A51A70BCA.report
Scheduling successful
submit!!!
jobs = 142
day = 122 run = 15122065
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15122065/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15122065/*.root.log: No such file or directory
158
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:38:25 PDT] Dataset size is 158 files
Removing files not on site LBL
[2017.09.05 07:38:25 PDT] Dataset size is 158 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:38:26 PDT] Dataset size is 158 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:38:30 PDT] Started with 158 files, current size is 158files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:38:32 PDT] Dataset size is 158 files
----------------------------------------------------
validating dataset ....passed
Writting process E3D2C11C600280C7EEADF4F7FD319F49_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E3D2C11C600280C7EEADF4F7FD319F49_1... done.
Writting process E3D2C11C600280C7EEADF4F7FD319F49_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE3D2C11C600280C7EEADF4F7FD319F49.report
Scheduling successful
submit!!!
Job submission for day 122 finished!
123
jobs = 145
day = 123 run = 15123001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123001/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:39:50 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 07:39:50 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:39:50 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:39:52 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:39:53 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 07F2899337588B4D36C15436BFBB3D74_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 07F2899337588B4D36C15436BFBB3D74_1... done.
Writting process 07F2899337588B4D36C15436BFBB3D74_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched07F2899337588B4D36C15436BFBB3D74.report
Scheduling successful
submit!!!
jobs = 146
day = 123 run = 15123002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123002/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:41:12 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 07:41:13 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:41:13 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:41:14 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:41:14 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process C375B50AE12F245A8BBDBA9FFC02ADA1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C375B50AE12F245A8BBDBA9FFC02ADA1_1... done.
Writting process C375B50AE12F245A8BBDBA9FFC02ADA1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC375B50AE12F245A8BBDBA9FFC02ADA1.report
Scheduling successful
submit!!!
jobs = 149
day = 123 run = 15123003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123003/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:42:30 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 07:42:31 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:42:32 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:42:34 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:42:34 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 85BDE87CBE730CF3FE4F40399CAFD736_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 85BDE87CBE730CF3FE4F40399CAFD736_1... done.
Writting process 85BDE87CBE730CF3FE4F40399CAFD736_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched85BDE87CBE730CF3FE4F40399CAFD736.report
Scheduling successful
submit!!!
jobs = 152
day = 123 run = 15123006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123006/*.root.log: No such file or directory
144
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:43:46 PDT] Dataset size is 144 files
Removing files not on site LBL
[2017.09.05 07:43:47 PDT] Dataset size is 144 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:43:48 PDT] Dataset size is 144 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:43:49 PDT] Started with 144 files, current size is 144files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:43:49 PDT] Dataset size is 144 files
----------------------------------------------------
validating dataset ....passed
Writting process 87E8E28F5F9C28339E1AC1F15BF45944_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 87E8E28F5F9C28339E1AC1F15BF45944_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched87E8E28F5F9C28339E1AC1F15BF45944.report
Scheduling successful
submit!!!
jobs = 153
day = 123 run = 15123009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123009/*.root.log: No such file or directory
197
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:45:06 PDT] Dataset size is 197 files
Removing files not on site LBL
[2017.09.05 07:45:08 PDT] Dataset size is 197 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:45:09 PDT] Dataset size is 197 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:45:11 PDT] Started with 197 files, current size is 197files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:45:12 PDT] Dataset size is 197 files
----------------------------------------------------
validating dataset ....passed
Writting process 4ED48C11F27D6DF4A0134C418AF1EB49_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4ED48C11F27D6DF4A0134C418AF1EB49_1... done.
Writting process 4ED48C11F27D6DF4A0134C418AF1EB49_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4ED48C11F27D6DF4A0134C418AF1EB49.report
Scheduling successful
submit!!!
jobs = 156
day = 123 run = 15123010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123010/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:46:27 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 07:46:28 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:46:28 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:46:29 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:46:30 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 53390A6037CADC0D3B7AB7DC35A465F1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 53390A6037CADC0D3B7AB7DC35A465F1_1... done.
Writting process 53390A6037CADC0D3B7AB7DC35A465F1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched53390A6037CADC0D3B7AB7DC35A465F1.report
Scheduling successful
submit!!!
jobs = 158
day = 123 run = 15123011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123011/*.root.log: No such file or directory
101
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:47:41 PDT] Dataset size is 101 files
Removing files not on site LBL
[2017.09.05 07:47:41 PDT] Dataset size is 101 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:47:41 PDT] Dataset size is 101 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:47:42 PDT] Started with 101 files, current size is 101files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:47:43 PDT] Dataset size is 101 files
----------------------------------------------------
validating dataset ....passed
Writting process 25B6657E55302B177A41A8C1285E4691_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 25B6657E55302B177A41A8C1285E4691_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched25B6657E55302B177A41A8C1285E4691.report
Scheduling successful
submit!!!
jobs = 158
day = 123 run = 15123019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123019/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:49:01 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 07:49:01 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:49:01 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:49:01 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:49:02 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process E83EAC20B5657D78841CC685EB15AC2D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E83EAC20B5657D78841CC685EB15AC2D_1... done.
Writting process E83EAC20B5657D78841CC685EB15AC2D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE83EAC20B5657D78841CC685EB15AC2D.report
Scheduling successful
submit!!!
jobs = 152
day = 123 run = 15123020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123020/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:50:15 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 07:50:15 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:50:15 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:50:15 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:50:15 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process 605F7C645E4C96F2F50E1C119952052E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 605F7C645E4C96F2F50E1C119952052E_1... done.
Writting process 605F7C645E4C96F2F50E1C119952052E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched605F7C645E4C96F2F50E1C119952052E.report
Scheduling successful
submit!!!
jobs = 155
day = 123 run = 15123021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123021/*.root.log: No such file or directory
224
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:51:29 PDT] Dataset size is 224 files
Removing files not on site LBL
[2017.09.05 07:51:29 PDT] Dataset size is 224 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:51:29 PDT] Dataset size is 224 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:51:29 PDT] Started with 224 files, current size is 224files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:51:29 PDT] Dataset size is 224 files
----------------------------------------------------
validating dataset ....passed
Writting process 9C4E5A3ED814AA7F457BB337CE697AB2_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9C4E5A3ED814AA7F457BB337CE697AB2_2... done.
Writting process 9C4E5A3ED814AA7F457BB337CE697AB2_1... done.
Writting process 9C4E5A3ED814AA7F457BB337CE697AB2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9C4E5A3ED814AA7F457BB337CE697AB2.report
Scheduling successful
submit!!!
jobs = 153
day = 123 run = 15123022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123022/*.root.log: No such file or directory
203
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:52:43 PDT] Dataset size is 203 files
Removing files not on site LBL
[2017.09.05 07:52:43 PDT] Dataset size is 203 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:52:44 PDT] Dataset size is 203 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:52:44 PDT] Started with 203 files, current size is 203files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:52:45 PDT] Dataset size is 203 files
----------------------------------------------------
validating dataset ....passed
Writting process EC9E300151312A1D3019906CAC2A0AF6_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EC9E300151312A1D3019906CAC2A0AF6_2... done.
Writting process EC9E300151312A1D3019906CAC2A0AF6_1... done.
Writting process EC9E300151312A1D3019906CAC2A0AF6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEC9E300151312A1D3019906CAC2A0AF6.report
Scheduling successful
submit!!!
jobs = 156
day = 123 run = 15123023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123023/*.root.log: No such file or directory
214
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:54:04 PDT] Dataset size is 214 files
Removing files not on site LBL
[2017.09.05 07:54:05 PDT] Dataset size is 214 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:54:05 PDT] Dataset size is 214 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:54:06 PDT] Started with 214 files, current size is 214files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:54:06 PDT] Dataset size is 214 files
----------------------------------------------------
validating dataset ....passed
Writting process 7D5D0F2576C197C5A311E794902EBD73_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7D5D0F2576C197C5A311E794902EBD73_2... done.
Writting process 7D5D0F2576C197C5A311E794902EBD73_1... done.
Writting process 7D5D0F2576C197C5A311E794902EBD73_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7D5D0F2576C197C5A311E794902EBD73.report
Scheduling successful
submit!!!
jobs = 158
day = 123 run = 15123024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123024/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:55:19 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 07:55:20 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:55:20 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:55:21 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:55:21 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process ABCE3AC0F7AF20E656191B4B15B5D524_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ABCE3AC0F7AF20E656191B4B15B5D524_1... done.
Writting process ABCE3AC0F7AF20E656191B4B15B5D524_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedABCE3AC0F7AF20E656191B4B15B5D524.report
Scheduling successful
submit!!!
jobs = 155
day = 123 run = 15123025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123025/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:56:37 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 07:56:37 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:56:38 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:56:39 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:56:39 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process 4AD7CC596E87439660EA843212436B4C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4AD7CC596E87439660EA843212436B4C_1... done.
Writting process 4AD7CC596E87439660EA843212436B4C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4AD7CC596E87439660EA843212436B4C.report
Scheduling successful
submit!!!
jobs = 154
day = 123 run = 15123026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123026/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:57:54 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 07:57:56 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:57:58 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:58:02 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:58:03 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process 3DDCF4B8F599F05ADA25A470276F1AE1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3DDCF4B8F599F05ADA25A470276F1AE1_1... done.
Writting process 3DDCF4B8F599F05ADA25A470276F1AE1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3DDCF4B8F599F05ADA25A470276F1AE1.report
Scheduling successful
submit!!!
jobs = 159
day = 123 run = 15123027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123027/*.root.log: No such file or directory
202
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 07:59:19 PDT] Dataset size is 202 files
Removing files not on site LBL
[2017.09.05 07:59:20 PDT] Dataset size is 202 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 07:59:22 PDT] Dataset size is 202 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 07:59:24 PDT] Started with 202 files, current size is 202files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 07:59:25 PDT] Dataset size is 202 files
----------------------------------------------------
validating dataset ....passed
Writting process 029BADFE6BF313C902650CCBF63950EF_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 029BADFE6BF313C902650CCBF63950EF_2... done.
Writting process 029BADFE6BF313C902650CCBF63950EF_1... done.
Writting process 029BADFE6BF313C902650CCBF63950EF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched029BADFE6BF313C902650CCBF63950EF.report
Scheduling successful
submit!!!
jobs = 157
day = 123 run = 15123028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123028/*.root.log: No such file or directory
128
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:00:53 PDT] Dataset size is 128 files
Removing files not on site LBL
[2017.09.05 08:00:55 PDT] Dataset size is 128 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:00:57 PDT] Dataset size is 128 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:01:00 PDT] Started with 128 files, current size is 128files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:01:01 PDT] Dataset size is 128 files
----------------------------------------------------
validating dataset ....passed
Writting process CD02B634A4ABDFC836DD2920EC42F65A_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CD02B634A4ABDFC836DD2920EC42F65A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCD02B634A4ABDFC836DD2920EC42F65A.report
Scheduling successful
submit!!!
jobs = 156
day = 123 run = 15123035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123035/*.root.log: No such file or directory
162
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:02:21 PDT] Dataset size is 162 files
Removing files not on site LBL
[2017.09.05 08:02:22 PDT] Dataset size is 162 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:02:23 PDT] Dataset size is 162 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:02:25 PDT] Started with 162 files, current size is 162files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:02:27 PDT] Dataset size is 162 files
----------------------------------------------------
validating dataset ....passed
Writting process 32976C08C8C3A4AEB09FD32DC3D47983_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 32976C08C8C3A4AEB09FD32DC3D47983_1... done.
Writting process 32976C08C8C3A4AEB09FD32DC3D47983_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched32976C08C8C3A4AEB09FD32DC3D47983.report
Scheduling successful
submit!!!
jobs = 155
day = 123 run = 15123036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123036/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:03:50 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 08:03:51 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:03:53 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:03:55 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:03:55 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process DD3F0E61975FE4AADE05B42E635F69BC_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DD3F0E61975FE4AADE05B42E635F69BC_1... done.
Writting process DD3F0E61975FE4AADE05B42E635F69BC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDD3F0E61975FE4AADE05B42E635F69BC.report
Scheduling successful
submit!!!
jobs = 154
day = 123 run = 15123037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123037/*.root.log: No such file or directory
144
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:05:18 PDT] Dataset size is 144 files
Removing files not on site LBL
[2017.09.05 08:05:19 PDT] Dataset size is 144 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:05:19 PDT] Dataset size is 144 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:05:21 PDT] Started with 144 files, current size is 144files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:05:22 PDT] Dataset size is 144 files
----------------------------------------------------
validating dataset ....passed
Writting process 9AED4DC927859C75E9C640A053F0EC50_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9AED4DC927859C75E9C640A053F0EC50_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9AED4DC927859C75E9C640A053F0EC50.report
Scheduling successful
submit!!!
jobs = 152
day = 123 run = 15123050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123050/*.root.log: No such file or directory
93
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:06:41 PDT] Dataset size is 93 files
Removing files not on site LBL
[2017.09.05 08:06:42 PDT] Dataset size is 93 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:06:43 PDT] Dataset size is 93 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:06:46 PDT] Started with 93 files, current size is 93files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:06:47 PDT] Dataset size is 93 files
----------------------------------------------------
validating dataset ....passed
Writting process 0F2DAD741DA8423E647891A14C8987B4_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0F2DAD741DA8423E647891A14C8987B4.report
Scheduling successful
submit!!!
jobs = 149
day = 123 run = 15123051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123051/*.root.log: No such file or directory
158
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:08:09 PDT] Dataset size is 158 files
Removing files not on site LBL
[2017.09.05 08:08:11 PDT] Dataset size is 158 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:08:11 PDT] Dataset size is 158 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:08:12 PDT] Started with 158 files, current size is 158files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:08:12 PDT] Dataset size is 158 files
----------------------------------------------------
validating dataset ....passed
Writting process 41E479AC96388F2B86568777FE0EF5DB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 41E479AC96388F2B86568777FE0EF5DB_1... done.
Writting process 41E479AC96388F2B86568777FE0EF5DB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched41E479AC96388F2B86568777FE0EF5DB.report
Scheduling successful
submit!!!
jobs = 147
day = 123 run = 15123053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123053/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:10:03 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 08:10:04 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:10:04 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:10:05 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:10:05 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 43009C22238AC81EB2649114831D8233_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 43009C22238AC81EB2649114831D8233_1... done.
Writting process 43009C22238AC81EB2649114831D8233_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched43009C22238AC81EB2649114831D8233.report
Scheduling successful
submit!!!
jobs = 144
day = 123 run = 15123054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15123054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15123054/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:11:25 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 08:11:26 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:11:26 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:11:31 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:11:32 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process 87D7360F5045052FAE17162E72CE2FC9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 87D7360F5045052FAE17162E72CE2FC9_1... done.
Writting process 87D7360F5045052FAE17162E72CE2FC9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched87D7360F5045052FAE17162E72CE2FC9.report
Scheduling successful
submit!!!
Job submission for day 123 finished!
124
jobs = 144
day = 124 run = 15124001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124001/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:12:53 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.05 08:12:54 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:12:55 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:12:55 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:12:56 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process 7D05FC0313D1C5F417E4BF582CE8779C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7D05FC0313D1C5F417E4BF582CE8779C_1... done.
Writting process 7D05FC0313D1C5F417E4BF582CE8779C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7D05FC0313D1C5F417E4BF582CE8779C.report
Scheduling successful
submit!!!
jobs = 141
day = 124 run = 15124002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124002/*.root.log: No such file or directory
159
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:14:14 PDT] Dataset size is 159 files
Removing files not on site LBL
[2017.09.05 08:14:16 PDT] Dataset size is 159 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:14:18 PDT] Dataset size is 159 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:14:21 PDT] Started with 159 files, current size is 159files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:14:22 PDT] Dataset size is 159 files
----------------------------------------------------
validating dataset ....passed
Writting process 59E32D006BCD46B19B753B191D46456C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 59E32D006BCD46B19B753B191D46456C_1... done.
Writting process 59E32D006BCD46B19B753B191D46456C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched59E32D006BCD46B19B753B191D46456C.report
Scheduling successful
submit!!!
jobs = 137
day = 124 run = 15124003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124003/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:15:41 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 08:15:43 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:15:44 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:15:47 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:15:48 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process 95DB24CD5CE6B04B24518C069B18DF96_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 95DB24CD5CE6B04B24518C069B18DF96_1... done.
Writting process 95DB24CD5CE6B04B24518C069B18DF96_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched95DB24CD5CE6B04B24518C069B18DF96.report
Scheduling successful
submit!!!
jobs = 135
day = 124 run = 15124004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124004/*.root.log: No such file or directory
101
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:17:01 PDT] Dataset size is 101 files
Removing files not on site LBL
[2017.09.05 08:17:02 PDT] Dataset size is 101 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:17:02 PDT] Dataset size is 101 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:17:03 PDT] Started with 101 files, current size is 101files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:17:04 PDT] Dataset size is 101 files
----------------------------------------------------
validating dataset ....passed
Writting process F1CD65225610C519D8D0682304F539AE_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F1CD65225610C519D8D0682304F539AE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF1CD65225610C519D8D0682304F539AE.report
Scheduling successful
submit!!!
jobs = 156
day = 124 run = 15124006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124006/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:18:24 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 08:18:25 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:18:28 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:18:31 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:18:33 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 3CE60D73779B82940665C4AE26452A0E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3CE60D73779B82940665C4AE26452A0E_1... done.
Writting process 3CE60D73779B82940665C4AE26452A0E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3CE60D73779B82940665C4AE26452A0E.report
Scheduling successful
submit!!!
jobs = 154
day = 124 run = 15124008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124008/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:19:56 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 08:19:57 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:19:58 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:20:00 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:20:03 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 0D889F716AB7374D43E6A03CD04CCA33_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0D889F716AB7374D43E6A03CD04CCA33_1... done.
Writting process 0D889F716AB7374D43E6A03CD04CCA33_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0D889F716AB7374D43E6A03CD04CCA33.report
Scheduling successful
submit!!!
jobs = 151
day = 124 run = 15124010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124010/*.root.log: No such file or directory
53
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:21:13 PDT] Dataset size is 53 files
Removing files not on site LBL
[2017.09.05 08:21:13 PDT] Dataset size is 53 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:21:13 PDT] Dataset size is 53 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:21:13 PDT] Started with 53 files, current size is 53files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:21:13 PDT] Dataset size is 53 files
----------------------------------------------------
validating dataset ....passed
Writting process F9EF5F54BC992C45645F45E698ECD9F9_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF9EF5F54BC992C45645F45E698ECD9F9.report
Scheduling successful
submit!!!
jobs = 149
day = 124 run = 15124028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124028/*.root.log: No such file or directory
41
41 41
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:22:22 PDT] Dataset size is 41 files
Removing files not on site LBL
[2017.09.05 08:22:23 PDT] Dataset size is 41 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:22:24 PDT] Dataset size is 41 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:22:26 PDT] Started with 41 files, current size is 41files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=41 ,maxSize=41 )
[2017.09.05 08:22:26 PDT] Dataset size is 41 files
----------------------------------------------------
validating dataset ....passed
Writting process 0D5655F8977B8F92C2CDA6637478A34C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0D5655F8977B8F92C2CDA6637478A34C.report
Scheduling successful
submit!!!
jobs = 150
day = 124 run = 15124031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124031/*.root.log: No such file or directory
139
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:23:38 PDT] Dataset size is 139 files
Removing files not on site LBL
[2017.09.05 08:23:39 PDT] Dataset size is 139 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:23:42 PDT] Dataset size is 139 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:23:46 PDT] Started with 139 files, current size is 139files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:23:47 PDT] Dataset size is 139 files
----------------------------------------------------
validating dataset ....passed
Writting process 7CD4C3A4CAC28EEF7692751A50FF085D_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7CD4C3A4CAC28EEF7692751A50FF085D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7CD4C3A4CAC28EEF7692751A50FF085D.report
Scheduling successful
submit!!!
jobs = 151
day = 124 run = 15124032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124032/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:25:02 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 08:25:04 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:25:05 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:25:08 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:25:10 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process C2504DA0CBC079F5D1A373E7DA2186F3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C2504DA0CBC079F5D1A373E7DA2186F3_1... done.
Writting process C2504DA0CBC079F5D1A373E7DA2186F3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC2504DA0CBC079F5D1A373E7DA2186F3.report
Scheduling successful
submit!!!
jobs = 149
day = 124 run = 15124033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124033/*.root.log: No such file or directory
136
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:26:22 PDT] Dataset size is 136 files
Removing files not on site LBL
[2017.09.05 08:26:22 PDT] Dataset size is 136 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:26:22 PDT] Dataset size is 136 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:26:24 PDT] Started with 136 files, current size is 136files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:26:24 PDT] Dataset size is 136 files
----------------------------------------------------
validating dataset ....passed
Writting process EE520905A40906482AA8648E87B523C2_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EE520905A40906482AA8648E87B523C2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEE520905A40906482AA8648E87B523C2.report
Scheduling successful
submit!!!
jobs = 148
day = 124 run = 15124034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124034/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:27:37 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 08:27:37 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:27:37 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:27:38 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:27:38 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process DDC854E0BBF42861A4B95496110E128A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DDC854E0BBF42861A4B95496110E128A_1... done.
Writting process DDC854E0BBF42861A4B95496110E128A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDDC854E0BBF42861A4B95496110E128A.report
Scheduling successful
submit!!!
jobs = 151
day = 124 run = 15124035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124035/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:28:52 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.05 08:28:53 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:28:53 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:28:54 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:28:54 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process A5B23856753F38F8ED79186123010C73_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A5B23856753F38F8ED79186123010C73_2... done.
Writting process A5B23856753F38F8ED79186123010C73_1... done.
Writting process A5B23856753F38F8ED79186123010C73_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA5B23856753F38F8ED79186123010C73.report
Scheduling successful
submit!!!
jobs = 151
day = 124 run = 15124040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124040/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:30:07 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 08:30:07 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:30:07 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:30:07 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:30:07 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 2B171F9D5D69F128E6F25F5DA0624C42_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2B171F9D5D69F128E6F25F5DA0624C42_1... done.
Writting process 2B171F9D5D69F128E6F25F5DA0624C42_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2B171F9D5D69F128E6F25F5DA0624C42.report
Scheduling successful
submit!!!
jobs = 152
day = 124 run = 15124041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124041/*.root.log: No such file or directory
224
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:31:23 PDT] Dataset size is 224 files
Removing files not on site LBL
[2017.09.05 08:31:24 PDT] Dataset size is 224 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:31:25 PDT] Dataset size is 224 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:31:27 PDT] Started with 224 files, current size is 224files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:31:27 PDT] Dataset size is 224 files
----------------------------------------------------
validating dataset ....passed
Writting process 722C3475EC83ABE4A36563E1AFF8B13A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 722C3475EC83ABE4A36563E1AFF8B13A_2... done.
Writting process 722C3475EC83ABE4A36563E1AFF8B13A_1... done.
Writting process 722C3475EC83ABE4A36563E1AFF8B13A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched722C3475EC83ABE4A36563E1AFF8B13A.report
Scheduling successful
submit!!!
jobs = 151
day = 124 run = 15124042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124042/*.root.log: No such file or directory
226
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:32:50 PDT] Dataset size is 226 files
Removing files not on site LBL
[2017.09.05 08:32:51 PDT] Dataset size is 226 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:32:51 PDT] Dataset size is 226 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:32:51 PDT] Started with 226 files, current size is 226files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:32:51 PDT] Dataset size is 226 files
----------------------------------------------------
validating dataset ....passed
Writting process 33788F431A1751B7BB3A7D025E223D27_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 33788F431A1751B7BB3A7D025E223D27_2... done.
Writting process 33788F431A1751B7BB3A7D025E223D27_1... done.
Writting process 33788F431A1751B7BB3A7D025E223D27_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched33788F431A1751B7BB3A7D025E223D27.report
Scheduling successful
submit!!!
jobs = 154
day = 124 run = 15124043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124043/*.root.log: No such file or directory
160
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:34:09 PDT] Dataset size is 160 files
Removing files not on site LBL
[2017.09.05 08:34:11 PDT] Dataset size is 160 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:34:13 PDT] Dataset size is 160 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:34:14 PDT] Started with 160 files, current size is 160files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:34:14 PDT] Dataset size is 160 files
----------------------------------------------------
validating dataset ....passed
Writting process 157D1786AB0EE3AFC299C18E28522B41_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 157D1786AB0EE3AFC299C18E28522B41_1... done.
Writting process 157D1786AB0EE3AFC299C18E28522B41_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched157D1786AB0EE3AFC299C18E28522B41.report
Scheduling successful
submit!!!
jobs = 152
day = 124 run = 15124044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124044/*.root.log: No such file or directory
40
40 40
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:35:28 PDT] Dataset size is 40 files
Removing files not on site LBL
[2017.09.05 08:35:28 PDT] Dataset size is 40 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:35:29 PDT] Dataset size is 40 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:35:30 PDT] Started with 40 files, current size is 40files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=40 ,maxSize=40 )
[2017.09.05 08:35:31 PDT] Dataset size is 40 files
----------------------------------------------------
validating dataset ....passed
Writting process 97A6CA422459EB4F22DD8BBEAAC55140_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched97A6CA422459EB4F22DD8BBEAAC55140.report
Scheduling successful
submit!!!
jobs = 151
day = 124 run = 15124056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124056/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:36:47 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 08:36:49 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:36:50 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:36:50 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:36:50 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process A1DE552ED2FE239EE6F41294D39ECD4C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A1DE552ED2FE239EE6F41294D39ECD4C_1... done.
Writting process A1DE552ED2FE239EE6F41294D39ECD4C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA1DE552ED2FE239EE6F41294D39ECD4C.report
Scheduling successful
submit!!!
jobs = 152
day = 124 run = 15124057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124057/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:38:30 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 08:38:30 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:38:30 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:38:31 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:38:31 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process 4FADE60342AE7DB44FE132E8A715A0EB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4FADE60342AE7DB44FE132E8A715A0EB_1... done.
Writting process 4FADE60342AE7DB44FE132E8A715A0EB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4FADE60342AE7DB44FE132E8A715A0EB.report
Scheduling successful
submit!!!
jobs = 150
day = 124 run = 15124058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124058/*.root.log: No such file or directory
283
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:39:50 PDT] Dataset size is 283 files
Removing files not on site LBL
[2017.09.05 08:39:52 PDT] Dataset size is 283 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:39:53 PDT] Dataset size is 283 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:39:56 PDT] Started with 283 files, current size is 283files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:39:57 PDT] Dataset size is 283 files
----------------------------------------------------
validating dataset ....passed
Writting process C6296CB1EF2A204B81F69A22B12DBD99_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C6296CB1EF2A204B81F69A22B12DBD99_3... done.
Writting process C6296CB1EF2A204B81F69A22B12DBD99_2... done.
Writting process C6296CB1EF2A204B81F69A22B12DBD99_1... done.
Writting process C6296CB1EF2A204B81F69A22B12DBD99_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC6296CB1EF2A204B81F69A22B12DBD99.report
Scheduling successful
submit!!!
jobs = 148
day = 124 run = 15124060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124060/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:41:36 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 08:41:38 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:41:40 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:41:42 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:41:43 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process DD2EEAB7C2CE311C758D56B9134C88EF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DD2EEAB7C2CE311C758D56B9134C88EF_1... done.
Writting process DD2EEAB7C2CE311C758D56B9134C88EF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDD2EEAB7C2CE311C758D56B9134C88EF.report
Scheduling successful
submit!!!
jobs = 151
day = 124 run = 15124061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124061/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:43:01 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.05 08:43:04 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:43:06 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:43:12 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:43:13 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process 404A02976E22E9E015E5F4BCFC72D79E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 404A02976E22E9E015E5F4BCFC72D79E_1... done.
Writting process 404A02976E22E9E015E5F4BCFC72D79E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched404A02976E22E9E015E5F4BCFC72D79E.report
Scheduling successful
submit!!!
jobs = 153
day = 124 run = 15124062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124062/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:44:27 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 08:44:27 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:44:27 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:44:27 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:44:28 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 890A7AA8BDDD6EF7E23D90ABC53259AC_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 890A7AA8BDDD6EF7E23D90ABC53259AC_1... done.
Writting process 890A7AA8BDDD6EF7E23D90ABC53259AC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched890A7AA8BDDD6EF7E23D90ABC53259AC.report
Scheduling successful
submit!!!
jobs = 153
day = 124 run = 15124063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15124063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15124063/*.root.log: No such file or directory
150
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:45:42 PDT] Dataset size is 150 files
Removing files not on site LBL
[2017.09.05 08:45:43 PDT] Dataset size is 150 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:45:44 PDT] Dataset size is 150 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:45:45 PDT] Started with 150 files, current size is 150files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:45:45 PDT] Dataset size is 150 files
----------------------------------------------------
validating dataset ....passed
Writting process D4AFF3C9A434EFC633B4560859AEEC84_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D4AFF3C9A434EFC633B4560859AEEC84_1... done.
Writting process D4AFF3C9A434EFC633B4560859AEEC84_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD4AFF3C9A434EFC633B4560859AEEC84.report
Scheduling successful
submit!!!
Job submission for day 124 finished!
125
jobs = 151
day = 125 run = 15125001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15125001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15125001/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:47:01 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 08:47:02 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:47:02 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:47:05 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:47:06 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process F74B40CFABE9A4B76FADF5B18495ADF1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F74B40CFABE9A4B76FADF5B18495ADF1_1... done.
Writting process F74B40CFABE9A4B76FADF5B18495ADF1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF74B40CFABE9A4B76FADF5B18495ADF1.report
Scheduling successful
submit!!!
jobs = 150
day = 125 run = 15125002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15125002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15125002/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:48:21 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 08:48:21 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:48:21 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:48:22 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:48:23 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 0691B51E42664FE9BC829346ABA7E833_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0691B51E42664FE9BC829346ABA7E833_1... done.
Writting process 0691B51E42664FE9BC829346ABA7E833_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0691B51E42664FE9BC829346ABA7E833.report
Scheduling successful
submit!!!
jobs = 149
day = 125 run = 15125003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15125003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15125003/*.root.log: No such file or directory
12
12 12
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:49:32 PDT] Dataset size is 12 files
Removing files not on site LBL
[2017.09.05 08:49:33 PDT] Dataset size is 12 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:49:36 PDT] Dataset size is 12 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:49:38 PDT] Started with 12 files, current size is 12files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=12 ,maxSize=12 )
[2017.09.05 08:49:39 PDT] Dataset size is 12 files
----------------------------------------------------
validating dataset ....passed
Writting process 44F2B407B592D3E3E8544D5A50BF7545_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched44F2B407B592D3E3E8544D5A50BF7545.report
Scheduling successful
submit!!!
jobs = 147
day = 125 run = 15125007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15125007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15125007/*.root.log: No such file or directory
123
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:50:51 PDT] Dataset size is 123 files
Removing files not on site LBL
[2017.09.05 08:50:52 PDT] Dataset size is 123 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:50:52 PDT] Dataset size is 123 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:50:52 PDT] Started with 123 files, current size is 123files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:50:52 PDT] Dataset size is 123 files
----------------------------------------------------
validating dataset ....passed
Writting process EE240A96676A217605E915B0FEBAEAF6_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EE240A96676A217605E915B0FEBAEAF6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEE240A96676A217605E915B0FEBAEAF6.report
Scheduling successful
submit!!!
jobs = 145
day = 125 run = 15125067
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15125067/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15125067/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:52:05 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 08:52:06 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:52:09 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:52:10 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:52:11 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process 8091628EAC932F017043C54A9FD9F296_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8091628EAC932F017043C54A9FD9F296_1... done.
Writting process 8091628EAC932F017043C54A9FD9F296_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8091628EAC932F017043C54A9FD9F296.report
Scheduling successful
submit!!!
Job submission for day 125 finished!
126
jobs = 147
day = 126 run = 15126009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126009/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:53:29 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 08:53:32 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:53:36 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:53:38 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:53:38 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process AF1665CFCDDDD5142AFCE4FC98D48C92_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AF1665CFCDDDD5142AFCE4FC98D48C92_1... done.
Writting process AF1665CFCDDDD5142AFCE4FC98D48C92_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAF1665CFCDDDD5142AFCE4FC98D48C92.report
Scheduling successful
submit!!!
jobs = 149
day = 126 run = 15126010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126010/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:55:03 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 08:55:04 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:55:05 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:55:07 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:55:08 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process A07D3B67A8090A60E83B42B69DA35B34_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A07D3B67A8090A60E83B42B69DA35B34_1... done.
Writting process A07D3B67A8090A60E83B42B69DA35B34_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA07D3B67A8090A60E83B42B69DA35B34.report
Scheduling successful
submit!!!
jobs = 149
day = 126 run = 15126011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126011/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:56:25 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 08:56:26 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:56:27 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:56:30 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:56:33 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process ACA6B2833E36398C9D84852673C3DA69_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ACA6B2833E36398C9D84852673C3DA69_1... done.
Writting process ACA6B2833E36398C9D84852673C3DA69_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedACA6B2833E36398C9D84852673C3DA69.report
Scheduling successful
submit!!!
jobs = 150
day = 126 run = 15126012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126012/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:58:05 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 08:58:05 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:58:05 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:58:05 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:58:05 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 8A02DA36064A2F4F09198727978E3638_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8A02DA36064A2F4F09198727978E3638_1... done.
Writting process 8A02DA36064A2F4F09198727978E3638_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8A02DA36064A2F4F09198727978E3638.report
Scheduling successful
submit!!!
jobs = 152
day = 126 run = 15126013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126013/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 08:59:37 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 08:59:37 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 08:59:38 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 08:59:39 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 08:59:40 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process 80ADD30CF8A9126C32D7FCA81925BE1C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 80ADD30CF8A9126C32D7FCA81925BE1C_1... done.
Writting process 80ADD30CF8A9126C32D7FCA81925BE1C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched80ADD30CF8A9126C32D7FCA81925BE1C.report
Scheduling successful
submit!!!
jobs = 150
day = 126 run = 15126015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126015/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:01:00 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 09:01:03 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:01:05 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:01:08 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:01:10 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 01A5299AEDF5BC185220AA6E88E03497_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 01A5299AEDF5BC185220AA6E88E03497_1... done.
Writting process 01A5299AEDF5BC185220AA6E88E03497_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched01A5299AEDF5BC185220AA6E88E03497.report
Scheduling successful
submit!!!
jobs = 148
day = 126 run = 15126016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126016/*.root.log: No such file or directory
281
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:02:32 PDT] Dataset size is 281 files
Removing files not on site LBL
[2017.09.05 09:02:33 PDT] Dataset size is 281 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:02:33 PDT] Dataset size is 281 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:02:33 PDT] Started with 281 files, current size is 281files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:02:34 PDT] Dataset size is 281 files
----------------------------------------------------
validating dataset ....passed
Writting process 729220C4FCF1390CF01E6935E9A0791D_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 729220C4FCF1390CF01E6935E9A0791D_3... done.
Writting process 729220C4FCF1390CF01E6935E9A0791D_2... done.
Writting process 729220C4FCF1390CF01E6935E9A0791D_1... done.
Writting process 729220C4FCF1390CF01E6935E9A0791D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched729220C4FCF1390CF01E6935E9A0791D.report
Scheduling successful
submit!!!
jobs = 151
day = 126 run = 15126017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126017/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:04:21 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 09:04:23 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:04:25 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:04:30 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:04:32 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process F42C086418508ACE4C938F9F35D492F3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F42C086418508ACE4C938F9F35D492F3_1... done.
Writting process F42C086418508ACE4C938F9F35D492F3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF42C086418508ACE4C938F9F35D492F3.report
Scheduling successful
submit!!!
jobs = 151
day = 126 run = 15126018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126018/*.root.log: No such file or directory
151
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:05:54 PDT] Dataset size is 151 files
Removing files not on site LBL
[2017.09.05 09:05:56 PDT] Dataset size is 151 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:05:57 PDT] Dataset size is 151 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:06:01 PDT] Started with 151 files, current size is 151files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:06:02 PDT] Dataset size is 151 files
----------------------------------------------------
validating dataset ....passed
Writting process 1D52A0551230DA50BB576CF92324AC6D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1D52A0551230DA50BB576CF92324AC6D_1... done.
Writting process 1D52A0551230DA50BB576CF92324AC6D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1D52A0551230DA50BB576CF92324AC6D.report
Scheduling successful
submit!!!
jobs = 148
day = 126 run = 15126019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126019/*.root.log: No such file or directory
59
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:07:18 PDT] Dataset size is 59 files
Removing files not on site LBL
[2017.09.05 09:07:19 PDT] Dataset size is 59 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:07:20 PDT] Dataset size is 59 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:07:22 PDT] Started with 59 files, current size is 59files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:07:22 PDT] Dataset size is 59 files
----------------------------------------------------
validating dataset ....passed
Writting process C82A6834FD7CFB44C9ED8D42ED38746D_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC82A6834FD7CFB44C9ED8D42ED38746D.report
Scheduling successful
submit!!!
jobs = 146
day = 126 run = 15126022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126022/*.root.log: No such file or directory
136
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:08:35 PDT] Dataset size is 136 files
Removing files not on site LBL
[2017.09.05 09:08:36 PDT] Dataset size is 136 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:08:37 PDT] Dataset size is 136 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:08:39 PDT] Started with 136 files, current size is 136files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:08:40 PDT] Dataset size is 136 files
----------------------------------------------------
validating dataset ....passed
Writting process 1D1E7B2ECCD11893E95F3241740ABC4F_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1D1E7B2ECCD11893E95F3241740ABC4F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1D1E7B2ECCD11893E95F3241740ABC4F.report
Scheduling successful
submit!!!
jobs = 144
day = 126 run = 15126023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126023/*.root.log: No such file or directory
160
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:09:56 PDT] Dataset size is 160 files
Removing files not on site LBL
[2017.09.05 09:09:56 PDT] Dataset size is 160 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:09:56 PDT] Dataset size is 160 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:09:57 PDT] Started with 160 files, current size is 160files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:09:57 PDT] Dataset size is 160 files
----------------------------------------------------
validating dataset ....passed
Writting process E24EE7FF7BE28820C259C3B38847AA70_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E24EE7FF7BE28820C259C3B38847AA70_1... done.
Writting process E24EE7FF7BE28820C259C3B38847AA70_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE24EE7FF7BE28820C259C3B38847AA70.report
Scheduling successful
submit!!!
jobs = 146
day = 126 run = 15126044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126044/*.root.log: No such file or directory
249
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:11:30 PDT] Dataset size is 249 files
Removing files not on site LBL
[2017.09.05 09:11:31 PDT] Dataset size is 249 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:11:31 PDT] Dataset size is 249 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:11:33 PDT] Started with 249 files, current size is 249files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:11:33 PDT] Dataset size is 249 files
----------------------------------------------------
validating dataset ....passed
Writting process 6BB47069A8F833EB4243464A332A9204_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6BB47069A8F833EB4243464A332A9204_2... done.
Writting process 6BB47069A8F833EB4243464A332A9204_1... done.
Writting process 6BB47069A8F833EB4243464A332A9204_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6BB47069A8F833EB4243464A332A9204.report
Scheduling successful
submit!!!
jobs = 145
day = 126 run = 15126045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126045/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:12:57 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.05 09:12:57 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:12:58 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:13:00 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:13:01 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process 84B0B391344443EFBA900D21680C3475_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 84B0B391344443EFBA900D21680C3475_2... done.
Writting process 84B0B391344443EFBA900D21680C3475_1... done.
Writting process 84B0B391344443EFBA900D21680C3475_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched84B0B391344443EFBA900D21680C3475.report
Scheduling successful
submit!!!
jobs = 149
day = 126 run = 15126046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126046/*.root.log: No such file or directory
202
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:14:21 PDT] Dataset size is 202 files
Removing files not on site LBL
[2017.09.05 09:14:21 PDT] Dataset size is 202 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:14:21 PDT] Dataset size is 202 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:14:21 PDT] Started with 202 files, current size is 202files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:14:22 PDT] Dataset size is 202 files
----------------------------------------------------
validating dataset ....passed
Writting process 17D2F4B63286BB8B038D4FC3D36378AD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 17D2F4B63286BB8B038D4FC3D36378AD_2... done.
Writting process 17D2F4B63286BB8B038D4FC3D36378AD_1... done.
Writting process 17D2F4B63286BB8B038D4FC3D36378AD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched17D2F4B63286BB8B038D4FC3D36378AD.report
Scheduling successful
submit!!!
jobs = 150
day = 126 run = 15126047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126047/*.root.log: No such file or directory
212
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:15:38 PDT] Dataset size is 212 files
Removing files not on site LBL
[2017.09.05 09:15:39 PDT] Dataset size is 212 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:15:40 PDT] Dataset size is 212 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:15:40 PDT] Started with 212 files, current size is 212files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:15:40 PDT] Dataset size is 212 files
----------------------------------------------------
validating dataset ....passed
Writting process 7C296F3C73876B3756E4F2F7014A323E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7C296F3C73876B3756E4F2F7014A323E_2... done.
Writting process 7C296F3C73876B3756E4F2F7014A323E_1... done.
Writting process 7C296F3C73876B3756E4F2F7014A323E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7C296F3C73876B3756E4F2F7014A323E.report
Scheduling successful
submit!!!
jobs = 151
day = 126 run = 15126048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126048/*.root.log: No such file or directory
228
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:16:56 PDT] Dataset size is 228 files
Removing files not on site LBL
[2017.09.05 09:16:57 PDT] Dataset size is 228 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:16:57 PDT] Dataset size is 228 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:16:57 PDT] Started with 228 files, current size is 228files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:16:57 PDT] Dataset size is 228 files
----------------------------------------------------
validating dataset ....passed
Writting process 889CCA293AE2E9DB8ABF95592C8011EE_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 889CCA293AE2E9DB8ABF95592C8011EE_2... done.
Writting process 889CCA293AE2E9DB8ABF95592C8011EE_1... done.
Writting process 889CCA293AE2E9DB8ABF95592C8011EE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched889CCA293AE2E9DB8ABF95592C8011EE.report
Scheduling successful
submit!!!
jobs = 152
day = 126 run = 15126049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126049/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:18:11 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 09:18:11 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:18:11 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:18:11 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:18:11 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 887C2003EE32AF7702396A393B947D80_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 887C2003EE32AF7702396A393B947D80_1... done.
Writting process 887C2003EE32AF7702396A393B947D80_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched887C2003EE32AF7702396A393B947D80.report
Scheduling successful
submit!!!
jobs = 152
day = 126 run = 15126050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126050/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:19:26 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 09:19:28 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:19:29 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:19:32 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:19:32 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 0CD379BC7247F20DC6443A4D67C7125B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0CD379BC7247F20DC6443A4D67C7125B_1... done.
Writting process 0CD379BC7247F20DC6443A4D67C7125B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0CD379BC7247F20DC6443A4D67C7125B.report
Scheduling successful
submit!!!
jobs = 153
day = 126 run = 15126051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126051/*.root.log: No such file or directory
202
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:20:54 PDT] Dataset size is 202 files
Removing files not on site LBL
[2017.09.05 09:20:55 PDT] Dataset size is 202 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:20:57 PDT] Dataset size is 202 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:21:00 PDT] Started with 202 files, current size is 202files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:21:01 PDT] Dataset size is 202 files
----------------------------------------------------
validating dataset ....passed
Writting process A379F71277C81A89BECEB47C97F9E8D0_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A379F71277C81A89BECEB47C97F9E8D0_2... done.
Writting process A379F71277C81A89BECEB47C97F9E8D0_1... done.
Writting process A379F71277C81A89BECEB47C97F9E8D0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA379F71277C81A89BECEB47C97F9E8D0.report
Scheduling successful
submit!!!
jobs = 153
day = 126 run = 15126052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126052/*.root.log: No such file or directory
218
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:22:18 PDT] Dataset size is 218 files
Removing files not on site LBL
[2017.09.05 09:22:19 PDT] Dataset size is 218 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:22:21 PDT] Dataset size is 218 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:22:24 PDT] Started with 218 files, current size is 218files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:22:26 PDT] Dataset size is 218 files
----------------------------------------------------
validating dataset ....passed
Writting process 251780C3E91893E39F78FFE31CA6248C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 251780C3E91893E39F78FFE31CA6248C_2... done.
Writting process 251780C3E91893E39F78FFE31CA6248C_1... done.
Writting process 251780C3E91893E39F78FFE31CA6248C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched251780C3E91893E39F78FFE31CA6248C.report
Scheduling successful
submit!!!
jobs = 155
day = 126 run = 15126053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126053/*.root.log: No such file or directory
144
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:23:43 PDT] Dataset size is 144 files
Removing files not on site LBL
[2017.09.05 09:23:45 PDT] Dataset size is 144 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:23:46 PDT] Dataset size is 144 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:23:49 PDT] Started with 144 files, current size is 144files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:23:50 PDT] Dataset size is 144 files
----------------------------------------------------
validating dataset ....passed
Writting process A1E510838F69A8F92F2DA08DDEEA134F_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A1E510838F69A8F92F2DA08DDEEA134F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA1E510838F69A8F92F2DA08DDEEA134F.report
Scheduling successful
submit!!!
jobs = 157
day = 126 run = 15126054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15126054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15126054/*.root.log: No such file or directory
67
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:25:02 PDT] Dataset size is 67 files
Removing files not on site LBL
[2017.09.05 09:25:02 PDT] Dataset size is 67 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:25:03 PDT] Dataset size is 67 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:25:04 PDT] Started with 67 files, current size is 67files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:25:04 PDT] Dataset size is 67 files
----------------------------------------------------
validating dataset ....passed
Writting process 5E1CB4D2E3576FDD55F82EAC667C3EB6_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5E1CB4D2E3576FDD55F82EAC667C3EB6.report
Scheduling successful
submit!!!
Job submission for day 126 finished!
127
jobs = 153
day = 127 run = 15127004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127004/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:26:22 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 09:26:23 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:26:25 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:26:28 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:26:31 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process 1FB92393D18F7E80F1A2087C79998837_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1FB92393D18F7E80F1A2087C79998837_1... done.
Writting process 1FB92393D18F7E80F1A2087C79998837_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1FB92393D18F7E80F1A2087C79998837.report
Scheduling successful
submit!!!
jobs = 150
day = 127 run = 15127005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127005/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:27:58 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 09:28:01 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:28:02 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:28:07 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:28:08 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 346AF3ADE804C86AF6D191F550E17942_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 346AF3ADE804C86AF6D191F550E17942_1... done.
Writting process 346AF3ADE804C86AF6D191F550E17942_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched346AF3ADE804C86AF6D191F550E17942.report
Scheduling successful
submit!!!
jobs = 150
day = 127 run = 15127006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127006/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:29:24 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 09:29:24 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:29:25 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:29:27 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:29:28 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 494C158242F01E953B436340A5BEE3FD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 494C158242F01E953B436340A5BEE3FD_1... done.
Writting process 494C158242F01E953B436340A5BEE3FD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched494C158242F01E953B436340A5BEE3FD.report
Scheduling successful
submit!!!
jobs = 150
day = 127 run = 15127007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127007/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:30:42 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 09:30:42 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:30:43 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:30:45 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:30:46 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 0FFA00BF384B50588B59784BA21DAFE0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0FFA00BF384B50588B59784BA21DAFE0_1... done.
Writting process 0FFA00BF384B50588B59784BA21DAFE0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0FFA00BF384B50588B59784BA21DAFE0.report
Scheduling successful
submit!!!
jobs = 152
day = 127 run = 15127009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127009/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:32:02 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 09:32:03 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:32:04 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:32:06 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:32:07 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process 1B880E836FD2ADF247CEB96C9303821F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1B880E836FD2ADF247CEB96C9303821F_1... done.
Writting process 1B880E836FD2ADF247CEB96C9303821F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1B880E836FD2ADF247CEB96C9303821F.report
Scheduling successful
submit!!!
jobs = 153
day = 127 run = 15127010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127010/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:33:25 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 09:33:26 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:33:27 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:33:29 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:33:30 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process F06E06399C82B2A0102B6B0573AFA43A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F06E06399C82B2A0102B6B0573AFA43A_1... done.
Writting process F06E06399C82B2A0102B6B0573AFA43A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF06E06399C82B2A0102B6B0573AFA43A.report
Scheduling successful
submit!!!
jobs = 155
day = 127 run = 15127011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127011/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:34:44 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 09:34:45 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:34:46 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:34:46 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:34:47 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process F3C48D324C504B937572ABA171CFE3B0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F3C48D324C504B937572ABA171CFE3B0_1... done.
Writting process F3C48D324C504B937572ABA171CFE3B0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF3C48D324C504B937572ABA171CFE3B0.report
Scheduling successful
submit!!!
jobs = 156
day = 127 run = 15127012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127012/*.root.log: No such file or directory
95
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:35:57 PDT] Dataset size is 95 files
Removing files not on site LBL
[2017.09.05 09:35:57 PDT] Dataset size is 95 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:35:58 PDT] Dataset size is 95 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:35:58 PDT] Started with 95 files, current size is 95files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:35:58 PDT] Dataset size is 95 files
----------------------------------------------------
validating dataset ....passed
Writting process CB00C80CA6CDA0B5BE237C6874CA2DE9_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCB00C80CA6CDA0B5BE237C6874CA2DE9.report
Scheduling successful
submit!!!
jobs = 154
day = 127 run = 15127013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15127013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15127013/*.root.log: No such file or directory
158
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:37:14 PDT] Dataset size is 158 files
Removing files not on site LBL
[2017.09.05 09:37:14 PDT] Dataset size is 158 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:37:15 PDT] Dataset size is 158 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:37:16 PDT] Started with 158 files, current size is 158files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:37:18 PDT] Dataset size is 158 files
----------------------------------------------------
validating dataset ....passed
Writting process E1537922389B300F2AFA293914E12873_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E1537922389B300F2AFA293914E12873_1... done.
Writting process E1537922389B300F2AFA293914E12873_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE1537922389B300F2AFA293914E12873.report
Scheduling successful
submit!!!
Job submission for day 127 finished!
128
jobs = 157
day = 128 run = 15128022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128022/*.root.log: No such file or directory
24
24 24
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:38:32 PDT] Dataset size is 24 files
Removing files not on site LBL
[2017.09.05 09:38:32 PDT] Dataset size is 24 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:38:32 PDT] Dataset size is 24 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:38:32 PDT] Started with 24 files, current size is 24files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=24 ,maxSize=24 )
[2017.09.05 09:38:32 PDT] Dataset size is 24 files
----------------------------------------------------
validating dataset ....passed
Writting process 208191E2B303C941D4EAD075D37E5DE2_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched208191E2B303C941D4EAD075D37E5DE2.report
Scheduling successful
submit!!!
jobs = 156
day = 128 run = 15128024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128024/*.root.log: No such file or directory
239
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:39:48 PDT] Dataset size is 239 files
Removing files not on site LBL
[2017.09.05 09:39:49 PDT] Dataset size is 239 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:39:51 PDT] Dataset size is 239 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:39:53 PDT] Started with 239 files, current size is 239files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:39:54 PDT] Dataset size is 239 files
----------------------------------------------------
validating dataset ....passed
Writting process DD91F5E16CAF81A2F01670F285A0CCEB_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DD91F5E16CAF81A2F01670F285A0CCEB_2... done.
Writting process DD91F5E16CAF81A2F01670F285A0CCEB_1... done.
Writting process DD91F5E16CAF81A2F01670F285A0CCEB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDD91F5E16CAF81A2F01670F285A0CCEB.report
Scheduling successful
submit!!!
jobs = 158
day = 128 run = 15128025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128025/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:41:27 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 09:41:29 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:41:31 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:41:33 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:41:34 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process B2F445F8F2C2C77EB66C987AC8D5F1B1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B2F445F8F2C2C77EB66C987AC8D5F1B1_1... done.
Writting process B2F445F8F2C2C77EB66C987AC8D5F1B1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB2F445F8F2C2C77EB66C987AC8D5F1B1.report
Scheduling successful
submit!!!
jobs = 156
day = 128 run = 15128026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128026/*.root.log: No such file or directory
245
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:42:52 PDT] Dataset size is 245 files
Removing files not on site LBL
[2017.09.05 09:42:53 PDT] Dataset size is 245 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:42:53 PDT] Dataset size is 245 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:42:54 PDT] Started with 245 files, current size is 245files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:42:54 PDT] Dataset size is 245 files
----------------------------------------------------
validating dataset ....passed
Writting process 1174EDD322FB62EC094A793385F90C26_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1174EDD322FB62EC094A793385F90C26_2... done.
Writting process 1174EDD322FB62EC094A793385F90C26_1... done.
Writting process 1174EDD322FB62EC094A793385F90C26_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1174EDD322FB62EC094A793385F90C26.report
Scheduling successful
submit!!!
jobs = 157
day = 128 run = 15128027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128027/*.root.log: No such file or directory
123
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:44:09 PDT] Dataset size is 123 files
Removing files not on site LBL
[2017.09.05 09:44:10 PDT] Dataset size is 123 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:44:11 PDT] Dataset size is 123 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:44:12 PDT] Started with 123 files, current size is 123files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:44:13 PDT] Dataset size is 123 files
----------------------------------------------------
validating dataset ....passed
Writting process 2ABD6007809E93832125D11247FA7FF1_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2ABD6007809E93832125D11247FA7FF1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2ABD6007809E93832125D11247FA7FF1.report
Scheduling successful
submit!!!
jobs = 156
day = 128 run = 15128028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128028/*.root.log: No such file or directory
259
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:45:34 PDT] Dataset size is 259 files
Removing files not on site LBL
[2017.09.05 09:45:35 PDT] Dataset size is 259 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:45:37 PDT] Dataset size is 259 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:45:40 PDT] Started with 259 files, current size is 259files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:45:43 PDT] Dataset size is 259 files
----------------------------------------------------
validating dataset ....passed
Writting process C518716BD8474755658FDF3CFFD2E630_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C518716BD8474755658FDF3CFFD2E630_3... done.
Writting process C518716BD8474755658FDF3CFFD2E630_2... done.
Writting process C518716BD8474755658FDF3CFFD2E630_1... done.
Writting process C518716BD8474755658FDF3CFFD2E630_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC518716BD8474755658FDF3CFFD2E630.report
Scheduling successful
submit!!!
jobs = 157
day = 128 run = 15128029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128029/*.root.log: No such file or directory
254
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:46:58 PDT] Dataset size is 254 files
Removing files not on site LBL
[2017.09.05 09:46:59 PDT] Dataset size is 254 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:47:00 PDT] Dataset size is 254 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:47:02 PDT] Started with 254 files, current size is 254files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:47:03 PDT] Dataset size is 254 files
----------------------------------------------------
validating dataset ....passed
Writting process D78769D2DE91AD3E8406D5FF3AA8EB9D_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D78769D2DE91AD3E8406D5FF3AA8EB9D_3... done.
Writting process D78769D2DE91AD3E8406D5FF3AA8EB9D_2... done.
Writting process D78769D2DE91AD3E8406D5FF3AA8EB9D_1... done.
Writting process D78769D2DE91AD3E8406D5FF3AA8EB9D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD78769D2DE91AD3E8406D5FF3AA8EB9D.report
Scheduling successful
submit!!!
jobs = 162
day = 128 run = 15128030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128030/*.root.log: No such file or directory
63
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:48:19 PDT] Dataset size is 63 files
Removing files not on site LBL
[2017.09.05 09:48:20 PDT] Dataset size is 63 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:48:22 PDT] Dataset size is 63 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:48:25 PDT] Started with 63 files, current size is 63files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:48:26 PDT] Dataset size is 63 files
----------------------------------------------------
validating dataset ....passed
Writting process 936F53903ABD471608673554B3C740F8_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched936F53903ABD471608673554B3C740F8.report
Scheduling successful
submit!!!
jobs = 158
day = 128 run = 15128031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128031/*.root.log: No such file or directory
82
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:49:48 PDT] Dataset size is 82 files
Removing files not on site LBL
[2017.09.05 09:49:49 PDT] Dataset size is 82 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:49:50 PDT] Dataset size is 82 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:49:53 PDT] Started with 82 files, current size is 82files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:49:54 PDT] Dataset size is 82 files
----------------------------------------------------
validating dataset ....passed
Writting process 2668D2B1E5E8BD92730B5D414D3549FC_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2668D2B1E5E8BD92730B5D414D3549FC.report
Scheduling successful
submit!!!
jobs = 156
day = 128 run = 15128032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128032/*.root.log: No such file or directory
220
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:51:09 PDT] Dataset size is 220 files
Removing files not on site LBL
[2017.09.05 09:51:09 PDT] Dataset size is 220 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:51:09 PDT] Dataset size is 220 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:51:09 PDT] Started with 220 files, current size is 220files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:51:09 PDT] Dataset size is 220 files
----------------------------------------------------
validating dataset ....passed
Writting process B4A639947FFFCD5736E38E8089974944_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B4A639947FFFCD5736E38E8089974944_2... done.
Writting process B4A639947FFFCD5736E38E8089974944_1... done.
Writting process B4A639947FFFCD5736E38E8089974944_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB4A639947FFFCD5736E38E8089974944.report
Scheduling successful
submit!!!
jobs = 154
day = 128 run = 15128033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15128033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15128033/*.root.log: No such file or directory
128
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:52:20 PDT] Dataset size is 128 files
Removing files not on site LBL
[2017.09.05 09:52:20 PDT] Dataset size is 128 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:52:20 PDT] Dataset size is 128 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:52:21 PDT] Started with 128 files, current size is 128files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:52:22 PDT] Dataset size is 128 files
----------------------------------------------------
validating dataset ....passed
Writting process 83A55F690D848133DAE389E42EDCF1B9_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 83A55F690D848133DAE389E42EDCF1B9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched83A55F690D848133DAE389E42EDCF1B9.report
Scheduling successful
submit!!!
Job submission for day 128 finished!
129
jobs = 153
day = 129 run = 15129002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129002/*.root.log: No such file or directory
153
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:53:35 PDT] Dataset size is 153 files
Removing files not on site LBL
[2017.09.05 09:53:36 PDT] Dataset size is 153 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:53:36 PDT] Dataset size is 153 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:53:37 PDT] Started with 153 files, current size is 153files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:53:37 PDT] Dataset size is 153 files
----------------------------------------------------
validating dataset ....passed
Writting process ED4593649B70DCFA405A2260E669724E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ED4593649B70DCFA405A2260E669724E_1... done.
Writting process ED4593649B70DCFA405A2260E669724E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedED4593649B70DCFA405A2260E669724E.report
Scheduling successful
submit!!!
jobs = 155
day = 129 run = 15129003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129003/*.root.log: No such file or directory
98
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:54:46 PDT] Dataset size is 98 files
Removing files not on site LBL
[2017.09.05 09:54:47 PDT] Dataset size is 98 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:54:48 PDT] Dataset size is 98 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:54:50 PDT] Started with 98 files, current size is 98files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:54:50 PDT] Dataset size is 98 files
----------------------------------------------------
validating dataset ....passed
Writting process 2D4D304EFC2B6F25432479640EDFB944_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2D4D304EFC2B6F25432479640EDFB944.report
Scheduling successful
submit!!!
jobs = 153
day = 129 run = 15129004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129004/*.root.log: No such file or directory
154
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:56:08 PDT] Dataset size is 154 files
Removing files not on site LBL
[2017.09.05 09:56:10 PDT] Dataset size is 154 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:56:12 PDT] Dataset size is 154 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:56:14 PDT] Started with 154 files, current size is 154files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:56:16 PDT] Dataset size is 154 files
----------------------------------------------------
validating dataset ....passed
Writting process 447FE8435D80FBEEA2B0543C171414C2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 447FE8435D80FBEEA2B0543C171414C2_1... done.
Writting process 447FE8435D80FBEEA2B0543C171414C2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched447FE8435D80FBEEA2B0543C171414C2.report
Scheduling successful
submit!!!
jobs = 153
day = 129 run = 15129006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129006/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:57:30 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 09:57:30 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:57:30 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:57:30 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:57:31 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process ADB436DD2DD8DFD6F169D2AB0FA2CC9D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ADB436DD2DD8DFD6F169D2AB0FA2CC9D_1... done.
Writting process ADB436DD2DD8DFD6F169D2AB0FA2CC9D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedADB436DD2DD8DFD6F169D2AB0FA2CC9D.report
Scheduling successful
submit!!!
jobs = 153
day = 129 run = 15129007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129007/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 09:58:51 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 09:58:51 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 09:58:52 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 09:58:53 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 09:58:54 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 845B08DE1782F9BE51342DF8D5D33558_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 845B08DE1782F9BE51342DF8D5D33558_1... done.
Writting process 845B08DE1782F9BE51342DF8D5D33558_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched845B08DE1782F9BE51342DF8D5D33558.report
Scheduling successful
submit!!!
jobs = 156
day = 129 run = 15129009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129009/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:00:20 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 10:00:23 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:00:25 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:00:31 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:00:35 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 9A8767226E575E775E11C0EA80289B5F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9A8767226E575E775E11C0EA80289B5F_1... done.
Writting process 9A8767226E575E775E11C0EA80289B5F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9A8767226E575E775E11C0EA80289B5F.report
Scheduling successful
submit!!!
jobs = 156
day = 129 run = 15129010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129010/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:02:12 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 10:02:16 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:02:18 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:02:21 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:02:21 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 813484FFA23F04EC1B0E4B73B7E527AF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 813484FFA23F04EC1B0E4B73B7E527AF_1... done.
Writting process 813484FFA23F04EC1B0E4B73B7E527AF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched813484FFA23F04EC1B0E4B73B7E527AF.report
Scheduling successful
submit!!!
jobs = 155
day = 129 run = 15129011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129011/*.root.log: No such file or directory
149
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:03:43 PDT] Dataset size is 149 files
Removing files not on site LBL
[2017.09.05 10:03:44 PDT] Dataset size is 149 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:03:45 PDT] Dataset size is 149 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:03:48 PDT] Started with 149 files, current size is 149files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:03:48 PDT] Dataset size is 149 files
----------------------------------------------------
validating dataset ....passed
Writting process 4D40B5ED6D3162C095BFD4D0D8B61729_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4D40B5ED6D3162C095BFD4D0D8B61729_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4D40B5ED6D3162C095BFD4D0D8B61729.report
Scheduling successful
submit!!!
jobs = 154
day = 129 run = 15129012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129012/*.root.log: No such file or directory
241
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:05:44 PDT] Dataset size is 241 files
Removing files not on site LBL
[2017.09.05 10:05:46 PDT] Dataset size is 241 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:05:49 PDT] Dataset size is 241 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:05:50 PDT] Started with 241 files, current size is 241files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:05:50 PDT] Dataset size is 241 files
----------------------------------------------------
validating dataset ....passed
Writting process CD9B2791730228681594E46BF60F2892_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CD9B2791730228681594E46BF60F2892_2... done.
Writting process CD9B2791730228681594E46BF60F2892_1... done.
Writting process CD9B2791730228681594E46BF60F2892_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCD9B2791730228681594E46BF60F2892.report
Scheduling successful
submit!!!
jobs = 153
day = 129 run = 15129013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129013/*.root.log: No such file or directory
255
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:07:16 PDT] Dataset size is 255 files
Removing files not on site LBL
[2017.09.05 10:07:17 PDT] Dataset size is 255 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:07:18 PDT] Dataset size is 255 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:07:18 PDT] Started with 255 files, current size is 255files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:07:18 PDT] Dataset size is 255 files
----------------------------------------------------
validating dataset ....passed
Writting process F0253B195B20C9F7D19F9E5C5C0C5D8B_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F0253B195B20C9F7D19F9E5C5C0C5D8B_3... done.
Writting process F0253B195B20C9F7D19F9E5C5C0C5D8B_2... done.
Writting process F0253B195B20C9F7D19F9E5C5C0C5D8B_1... done.
Writting process F0253B195B20C9F7D19F9E5C5C0C5D8B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF0253B195B20C9F7D19F9E5C5C0C5D8B.report
Scheduling successful
submit!!!
jobs = 156
day = 129 run = 15129014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129014/*.root.log: No such file or directory
75
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:08:42 PDT] Dataset size is 75 files
Removing files not on site LBL
[2017.09.05 10:08:43 PDT] Dataset size is 75 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:08:44 PDT] Dataset size is 75 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:08:45 PDT] Started with 75 files, current size is 75files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:08:45 PDT] Dataset size is 75 files
----------------------------------------------------
validating dataset ....passed
Writting process 5E3A5A0A7665E7DC6EADD5136AE90125_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5E3A5A0A7665E7DC6EADD5136AE90125.report
Scheduling successful
submit!!!
jobs = 155
day = 129 run = 15129015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129015/*.root.log: No such file or directory
212
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:10:25 PDT] Dataset size is 212 files
Removing files not on site LBL
[2017.09.05 10:10:25 PDT] Dataset size is 212 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:10:25 PDT] Dataset size is 212 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:10:25 PDT] Started with 212 files, current size is 212files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:10:25 PDT] Dataset size is 212 files
----------------------------------------------------
validating dataset ....passed
Writting process F8F997CACBCED29353539A26D2FC5FD2_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F8F997CACBCED29353539A26D2FC5FD2_2... done.
Writting process F8F997CACBCED29353539A26D2FC5FD2_1... done.
Writting process F8F997CACBCED29353539A26D2FC5FD2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF8F997CACBCED29353539A26D2FC5FD2.report
Scheduling successful
submit!!!
jobs = 158
day = 129 run = 15129016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129016/*.root.log: No such file or directory
217
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:11:44 PDT] Dataset size is 217 files
Removing files not on site LBL
[2017.09.05 10:11:44 PDT] Dataset size is 217 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:11:45 PDT] Dataset size is 217 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:11:45 PDT] Started with 217 files, current size is 217files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:11:45 PDT] Dataset size is 217 files
----------------------------------------------------
validating dataset ....passed
Writting process 4502AC20A79B1B2B8777D22171E08A44_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4502AC20A79B1B2B8777D22171E08A44_2... done.
Writting process 4502AC20A79B1B2B8777D22171E08A44_1... done.
Writting process 4502AC20A79B1B2B8777D22171E08A44_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4502AC20A79B1B2B8777D22171E08A44.report
Scheduling successful
submit!!!
jobs = 158
day = 129 run = 15129017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129017/*.root.log: No such file or directory
104
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:13:01 PDT] Dataset size is 104 files
Removing files not on site LBL
[2017.09.05 10:13:02 PDT] Dataset size is 104 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:13:04 PDT] Dataset size is 104 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:13:07 PDT] Started with 104 files, current size is 104files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:13:08 PDT] Dataset size is 104 files
----------------------------------------------------
validating dataset ....passed
Writting process D48353C1DCA4DD90D5F401784EAF999D_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D48353C1DCA4DD90D5F401784EAF999D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD48353C1DCA4DD90D5F401784EAF999D.report
Scheduling successful
submit!!!
jobs = 159
day = 129 run = 15129018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129018/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:14:22 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 10:14:23 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:14:24 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:14:28 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:14:30 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process B866EE3DDB849415E1E244EB61D097CD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B866EE3DDB849415E1E244EB61D097CD_1... done.
Writting process B866EE3DDB849415E1E244EB61D097CD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB866EE3DDB849415E1E244EB61D097CD.report
Scheduling successful
submit!!!
jobs = 160
day = 129 run = 15129022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129022/*.root.log: No such file or directory
68
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:15:45 PDT] Dataset size is 68 files
Removing files not on site LBL
[2017.09.05 10:15:46 PDT] Dataset size is 68 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:15:48 PDT] Dataset size is 68 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:15:52 PDT] Started with 68 files, current size is 68files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:15:53 PDT] Dataset size is 68 files
----------------------------------------------------
validating dataset ....passed
Writting process 10698E685EA95BA55779AAB93091A812_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched10698E685EA95BA55779AAB93091A812.report
Scheduling successful
submit!!!
jobs = 161
day = 129 run = 15129050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129050/*.root.log: No such file or directory
225
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:17:06 PDT] Dataset size is 225 files
Removing files not on site LBL
[2017.09.05 10:17:07 PDT] Dataset size is 225 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:17:07 PDT] Dataset size is 225 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:17:07 PDT] Started with 225 files, current size is 225files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:17:07 PDT] Dataset size is 225 files
----------------------------------------------------
validating dataset ....passed
Writting process A6A411EA990ECED1BC91921CBE34A76B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A6A411EA990ECED1BC91921CBE34A76B_2... done.
Writting process A6A411EA990ECED1BC91921CBE34A76B_1... done.
Writting process A6A411EA990ECED1BC91921CBE34A76B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA6A411EA990ECED1BC91921CBE34A76B.report
Scheduling successful
submit!!!
jobs = 164
day = 129 run = 15129051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129051/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:18:25 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 10:18:29 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:18:32 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:18:40 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:18:44 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process 402938D19D1C723557B6F23559554FB8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 402938D19D1C723557B6F23559554FB8_1... done.
Writting process 402938D19D1C723557B6F23559554FB8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched402938D19D1C723557B6F23559554FB8.report
Scheduling successful
submit!!!
jobs = 165
day = 129 run = 15129052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15129052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15129052/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:20:01 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 10:20:02 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:20:04 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:20:06 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:20:07 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process D3810F7FB8CEF8ECEDD55F94C1406EB4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D3810F7FB8CEF8ECEDD55F94C1406EB4_1... done.
Writting process D3810F7FB8CEF8ECEDD55F94C1406EB4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD3810F7FB8CEF8ECEDD55F94C1406EB4.report
Scheduling successful
submit!!!
Job submission for day 129 finished!
130
jobs = 166
day = 130 run = 15130001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130001/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:21:22 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 10:21:23 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:21:25 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:21:28 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:21:29 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 34091A536146EAEF7CC7A6753FF46D25_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 34091A536146EAEF7CC7A6753FF46D25_1... done.
Writting process 34091A536146EAEF7CC7A6753FF46D25_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched34091A536146EAEF7CC7A6753FF46D25.report
Scheduling successful
submit!!!
jobs = 168
day = 130 run = 15130002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130002/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:22:43 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 10:22:43 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:22:43 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:22:43 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:22:43 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process AEAAFCC6B68EC286EE598D98E509DB1D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AEAAFCC6B68EC286EE598D98E509DB1D_1... done.
Writting process AEAAFCC6B68EC286EE598D98E509DB1D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAEAAFCC6B68EC286EE598D98E509DB1D.report
Scheduling successful
submit!!!
jobs = 169
day = 130 run = 15130003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130003/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:23:59 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 10:24:02 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:24:03 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:24:11 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:24:12 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 80C4ED582539C08C1004E50A1FF2CF82_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 80C4ED582539C08C1004E50A1FF2CF82_1... done.
Writting process 80C4ED582539C08C1004E50A1FF2CF82_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched80C4ED582539C08C1004E50A1FF2CF82.report
Scheduling successful
submit!!!
jobs = 169
day = 130 run = 15130004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130004/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:25:29 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 10:25:30 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:25:31 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:25:34 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:25:35 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process 0F2DC7E6C43BC4480BB1BF526ED2D815_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0F2DC7E6C43BC4480BB1BF526ED2D815_1... done.
Writting process 0F2DC7E6C43BC4480BB1BF526ED2D815_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0F2DC7E6C43BC4480BB1BF526ED2D815.report
Scheduling successful
submit!!!
jobs = 172
day = 130 run = 15130005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130005/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:26:50 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 10:26:51 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:26:51 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:26:53 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:26:53 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 0A65AFFAE7D39884F329ADEC783F51CE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0A65AFFAE7D39884F329ADEC783F51CE_1... done.
Writting process 0A65AFFAE7D39884F329ADEC783F51CE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0A65AFFAE7D39884F329ADEC783F51CE.report
Scheduling successful
submit!!!
jobs = 173
day = 130 run = 15130006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130006/*.root.log: No such file or directory
62
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:28:05 PDT] Dataset size is 62 files
Removing files not on site LBL
[2017.09.05 10:28:07 PDT] Dataset size is 62 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:28:08 PDT] Dataset size is 62 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:28:11 PDT] Started with 62 files, current size is 62files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:28:11 PDT] Dataset size is 62 files
----------------------------------------------------
validating dataset ....passed
Writting process EBB6A8A40248560C5B0926E593F10FA0_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEBB6A8A40248560C5B0926E593F10FA0.report
Scheduling successful
submit!!!
jobs = 172
day = 130 run = 15130007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130007/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:29:28 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 10:29:29 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:29:31 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:29:34 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:29:36 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 2A1A6AB1D2995E76CDAFF217374EBAC9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2A1A6AB1D2995E76CDAFF217374EBAC9_1... done.
Writting process 2A1A6AB1D2995E76CDAFF217374EBAC9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2A1A6AB1D2995E76CDAFF217374EBAC9.report
Scheduling successful
submit!!!
jobs = 173
day = 130 run = 15130008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130008/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:30:55 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 10:30:55 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:30:55 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:30:56 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:30:56 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 1DD4D6F93663C90A7DDE8A56FE4FC919_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1DD4D6F93663C90A7DDE8A56FE4FC919_1... done.
Writting process 1DD4D6F93663C90A7DDE8A56FE4FC919_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1DD4D6F93663C90A7DDE8A56FE4FC919.report
Scheduling successful
submit!!!
jobs = 175
day = 130 run = 15130009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130009/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:32:09 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 10:32:09 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:32:09 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:32:11 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:32:11 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 16DEA9AA01C681DEE963F32AE9DB5090_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 16DEA9AA01C681DEE963F32AE9DB5090_1... done.
Writting process 16DEA9AA01C681DEE963F32AE9DB5090_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched16DEA9AA01C681DEE963F32AE9DB5090.report
Scheduling successful
submit!!!
jobs = 174
day = 130 run = 15130011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130011/*.root.log: No such file or directory
125
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:33:25 PDT] Dataset size is 125 files
Removing files not on site LBL
[2017.09.05 10:33:26 PDT] Dataset size is 125 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:33:27 PDT] Dataset size is 125 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:33:30 PDT] Started with 125 files, current size is 125files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:33:31 PDT] Dataset size is 125 files
----------------------------------------------------
validating dataset ....passed
Writting process 3E8F7B41E577502B3F87B57806E67447_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3E8F7B41E577502B3F87B57806E67447_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3E8F7B41E577502B3F87B57806E67447.report
Scheduling successful
submit!!!
jobs = 170
day = 130 run = 15130037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130037/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:34:47 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 10:34:48 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:34:49 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:34:52 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:34:53 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process AF3A8D6B7A6EFD52B46F5E9FB6D841FA_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AF3A8D6B7A6EFD52B46F5E9FB6D841FA_1... done.
Writting process AF3A8D6B7A6EFD52B46F5E9FB6D841FA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAF3A8D6B7A6EFD52B46F5E9FB6D841FA.report
Scheduling successful
submit!!!
jobs = 170
day = 130 run = 15130038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130038/*.root.log: No such file or directory
216
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:36:07 PDT] Dataset size is 216 files
Removing files not on site LBL
[2017.09.05 10:36:07 PDT] Dataset size is 216 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:36:07 PDT] Dataset size is 216 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:36:07 PDT] Started with 216 files, current size is 216files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:36:07 PDT] Dataset size is 216 files
----------------------------------------------------
validating dataset ....passed
Writting process 6DB55CCE0126A38FF162C8CCBD9AD27B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6DB55CCE0126A38FF162C8CCBD9AD27B_2... done.
Writting process 6DB55CCE0126A38FF162C8CCBD9AD27B_1... done.
Writting process 6DB55CCE0126A38FF162C8CCBD9AD27B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6DB55CCE0126A38FF162C8CCBD9AD27B.report
Scheduling successful
submit!!!
jobs = 170
day = 130 run = 15130040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130040/*.root.log: No such file or directory
223
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:37:21 PDT] Dataset size is 223 files
Removing files not on site LBL
[2017.09.05 10:37:21 PDT] Dataset size is 223 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:37:21 PDT] Dataset size is 223 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:37:21 PDT] Started with 223 files, current size is 223files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:37:21 PDT] Dataset size is 223 files
----------------------------------------------------
validating dataset ....passed
Writting process A6BE3CEAAAD546D46AC97DC0890A1758_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A6BE3CEAAAD546D46AC97DC0890A1758_2... done.
Writting process A6BE3CEAAAD546D46AC97DC0890A1758_1... done.
Writting process A6BE3CEAAAD546D46AC97DC0890A1758_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA6BE3CEAAAD546D46AC97DC0890A1758.report
Scheduling successful
submit!!!
jobs = 167
day = 130 run = 15130041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130041/*.root.log: No such file or directory
258
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:38:36 PDT] Dataset size is 258 files
Removing files not on site LBL
[2017.09.05 10:38:36 PDT] Dataset size is 258 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:38:36 PDT] Dataset size is 258 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:38:36 PDT] Started with 258 files, current size is 258files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:38:36 PDT] Dataset size is 258 files
----------------------------------------------------
validating dataset ....passed
Writting process 6C7319C3A412A4D4FB69CA45486E1041_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6C7319C3A412A4D4FB69CA45486E1041_3... done.
Writting process 6C7319C3A412A4D4FB69CA45486E1041_2... done.
Writting process 6C7319C3A412A4D4FB69CA45486E1041_1... done.
Writting process 6C7319C3A412A4D4FB69CA45486E1041_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6C7319C3A412A4D4FB69CA45486E1041.report
Scheduling successful
submit!!!
jobs = 171
day = 130 run = 15130042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130042/*.root.log: No such file or directory
233
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:39:50 PDT] Dataset size is 233 files
Removing files not on site LBL
[2017.09.05 10:39:52 PDT] Dataset size is 233 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:39:54 PDT] Dataset size is 233 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:39:56 PDT] Started with 233 files, current size is 233files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:39:57 PDT] Dataset size is 233 files
----------------------------------------------------
validating dataset ....passed
Writting process 48B82CC0073D2AB85E4511BB392DC7D4_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 48B82CC0073D2AB85E4511BB392DC7D4_2... done.
Writting process 48B82CC0073D2AB85E4511BB392DC7D4_1... done.
Writting process 48B82CC0073D2AB85E4511BB392DC7D4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched48B82CC0073D2AB85E4511BB392DC7D4.report
Scheduling successful
submit!!!
jobs = 173
day = 130 run = 15130043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130043/*.root.log: No such file or directory
202
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:41:13 PDT] Dataset size is 202 files
Removing files not on site LBL
[2017.09.05 10:41:14 PDT] Dataset size is 202 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:41:14 PDT] Dataset size is 202 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:41:16 PDT] Started with 202 files, current size is 202files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:41:16 PDT] Dataset size is 202 files
----------------------------------------------------
validating dataset ....passed
Writting process 2DA33D7D5289705E8BB9801D9070BDD9_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2DA33D7D5289705E8BB9801D9070BDD9_2... done.
Writting process 2DA33D7D5289705E8BB9801D9070BDD9_1... done.
Writting process 2DA33D7D5289705E8BB9801D9070BDD9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2DA33D7D5289705E8BB9801D9070BDD9.report
Scheduling successful
submit!!!
jobs = 174
day = 130 run = 15130044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130044/*.root.log: No such file or directory
118
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:42:32 PDT] Dataset size is 118 files
Removing files not on site LBL
[2017.09.05 10:42:33 PDT] Dataset size is 118 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:42:33 PDT] Dataset size is 118 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:42:33 PDT] Started with 118 files, current size is 118files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:42:33 PDT] Dataset size is 118 files
----------------------------------------------------
validating dataset ....passed
Writting process 03BD92FA3ED6A9B7FB848D6A7A4299A3_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 03BD92FA3ED6A9B7FB848D6A7A4299A3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched03BD92FA3ED6A9B7FB848D6A7A4299A3.report
Scheduling successful
submit!!!
jobs = 174
day = 130 run = 15130045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130045/*.root.log: No such file or directory
252
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:43:50 PDT] Dataset size is 252 files
Removing files not on site LBL
[2017.09.05 10:43:51 PDT] Dataset size is 252 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:43:51 PDT] Dataset size is 252 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:43:52 PDT] Started with 252 files, current size is 252files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:43:54 PDT] Dataset size is 252 files
----------------------------------------------------
validating dataset ....passed
Writting process 7A43143BEB8F0372E16F28500702B778_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7A43143BEB8F0372E16F28500702B778_3... done.
Writting process 7A43143BEB8F0372E16F28500702B778_2... done.
Writting process 7A43143BEB8F0372E16F28500702B778_1... done.
Writting process 7A43143BEB8F0372E16F28500702B778_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7A43143BEB8F0372E16F28500702B778.report
Scheduling successful
submit!!!
jobs = 176
day = 130 run = 15130046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130046/*.root.log: No such file or directory
237
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:45:17 PDT] Dataset size is 237 files
Removing files not on site LBL
[2017.09.05 10:45:19 PDT] Dataset size is 237 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:45:20 PDT] Dataset size is 237 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:45:23 PDT] Started with 237 files, current size is 237files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:45:24 PDT] Dataset size is 237 files
----------------------------------------------------
validating dataset ....passed
Writting process AABB15A6D8688EF984BCFF7D1AEB13CA_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AABB15A6D8688EF984BCFF7D1AEB13CA_2... done.
Writting process AABB15A6D8688EF984BCFF7D1AEB13CA_1... done.
Writting process AABB15A6D8688EF984BCFF7D1AEB13CA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAABB15A6D8688EF984BCFF7D1AEB13CA.report
Scheduling successful
submit!!!
jobs = 177
day = 130 run = 15130047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130047/*.root.log: No such file or directory
258
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:46:44 PDT] Dataset size is 258 files
Removing files not on site LBL
[2017.09.05 10:46:47 PDT] Dataset size is 258 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:46:48 PDT] Dataset size is 258 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:46:48 PDT] Started with 258 files, current size is 258files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:46:50 PDT] Dataset size is 258 files
----------------------------------------------------
validating dataset ....passed
Writting process 8DEE8BD80E7D314D2C0C8F414D303798_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8DEE8BD80E7D314D2C0C8F414D303798_3... done.
Writting process 8DEE8BD80E7D314D2C0C8F414D303798_2... done.
Writting process 8DEE8BD80E7D314D2C0C8F414D303798_1... done.
Writting process 8DEE8BD80E7D314D2C0C8F414D303798_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8DEE8BD80E7D314D2C0C8F414D303798.report
Scheduling successful
submit!!!
jobs = 182
day = 130 run = 15130048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15130048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15130048/*.root.log: No such file or directory
58
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:48:02 PDT] Dataset size is 58 files
Removing files not on site LBL
[2017.09.05 10:48:03 PDT] Dataset size is 58 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:48:06 PDT] Dataset size is 58 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:48:08 PDT] Started with 58 files, current size is 58files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:48:08 PDT] Dataset size is 58 files
----------------------------------------------------
validating dataset ....passed
Writting process 22A668CAB0899DBA9AC64430CC26250D_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched22A668CAB0899DBA9AC64430CC26250D.report
Scheduling successful
submit!!!
Job submission for day 130 finished!
131
jobs = 182
day = 131 run = 15131004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131004/*.root.log: No such file or directory
153
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:49:20 PDT] Dataset size is 153 files
Removing files not on site LBL
[2017.09.05 10:49:20 PDT] Dataset size is 153 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:49:20 PDT] Dataset size is 153 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:49:20 PDT] Started with 153 files, current size is 153files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:49:20 PDT] Dataset size is 153 files
----------------------------------------------------
validating dataset ....passed
Writting process 8B7B65FD407115340B48E586B87F082B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8B7B65FD407115340B48E586B87F082B_1... done.
Writting process 8B7B65FD407115340B48E586B87F082B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8B7B65FD407115340B48E586B87F082B.report
Scheduling successful
submit!!!
jobs = 182
day = 131 run = 15131005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131005/*.root.log: No such file or directory
160
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:50:33 PDT] Dataset size is 160 files
Removing files not on site LBL
[2017.09.05 10:50:33 PDT] Dataset size is 160 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:50:33 PDT] Dataset size is 160 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:50:34 PDT] Started with 160 files, current size is 160files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:50:35 PDT] Dataset size is 160 files
----------------------------------------------------
validating dataset ....passed
Writting process 537EF66802F1BC0694D1CE772B6045F3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 537EF66802F1BC0694D1CE772B6045F3_1... done.
Writting process 537EF66802F1BC0694D1CE772B6045F3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched537EF66802F1BC0694D1CE772B6045F3.report
Scheduling successful
submit!!!
jobs = 182
day = 131 run = 15131006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131006/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:51:49 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 10:51:49 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:51:49 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:51:51 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:51:52 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 395DE7E06A7A599BA19EB63C5DD47D2D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 395DE7E06A7A599BA19EB63C5DD47D2D_1... done.
Writting process 395DE7E06A7A599BA19EB63C5DD47D2D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched395DE7E06A7A599BA19EB63C5DD47D2D.report
Scheduling successful
submit!!!
jobs = 183
day = 131 run = 15131007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131007/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:53:10 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 10:53:10 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:53:11 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:53:12 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:53:12 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process FB6696AFBF925BED4365216DB86DF62A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FB6696AFBF925BED4365216DB86DF62A_1... done.
Writting process FB6696AFBF925BED4365216DB86DF62A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFB6696AFBF925BED4365216DB86DF62A.report
Scheduling successful
submit!!!
jobs = 184
day = 131 run = 15131008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131008/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:54:25 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 10:54:25 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:54:25 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:54:25 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:54:25 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process 819E961A9A4532CCC6E567BC3714510E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 819E961A9A4532CCC6E567BC3714510E_1... done.
Writting process 819E961A9A4532CCC6E567BC3714510E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched819E961A9A4532CCC6E567BC3714510E.report
Scheduling successful
submit!!!
jobs = 185
day = 131 run = 15131009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131009/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:55:39 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 10:55:39 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:55:40 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:55:40 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:55:41 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process B324BE4314635746521420DDF25551B1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B324BE4314635746521420DDF25551B1_1... done.
Writting process B324BE4314635746521420DDF25551B1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB324BE4314635746521420DDF25551B1.report
Scheduling successful
submit!!!
jobs = 186
day = 131 run = 15131010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131010/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:56:54 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 10:56:54 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:56:54 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:56:54 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:56:55 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 43A32F2D65FC5097E20C1695E7101CCE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 43A32F2D65FC5097E20C1695E7101CCE_1... done.
Writting process 43A32F2D65FC5097E20C1695E7101CCE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched43A32F2D65FC5097E20C1695E7101CCE.report
Scheduling successful
submit!!!
jobs = 188
day = 131 run = 15131011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131011/*.root.log: No such file or directory
147
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:58:07 PDT] Dataset size is 147 files
Removing files not on site LBL
[2017.09.05 10:58:09 PDT] Dataset size is 147 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:58:10 PDT] Dataset size is 147 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:58:10 PDT] Started with 147 files, current size is 147files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:58:10 PDT] Dataset size is 147 files
----------------------------------------------------
validating dataset ....passed
Writting process F3343EBE1E86F8FB59401088EE30037F_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F3343EBE1E86F8FB59401088EE30037F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF3343EBE1E86F8FB59401088EE30037F.report
Scheduling successful
submit!!!
jobs = 189
day = 131 run = 15131012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131012/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 10:59:23 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 10:59:25 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 10:59:26 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 10:59:28 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 10:59:29 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process C51CE1651D5350D6116D532CE2A8A1B5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C51CE1651D5350D6116D532CE2A8A1B5_1... done.
Writting process C51CE1651D5350D6116D532CE2A8A1B5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC51CE1651D5350D6116D532CE2A8A1B5.report
Scheduling successful
submit!!!
jobs = 190
day = 131 run = 15131013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131013/*.root.log: No such file or directory
222
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:00:49 PDT] Dataset size is 222 files
Removing files not on site LBL
[2017.09.05 11:00:50 PDT] Dataset size is 222 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:00:52 PDT] Dataset size is 222 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:00:54 PDT] Started with 222 files, current size is 222files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:00:54 PDT] Dataset size is 222 files
----------------------------------------------------
validating dataset ....passed
Writting process 89212F98DFDD9A0F2635E56B49E9104B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 89212F98DFDD9A0F2635E56B49E9104B_2... done.
Writting process 89212F98DFDD9A0F2635E56B49E9104B_1... done.
Writting process 89212F98DFDD9A0F2635E56B49E9104B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched89212F98DFDD9A0F2635E56B49E9104B.report
Scheduling successful
submit!!!
jobs = 190
day = 131 run = 15131014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131014/*.root.log: No such file or directory
80
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:02:11 PDT] Dataset size is 80 files
Removing files not on site LBL
[2017.09.05 11:02:11 PDT] Dataset size is 80 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:02:11 PDT] Dataset size is 80 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:02:11 PDT] Started with 80 files, current size is 80files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:02:11 PDT] Dataset size is 80 files
----------------------------------------------------
validating dataset ....passed
Writting process E12A0A4FEAE6C5967C60D4E8FA3EB58C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE12A0A4FEAE6C5967C60D4E8FA3EB58C.report
Scheduling successful
submit!!!
jobs = 190
day = 131 run = 15131040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131040/*.root.log: No such file or directory
220
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:03:38 PDT] Dataset size is 220 files
Removing files not on site LBL
[2017.09.05 11:03:40 PDT] Dataset size is 220 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:03:41 PDT] Dataset size is 220 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:03:44 PDT] Started with 220 files, current size is 220files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:03:45 PDT] Dataset size is 220 files
----------------------------------------------------
validating dataset ....passed
Writting process 51F11A65319A06FD705E26C0598CC0BD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 51F11A65319A06FD705E26C0598CC0BD_2... done.
Writting process 51F11A65319A06FD705E26C0598CC0BD_1... done.
Writting process 51F11A65319A06FD705E26C0598CC0BD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched51F11A65319A06FD705E26C0598CC0BD.report
Scheduling successful
submit!!!
jobs = 190
day = 131 run = 15131041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131041/*.root.log: No such file or directory
203
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:05:06 PDT] Dataset size is 203 files
Removing files not on site LBL
[2017.09.05 11:05:06 PDT] Dataset size is 203 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:05:06 PDT] Dataset size is 203 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:05:06 PDT] Started with 203 files, current size is 203files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:05:07 PDT] Dataset size is 203 files
----------------------------------------------------
validating dataset ....passed
Writting process 93A400C6F34D4AB71008057ADA6B28E1_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 93A400C6F34D4AB71008057ADA6B28E1_2... done.
Writting process 93A400C6F34D4AB71008057ADA6B28E1_1... done.
Writting process 93A400C6F34D4AB71008057ADA6B28E1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched93A400C6F34D4AB71008057ADA6B28E1.report
Scheduling successful
submit!!!
jobs = 193
day = 131 run = 15131042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131042/*.root.log: No such file or directory
250
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:06:29 PDT] Dataset size is 250 files
Removing files not on site LBL
[2017.09.05 11:06:29 PDT] Dataset size is 250 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:06:30 PDT] Dataset size is 250 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:06:32 PDT] Started with 250 files, current size is 250files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:06:32 PDT] Dataset size is 250 files
----------------------------------------------------
validating dataset ....passed
Writting process CBA7D302B1217DBF0E21721BF6481DD9_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CBA7D302B1217DBF0E21721BF6481DD9_3... done.
Writting process CBA7D302B1217DBF0E21721BF6481DD9_2... done.
Writting process CBA7D302B1217DBF0E21721BF6481DD9_1... done.
Writting process CBA7D302B1217DBF0E21721BF6481DD9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCBA7D302B1217DBF0E21721BF6481DD9.report
Scheduling successful
submit!!!
jobs = 196
day = 131 run = 15131043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131043/*.root.log: No such file or directory
72
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:07:43 PDT] Dataset size is 72 files
Removing files not on site LBL
[2017.09.05 11:07:43 PDT] Dataset size is 72 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:07:44 PDT] Dataset size is 72 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:07:44 PDT] Started with 72 files, current size is 72files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:07:45 PDT] Dataset size is 72 files
----------------------------------------------------
validating dataset ....passed
Writting process 00D6B5A5D9E2496FA49B9E5771BE8A24_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched00D6B5A5D9E2496FA49B9E5771BE8A24.report
Scheduling successful
submit!!!
jobs = 195
day = 131 run = 15131044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131044/*.root.log: No such file or directory
110
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:08:55 PDT] Dataset size is 110 files
Removing files not on site LBL
[2017.09.05 11:08:55 PDT] Dataset size is 110 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:08:55 PDT] Dataset size is 110 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:08:55 PDT] Started with 110 files, current size is 110files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:08:56 PDT] Dataset size is 110 files
----------------------------------------------------
validating dataset ....passed
Writting process F95292CA2FB423430797C5C85EF631A5_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F95292CA2FB423430797C5C85EF631A5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF95292CA2FB423430797C5C85EF631A5.report
Scheduling successful
submit!!!
jobs = 192
day = 131 run = 15131045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131045/*.root.log: No such file or directory
264
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:10:13 PDT] Dataset size is 264 files
Removing files not on site LBL
[2017.09.05 11:10:14 PDT] Dataset size is 264 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:10:14 PDT] Dataset size is 264 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:10:15 PDT] Started with 264 files, current size is 264files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:10:15 PDT] Dataset size is 264 files
----------------------------------------------------
validating dataset ....passed
Writting process 06427D3836A0E805F885C25F400892F3_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 06427D3836A0E805F885C25F400892F3_3... done.
Writting process 06427D3836A0E805F885C25F400892F3_2... done.
Writting process 06427D3836A0E805F885C25F400892F3_1... done.
Writting process 06427D3836A0E805F885C25F400892F3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched06427D3836A0E805F885C25F400892F3.report
Scheduling successful
submit!!!
jobs = 194
day = 131 run = 15131046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131046/*.root.log: No such file or directory
256
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:11:33 PDT] Dataset size is 256 files
Removing files not on site LBL
[2017.09.05 11:11:33 PDT] Dataset size is 256 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:11:33 PDT] Dataset size is 256 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:11:34 PDT] Started with 256 files, current size is 256files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:11:34 PDT] Dataset size is 256 files
----------------------------------------------------
validating dataset ....passed
Writting process D93ECBAFDE17FDCC5CB454DFA12AC223_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D93ECBAFDE17FDCC5CB454DFA12AC223_3... done.
Writting process D93ECBAFDE17FDCC5CB454DFA12AC223_2... done.
Writting process D93ECBAFDE17FDCC5CB454DFA12AC223_1... done.
Writting process D93ECBAFDE17FDCC5CB454DFA12AC223_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD93ECBAFDE17FDCC5CB454DFA12AC223.report
Scheduling successful
submit!!!
jobs = 191
day = 131 run = 15131047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131047/*.root.log: No such file or directory
153
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:12:48 PDT] Dataset size is 153 files
Removing files not on site LBL
[2017.09.05 11:12:54 PDT] Dataset size is 153 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:12:56 PDT] Dataset size is 153 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:12:58 PDT] Started with 153 files, current size is 153files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:12:58 PDT] Dataset size is 153 files
----------------------------------------------------
validating dataset ....passed
Writting process 5275C81BDA364071F0C7EBDB4EECED8A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5275C81BDA364071F0C7EBDB4EECED8A_1... done.
Writting process 5275C81BDA364071F0C7EBDB4EECED8A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5275C81BDA364071F0C7EBDB4EECED8A.report
Scheduling successful
submit!!!
jobs = 190
day = 131 run = 15131048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131048/*.root.log: No such file or directory
114
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:14:13 PDT] Dataset size is 114 files
Removing files not on site LBL
[2017.09.05 11:14:15 PDT] Dataset size is 114 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:14:17 PDT] Dataset size is 114 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:14:18 PDT] Started with 114 files, current size is 114files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:14:18 PDT] Dataset size is 114 files
----------------------------------------------------
validating dataset ....passed
Writting process 00E98B2DCE7095226B80D4513173F95B_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 00E98B2DCE7095226B80D4513173F95B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched00E98B2DCE7095226B80D4513173F95B.report
Scheduling successful
submit!!!
jobs = 189
day = 131 run = 15131049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131049/*.root.log: No such file or directory
87
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:15:27 PDT] Dataset size is 87 files
Removing files not on site LBL
[2017.09.05 11:15:27 PDT] Dataset size is 87 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:15:27 PDT] Dataset size is 87 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:15:27 PDT] Started with 87 files, current size is 87files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:15:28 PDT] Dataset size is 87 files
----------------------------------------------------
validating dataset ....passed
Writting process DE063861886BD449560D9634A60988CE_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDE063861886BD449560D9634A60988CE.report
Scheduling successful
submit!!!
jobs = 185
day = 131 run = 15131050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131050/*.root.log: No such file or directory
235
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:16:41 PDT] Dataset size is 235 files
Removing files not on site LBL
[2017.09.05 11:16:41 PDT] Dataset size is 235 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:16:41 PDT] Dataset size is 235 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:16:42 PDT] Started with 235 files, current size is 235files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:16:42 PDT] Dataset size is 235 files
----------------------------------------------------
validating dataset ....passed
Writting process B990AC11ED60BFE97E123083C23061D9_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B990AC11ED60BFE97E123083C23061D9_2... done.
Writting process B990AC11ED60BFE97E123083C23061D9_1... done.
Writting process B990AC11ED60BFE97E123083C23061D9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB990AC11ED60BFE97E123083C23061D9.report
Scheduling successful
submit!!!
jobs = 185
day = 131 run = 15131051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131051/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:17:53 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 11:17:53 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:17:53 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:17:54 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:17:54 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 3342FE791D71FE8D1FD0990636C20EC8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3342FE791D71FE8D1FD0990636C20EC8_1... done.
Writting process 3342FE791D71FE8D1FD0990636C20EC8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3342FE791D71FE8D1FD0990636C20EC8.report
Scheduling successful
submit!!!
jobs = 186
day = 131 run = 15131052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131052/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:19:05 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 11:19:06 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:19:06 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:19:06 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:19:06 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process 695A3BF2340DDBDC24199CE53619DBA9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 695A3BF2340DDBDC24199CE53619DBA9_1... done.
Writting process 695A3BF2340DDBDC24199CE53619DBA9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched695A3BF2340DDBDC24199CE53619DBA9.report
Scheduling successful
submit!!!
jobs = 185
day = 131 run = 15131053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15131053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15131053/*.root.log: No such file or directory
48
48 48
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:20:16 PDT] Dataset size is 48 files
Removing files not on site LBL
[2017.09.05 11:20:17 PDT] Dataset size is 48 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:20:17 PDT] Dataset size is 48 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:20:18 PDT] Started with 48 files, current size is 48files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=48 ,maxSize=48 )
[2017.09.05 11:20:19 PDT] Dataset size is 48 files
----------------------------------------------------
validating dataset ....passed
Writting process 845F14E31A84D29623265351114B0D4C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched845F14E31A84D29623265351114B0D4C.report
Scheduling successful
submit!!!
Job submission for day 131 finished!
132
jobs = 185
day = 132 run = 15132007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132007/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:21:35 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 11:21:36 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:21:38 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:21:38 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:21:38 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process CA56BC85C531E21C5A36D0604DA37DED_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CA56BC85C531E21C5A36D0604DA37DED_1... done.
Writting process CA56BC85C531E21C5A36D0604DA37DED_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCA56BC85C531E21C5A36D0604DA37DED.report
Scheduling successful
submit!!!
jobs = 187
day = 132 run = 15132008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132008/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:22:53 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 11:22:54 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:22:55 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:22:55 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:22:56 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process CCEEC961D544A67B3F97C8E831E0ABD5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CCEEC961D544A67B3F97C8E831E0ABD5_1... done.
Writting process CCEEC961D544A67B3F97C8E831E0ABD5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCCEEC961D544A67B3F97C8E831E0ABD5.report
Scheduling successful
submit!!!
jobs = 187
day = 132 run = 15132009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132009/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:24:08 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 11:24:08 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:24:08 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:24:09 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:24:09 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 683AFA56C48266613AD0EE839AB3FEB4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 683AFA56C48266613AD0EE839AB3FEB4_1... done.
Writting process 683AFA56C48266613AD0EE839AB3FEB4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched683AFA56C48266613AD0EE839AB3FEB4.report
Scheduling successful
submit!!!
jobs = 185
day = 132 run = 15132010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132010/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:25:24 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 11:25:24 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:25:24 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:25:25 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:25:25 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 6FA3FA643F675A10EAB62BFE026EC51E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6FA3FA643F675A10EAB62BFE026EC51E_1... done.
Writting process 6FA3FA643F675A10EAB62BFE026EC51E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6FA3FA643F675A10EAB62BFE026EC51E.report
Scheduling successful
submit!!!
jobs = 187
day = 132 run = 15132011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132011/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:26:42 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 11:26:43 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:26:44 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:26:45 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:26:46 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 51C2B4CA7B89F6DE12EC45542E81BE1A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 51C2B4CA7B89F6DE12EC45542E81BE1A_1... done.
Writting process 51C2B4CA7B89F6DE12EC45542E81BE1A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched51C2B4CA7B89F6DE12EC45542E81BE1A.report
Scheduling successful
submit!!!
jobs = 187
day = 132 run = 15132012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132012/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:28:04 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 11:28:05 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:28:05 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:28:07 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:28:07 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process 9F59D744C505364C8AC1E38C7C6FAFF6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9F59D744C505364C8AC1E38C7C6FAFF6_1... done.
Writting process 9F59D744C505364C8AC1E38C7C6FAFF6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9F59D744C505364C8AC1E38C7C6FAFF6.report
Scheduling successful
submit!!!
jobs = 186
day = 132 run = 15132014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132014/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:29:29 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 11:29:31 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:29:32 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:29:35 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:29:36 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process B16416A79E37689D5B6AE0B6E8F99089_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B16416A79E37689D5B6AE0B6E8F99089_1... done.
Writting process B16416A79E37689D5B6AE0B6E8F99089_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB16416A79E37689D5B6AE0B6E8F99089.report
Scheduling successful
submit!!!
jobs = 185
day = 132 run = 15132015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132015/*.root.log: No such file or directory
302
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:30:56 PDT] Dataset size is 302 files
Removing files not on site LBL
[2017.09.05 11:30:58 PDT] Dataset size is 302 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:30:59 PDT] Dataset size is 302 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:31:03 PDT] Started with 302 files, current size is 302files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:31:05 PDT] Dataset size is 302 files
----------------------------------------------------
validating dataset ....passed
Writting process 1C1E71A22F7B50D69A1EB07699A122DE_5.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1C1E71A22F7B50D69A1EB07699A122DE_4... done.
Writting process 1C1E71A22F7B50D69A1EB07699A122DE_3... done.
Writting process 1C1E71A22F7B50D69A1EB07699A122DE_2... done.
Writting process 1C1E71A22F7B50D69A1EB07699A122DE_1... done.
Writting process 1C1E71A22F7B50D69A1EB07699A122DE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1C1E71A22F7B50D69A1EB07699A122DE.report
Scheduling successful
submit!!!
jobs = 183
day = 132 run = 15132016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132016/*.root.log: No such file or directory
46
46 46
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:32:29 PDT] Dataset size is 46 files
Removing files not on site LBL
[2017.09.05 11:32:30 PDT] Dataset size is 46 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:32:30 PDT] Dataset size is 46 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:32:30 PDT] Started with 46 files, current size is 46files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=46 ,maxSize=46 )
[2017.09.05 11:32:31 PDT] Dataset size is 46 files
----------------------------------------------------
validating dataset ....passed
Writting process AD50976C4E12A051C6058BE3C88A7554_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD50976C4E12A051C6058BE3C88A7554.report
Scheduling successful
submit!!!
jobs = 181
day = 132 run = 15132017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132017/*.root.log: No such file or directory
247
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:33:53 PDT] Dataset size is 247 files
Removing files not on site LBL
[2017.09.05 11:33:54 PDT] Dataset size is 247 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:33:55 PDT] Dataset size is 247 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:33:56 PDT] Started with 247 files, current size is 247files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:33:56 PDT] Dataset size is 247 files
----------------------------------------------------
validating dataset ....passed
Writting process B59D56DD3F4D8ED9729F6C5B3CC4785B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B59D56DD3F4D8ED9729F6C5B3CC4785B_2... done.
Writting process B59D56DD3F4D8ED9729F6C5B3CC4785B_1... done.
Writting process B59D56DD3F4D8ED9729F6C5B3CC4785B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB59D56DD3F4D8ED9729F6C5B3CC4785B.report
Scheduling successful
submit!!!
jobs = 182
day = 132 run = 15132018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132018/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:35:19 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 11:35:19 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:35:19 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:35:20 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:35:21 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process EFF88E19CC6846C40B0A723DCA310CA0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EFF88E19CC6846C40B0A723DCA310CA0_1... done.
Writting process EFF88E19CC6846C40B0A723DCA310CA0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEFF88E19CC6846C40B0A723DCA310CA0.report
Scheduling successful
submit!!!
jobs = 180
day = 132 run = 15132019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132019/*.root.log: No such file or directory
253
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:36:41 PDT] Dataset size is 253 files
Removing files not on site LBL
[2017.09.05 11:36:41 PDT] Dataset size is 253 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:36:41 PDT] Dataset size is 253 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:36:43 PDT] Started with 253 files, current size is 253files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:36:44 PDT] Dataset size is 253 files
----------------------------------------------------
validating dataset ....passed
Writting process B9877B58B4F648CAE3825065F7936732_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B9877B58B4F648CAE3825065F7936732_3... done.
Writting process B9877B58B4F648CAE3825065F7936732_2... done.
Writting process B9877B58B4F648CAE3825065F7936732_1... done.
Writting process B9877B58B4F648CAE3825065F7936732_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB9877B58B4F648CAE3825065F7936732.report
Scheduling successful
submit!!!
jobs = 184
day = 132 run = 15132026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132026/*.root.log: No such file or directory
100
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:37:55 PDT] Dataset size is 100 files
Removing files not on site LBL
[2017.09.05 11:37:56 PDT] Dataset size is 100 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:37:57 PDT] Dataset size is 100 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:38:00 PDT] Started with 100 files, current size is 100files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:38:02 PDT] Dataset size is 100 files
----------------------------------------------------
validating dataset ....passed
Writting process 889111B16C01158720A74E2203F5A42E_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 889111B16C01158720A74E2203F5A42E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched889111B16C01158720A74E2203F5A42E.report
Scheduling successful
submit!!!
jobs = 186
day = 132 run = 15132028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132028/*.root.log: No such file or directory
222
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:39:19 PDT] Dataset size is 222 files
Removing files not on site LBL
[2017.09.05 11:39:19 PDT] Dataset size is 222 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:39:20 PDT] Dataset size is 222 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:39:21 PDT] Started with 222 files, current size is 222files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:39:22 PDT] Dataset size is 222 files
----------------------------------------------------
validating dataset ....passed
Writting process 1BAFB75EA078E1F9DB32AEFFBE9E2859_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1BAFB75EA078E1F9DB32AEFFBE9E2859_2... done.
Writting process 1BAFB75EA078E1F9DB32AEFFBE9E2859_1... done.
Writting process 1BAFB75EA078E1F9DB32AEFFBE9E2859_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1BAFB75EA078E1F9DB32AEFFBE9E2859.report
Scheduling successful
submit!!!
jobs = 186
day = 132 run = 15132029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132029/*.root.log: No such file or directory
218
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:40:49 PDT] Dataset size is 218 files
Removing files not on site LBL
[2017.09.05 11:40:51 PDT] Dataset size is 218 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:40:52 PDT] Dataset size is 218 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:40:53 PDT] Started with 218 files, current size is 218files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:40:54 PDT] Dataset size is 218 files
----------------------------------------------------
validating dataset ....passed
Writting process C4143BFCC758CFA918A005AC73DF1625_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C4143BFCC758CFA918A005AC73DF1625_2... done.
Writting process C4143BFCC758CFA918A005AC73DF1625_1... done.
Writting process C4143BFCC758CFA918A005AC73DF1625_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC4143BFCC758CFA918A005AC73DF1625.report
Scheduling successful
submit!!!
jobs = 186
day = 132 run = 15132030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132030/*.root.log: No such file or directory
239
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:42:10 PDT] Dataset size is 239 files
Removing files not on site LBL
[2017.09.05 11:42:10 PDT] Dataset size is 239 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:42:10 PDT] Dataset size is 239 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:42:10 PDT] Started with 239 files, current size is 239files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:42:10 PDT] Dataset size is 239 files
----------------------------------------------------
validating dataset ....passed
Writting process 06DA25E6A7766F82D5D4756DD7B883BD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 06DA25E6A7766F82D5D4756DD7B883BD_2... done.
Writting process 06DA25E6A7766F82D5D4756DD7B883BD_1... done.
Writting process 06DA25E6A7766F82D5D4756DD7B883BD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched06DA25E6A7766F82D5D4756DD7B883BD.report
Scheduling successful
submit!!!
jobs = 186
day = 132 run = 15132031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132031/*.root.log: No such file or directory
254
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:43:28 PDT] Dataset size is 254 files
Removing files not on site LBL
[2017.09.05 11:43:28 PDT] Dataset size is 254 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:43:29 PDT] Dataset size is 254 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:43:29 PDT] Started with 254 files, current size is 254files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:43:29 PDT] Dataset size is 254 files
----------------------------------------------------
validating dataset ....passed
Writting process 9205A6CC62260361A6908139EE7C3A0D_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9205A6CC62260361A6908139EE7C3A0D_3... done.
Writting process 9205A6CC62260361A6908139EE7C3A0D_2... done.
Writting process 9205A6CC62260361A6908139EE7C3A0D_1... done.
Writting process 9205A6CC62260361A6908139EE7C3A0D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9205A6CC62260361A6908139EE7C3A0D.report
Scheduling successful
submit!!!
jobs = 183
day = 132 run = 15132032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132032/*.root.log: No such file or directory
250
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:44:49 PDT] Dataset size is 250 files
Removing files not on site LBL
[2017.09.05 11:44:50 PDT] Dataset size is 250 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:44:51 PDT] Dataset size is 250 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:44:52 PDT] Started with 250 files, current size is 250files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:44:53 PDT] Dataset size is 250 files
----------------------------------------------------
validating dataset ....passed
Writting process 1963425ED63FE660C2CA345E9372FE1C_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1963425ED63FE660C2CA345E9372FE1C_3... done.
Writting process 1963425ED63FE660C2CA345E9372FE1C_2... done.
Writting process 1963425ED63FE660C2CA345E9372FE1C_1... done.
Writting process 1963425ED63FE660C2CA345E9372FE1C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1963425ED63FE660C2CA345E9372FE1C.report
Scheduling successful
submit!!!
jobs = 185
day = 132 run = 15132033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132033/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:46:07 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 11:46:10 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:46:12 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:46:15 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:46:17 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process B91B3FB58CB0D3BAC849D006148E4096_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B91B3FB58CB0D3BAC849D006148E4096_1... done.
Writting process B91B3FB58CB0D3BAC849D006148E4096_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB91B3FB58CB0D3BAC849D006148E4096.report
Scheduling successful
submit!!!
jobs = 180
day = 132 run = 15132034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132034/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:48:00 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 11:48:01 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:48:05 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:48:07 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:48:08 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process 182569BF893BF8E184B20275441594AB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 182569BF893BF8E184B20275441594AB_1... done.
Writting process 182569BF893BF8E184B20275441594AB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched182569BF893BF8E184B20275441594AB.report
Scheduling successful
submit!!!
jobs = 173
day = 132 run = 15132035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132035/*.root.log: No such file or directory
234
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:49:21 PDT] Dataset size is 234 files
Removing files not on site LBL
[2017.09.05 11:49:21 PDT] Dataset size is 234 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:49:22 PDT] Dataset size is 234 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:49:22 PDT] Started with 234 files, current size is 234files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:49:22 PDT] Dataset size is 234 files
----------------------------------------------------
validating dataset ....passed
Writting process 8D4E080ED39E30BBD4D9EB988A16B82E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8D4E080ED39E30BBD4D9EB988A16B82E_2... done.
Writting process 8D4E080ED39E30BBD4D9EB988A16B82E_1... done.
Writting process 8D4E080ED39E30BBD4D9EB988A16B82E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8D4E080ED39E30BBD4D9EB988A16B82E.report
Scheduling successful
submit!!!
jobs = 174
day = 132 run = 15132036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132036/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:50:36 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.05 11:50:36 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:50:37 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:50:37 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:50:37 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process 24C27057139FA420DAB19DCD2E784C9B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 24C27057139FA420DAB19DCD2E784C9B_2... done.
Writting process 24C27057139FA420DAB19DCD2E784C9B_1... done.
Writting process 24C27057139FA420DAB19DCD2E784C9B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched24C27057139FA420DAB19DCD2E784C9B.report
Scheduling successful
submit!!!
jobs = 174
day = 132 run = 15132037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132037/*.root.log: No such file or directory
232
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:51:51 PDT] Dataset size is 232 files
Removing files not on site LBL
[2017.09.05 11:51:53 PDT] Dataset size is 232 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:51:55 PDT] Dataset size is 232 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:51:58 PDT] Started with 232 files, current size is 232files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:51:59 PDT] Dataset size is 232 files
----------------------------------------------------
validating dataset ....passed
Writting process AC49818A2D829AF519E607421623405E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AC49818A2D829AF519E607421623405E_2... done.
Writting process AC49818A2D829AF519E607421623405E_1... done.
Writting process AC49818A2D829AF519E607421623405E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAC49818A2D829AF519E607421623405E.report
Scheduling successful
submit!!!
jobs = 171
day = 132 run = 15132038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15132038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15132038/*.root.log: No such file or directory
90
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:53:14 PDT] Dataset size is 90 files
Removing files not on site LBL
[2017.09.05 11:53:15 PDT] Dataset size is 90 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:53:15 PDT] Dataset size is 90 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:53:16 PDT] Started with 90 files, current size is 90files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:53:17 PDT] Dataset size is 90 files
----------------------------------------------------
validating dataset ....passed
Writting process 97E2EF0B830D696559AB5375E3462F05_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched97E2EF0B830D696559AB5375E3462F05.report
Scheduling successful
submit!!!
Job submission for day 132 finished!
133
jobs = 165
day = 133 run = 15133008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133008/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:54:33 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 11:54:33 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:54:33 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:54:34 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:54:34 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process EFF5F243A1A687D845039962D85C551B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EFF5F243A1A687D845039962D85C551B_1... done.
Writting process EFF5F243A1A687D845039962D85C551B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEFF5F243A1A687D845039962D85C551B.report
Scheduling successful
submit!!!
jobs = 162
day = 133 run = 15133009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133009/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:55:47 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 11:55:48 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:55:49 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:55:51 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:55:51 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process 61594721E234D5BDD49E00A10B41D212_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 61594721E234D5BDD49E00A10B41D212_1... done.
Writting process 61594721E234D5BDD49E00A10B41D212_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched61594721E234D5BDD49E00A10B41D212.report
Scheduling successful
submit!!!
jobs = 160
day = 133 run = 15133010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133010/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:57:05 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 11:57:05 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:57:06 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:57:07 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:57:07 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process EC7F49D27CF87CFFAB31DA17BDE116D9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EC7F49D27CF87CFFAB31DA17BDE116D9_1... done.
Writting process EC7F49D27CF87CFFAB31DA17BDE116D9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEC7F49D27CF87CFFAB31DA17BDE116D9.report
Scheduling successful
submit!!!
jobs = 157
day = 133 run = 15133011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133011/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:58:24 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 11:58:24 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:58:24 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:58:25 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:58:25 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 0073C858481889331FA88772D81D006B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0073C858481889331FA88772D81D006B_1... done.
Writting process 0073C858481889331FA88772D81D006B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0073C858481889331FA88772D81D006B.report
Scheduling successful
submit!!!
jobs = 159
day = 133 run = 15133012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133012/*.root.log: No such file or directory
209
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 11:59:39 PDT] Dataset size is 209 files
Removing files not on site LBL
[2017.09.05 11:59:39 PDT] Dataset size is 209 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 11:59:39 PDT] Dataset size is 209 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 11:59:40 PDT] Started with 209 files, current size is 209files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 11:59:40 PDT] Dataset size is 209 files
----------------------------------------------------
validating dataset ....passed
Writting process 6EED594C14B9573F508AE00AC783A1B5_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6EED594C14B9573F508AE00AC783A1B5_2... done.
Writting process 6EED594C14B9573F508AE00AC783A1B5_1... done.
Writting process 6EED594C14B9573F508AE00AC783A1B5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6EED594C14B9573F508AE00AC783A1B5.report
Scheduling successful
submit!!!
jobs = 161
day = 133 run = 15133013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133013/*.root.log: No such file or directory
59
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:00:53 PDT] Dataset size is 59 files
Removing files not on site LBL
[2017.09.05 12:00:53 PDT] Dataset size is 59 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:00:54 PDT] Dataset size is 59 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:00:55 PDT] Started with 59 files, current size is 59files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:00:55 PDT] Dataset size is 59 files
----------------------------------------------------
validating dataset ....passed
Writting process 63FA4226C3D73EFEE9E5286C7894FDC0_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched63FA4226C3D73EFEE9E5286C7894FDC0.report
Scheduling successful
submit!!!
jobs = 159
day = 133 run = 15133014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133014/*.root.log: No such file or directory
44
44 44
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:02:05 PDT] Dataset size is 44 files
Removing files not on site LBL
[2017.09.05 12:02:06 PDT] Dataset size is 44 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:02:06 PDT] Dataset size is 44 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:02:06 PDT] Started with 44 files, current size is 44files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=44 ,maxSize=44 )
[2017.09.05 12:02:06 PDT] Dataset size is 44 files
----------------------------------------------------
validating dataset ....passed
Writting process A228F38B4A38C328A9DD7BEB8B30AF1A_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA228F38B4A38C328A9DD7BEB8B30AF1A.report
Scheduling successful
submit!!!
jobs = 157
day = 133 run = 15133018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133018/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:03:23 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 12:03:24 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:03:25 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:03:28 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:03:28 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 4C61729A44EB7898234C8FDD96E3284B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4C61729A44EB7898234C8FDD96E3284B_1... done.
Writting process 4C61729A44EB7898234C8FDD96E3284B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4C61729A44EB7898234C8FDD96E3284B.report
Scheduling successful
submit!!!
jobs = 155
day = 133 run = 15133019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133019/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:05:07 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 12:05:09 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:05:10 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:05:13 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:05:14 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 8794D53C9220E6F81A2ABB207B8A0831_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8794D53C9220E6F81A2ABB207B8A0831_1... done.
Writting process 8794D53C9220E6F81A2ABB207B8A0831_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8794D53C9220E6F81A2ABB207B8A0831.report
Scheduling successful
submit!!!
jobs = 154
day = 133 run = 15133020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133020/*.root.log: No such file or directory
116
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:06:32 PDT] Dataset size is 116 files
Removing files not on site LBL
[2017.09.05 12:06:33 PDT] Dataset size is 116 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:06:33 PDT] Dataset size is 116 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:06:35 PDT] Started with 116 files, current size is 116files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:06:36 PDT] Dataset size is 116 files
----------------------------------------------------
validating dataset ....passed
Writting process 2192D552CC96411FB3EC49823C59E933_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2192D552CC96411FB3EC49823C59E933_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2192D552CC96411FB3EC49823C59E933.report
Scheduling successful
submit!!!
jobs = 151
day = 133 run = 15133021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133021/*.root.log: No such file or directory
243
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:07:56 PDT] Dataset size is 243 files
Removing files not on site LBL
[2017.09.05 12:07:58 PDT] Dataset size is 243 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:07:59 PDT] Dataset size is 243 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:08:03 PDT] Started with 243 files, current size is 243files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:08:05 PDT] Dataset size is 243 files
----------------------------------------------------
validating dataset ....passed
Writting process F65C51E837DA420E816D79ADA16869A2_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F65C51E837DA420E816D79ADA16869A2_2... done.
Writting process F65C51E837DA420E816D79ADA16869A2_1... done.
Writting process F65C51E837DA420E816D79ADA16869A2_0... done.
Submitting array... done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF65C51E837DA420E816D79ADA16869A2.report
Scheduling successful
submit!!!
jobs = 152
day = 133 run = 15133036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133036/*.root.log: No such file or directory
227
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:09:27 PDT] Dataset size is 227 files
Removing files not on site LBL
[2017.09.05 12:09:28 PDT] Dataset size is 227 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:09:30 PDT] Dataset size is 227 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:09:31 PDT] Started with 227 files, current size is 227files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:09:32 PDT] Dataset size is 227 files
----------------------------------------------------
validating dataset ....passed
Writting process 7579ED96112CFFDD6C75ADEC92D07A20_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7579ED96112CFFDD6C75ADEC92D07A20_2... done.
Writting process 7579ED96112CFFDD6C75ADEC92D07A20_1... done.
Writting process 7579ED96112CFFDD6C75ADEC92D07A20_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7579ED96112CFFDD6C75ADEC92D07A20.report
Scheduling successful
submit!!!
jobs = 151
day = 133 run = 15133037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133037/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:10:50 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 12:10:50 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:10:50 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:10:51 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:10:53 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process 22456D77A48CB670444FB650DF17A117_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 22456D77A48CB670444FB650DF17A117_1... done.
Writting process 22456D77A48CB670444FB650DF17A117_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched22456D77A48CB670444FB650DF17A117.report
Scheduling successful
submit!!!
jobs = 150
day = 133 run = 15133038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133038/*.root.log: No such file or directory
164
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:12:14 PDT] Dataset size is 164 files
Removing files not on site LBL
[2017.09.05 12:12:14 PDT] Dataset size is 164 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:12:14 PDT] Dataset size is 164 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:12:14 PDT] Started with 164 files, current size is 164files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:12:14 PDT] Dataset size is 164 files
----------------------------------------------------
validating dataset ....passed
Writting process C3F21A72A28150E2752528C4C65CA0B0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C3F21A72A28150E2752528C4C65CA0B0_1... done.
Writting process C3F21A72A28150E2752528C4C65CA0B0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC3F21A72A28150E2752528C4C65CA0B0.report
Scheduling successful
submit!!!
jobs = 145
day = 133 run = 15133039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133039/*.root.log: No such file or directory
252
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:14:14 PDT] Dataset size is 252 files
Removing files not on site LBL
[2017.09.05 12:14:16 PDT] Dataset size is 252 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:14:18 PDT] Dataset size is 252 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:14:21 PDT] Started with 252 files, current size is 252files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:14:22 PDT] Dataset size is 252 files
----------------------------------------------------
validating dataset ....passed
Writting process D674F151747FC9BC39FE698D0690DF26_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D674F151747FC9BC39FE698D0690DF26_3... done.
Writting process D674F151747FC9BC39FE698D0690DF26_2... done.
Writting process D674F151747FC9BC39FE698D0690DF26_1... done.
Writting process D674F151747FC9BC39FE698D0690DF26_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD674F151747FC9BC39FE698D0690DF26.report
Scheduling successful
submit!!!
jobs = 142
day = 133 run = 15133040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133040/*.root.log: No such file or directory
273
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:16:21 PDT] Dataset size is 273 files
Removing files not on site LBL
[2017.09.05 12:16:23 PDT] Dataset size is 273 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:16:25 PDT] Dataset size is 273 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:16:27 PDT] Started with 273 files, current size is 273files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:16:29 PDT] Dataset size is 273 files
----------------------------------------------------
validating dataset ....passed
Writting process 5270D5D77B584458166B24059539D826_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5270D5D77B584458166B24059539D826_3... done.
Writting process 5270D5D77B584458166B24059539D826_2... done.
Writting process 5270D5D77B584458166B24059539D826_1... done.
Writting process 5270D5D77B584458166B24059539D826_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5270D5D77B584458166B24059539D826.report
Scheduling successful
submit!!!
jobs = 138
day = 133 run = 15133041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133041/*.root.log: No such file or directory
158
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:18:00 PDT] Dataset size is 158 files
Removing files not on site LBL
[2017.09.05 12:18:00 PDT] Dataset size is 158 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:18:00 PDT] Dataset size is 158 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:18:03 PDT] Started with 158 files, current size is 158files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:18:06 PDT] Dataset size is 158 files
----------------------------------------------------
validating dataset ....passed
Writting process CE22D6425EE108ADC9039C71F2325D1F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CE22D6425EE108ADC9039C71F2325D1F_1... done.
Writting process CE22D6425EE108ADC9039C71F2325D1F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCE22D6425EE108ADC9039C71F2325D1F.report
Scheduling successful
submit!!!
jobs = 134
day = 133 run = 15133042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133042/*.root.log: No such file or directory
102
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:19:21 PDT] Dataset size is 102 files
Removing files not on site LBL
[2017.09.05 12:19:21 PDT] Dataset size is 102 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:19:21 PDT] Dataset size is 102 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:19:22 PDT] Started with 102 files, current size is 102files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:19:22 PDT] Dataset size is 102 files
----------------------------------------------------
validating dataset ....passed
Writting process 02097E0D255305CD663DDAFD8E2BAB8D_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 02097E0D255305CD663DDAFD8E2BAB8D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched02097E0D255305CD663DDAFD8E2BAB8D.report
Scheduling successful
submit!!!
jobs = 135
day = 133 run = 15133043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133043/*.root.log: No such file or directory
31
31 31
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:20:30 PDT] Dataset size is 31 files
Removing files not on site LBL
[2017.09.05 12:20:30 PDT] Dataset size is 31 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:20:31 PDT] Dataset size is 31 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:20:31 PDT] Started with 31 files, current size is 31files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=31 ,maxSize=31 )
[2017.09.05 12:20:31 PDT] Dataset size is 31 files
----------------------------------------------------
validating dataset ....passed
Writting process 86C6A350ACA2ABEB0CEC8B0CC8DD5FC7_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched86C6A350ACA2ABEB0CEC8B0CC8DD5FC7.report
Scheduling successful
submit!!!
jobs = 132
day = 133 run = 15133044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133044/*.root.log: No such file or directory
74
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:21:39 PDT] Dataset size is 74 files
Removing files not on site LBL
[2017.09.05 12:21:39 PDT] Dataset size is 74 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:21:40 PDT] Dataset size is 74 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:21:40 PDT] Started with 74 files, current size is 74files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:21:40 PDT] Dataset size is 74 files
----------------------------------------------------
validating dataset ....passed
Writting process 60F6946DA27509628B2966197E5346ED_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched60F6946DA27509628B2966197E5346ED.report
Scheduling successful
submit!!!
jobs = 127
day = 133 run = 15133045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133045/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:22:52 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 12:22:52 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:22:52 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:22:52 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:22:52 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process 0E5FFCE85E45AB676C5794422980773C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0E5FFCE85E45AB676C5794422980773C_1... done.
Writting process 0E5FFCE85E45AB676C5794422980773C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0E5FFCE85E45AB676C5794422980773C.report
Scheduling successful
submit!!!
jobs = 124
day = 133 run = 15133056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15133056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15133056/*.root.log: No such file or directory
198
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:24:06 PDT] Dataset size is 198 files
Removing files not on site LBL
[2017.09.05 12:24:06 PDT] Dataset size is 198 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:24:06 PDT] Dataset size is 198 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:24:06 PDT] Started with 198 files, current size is 198files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:24:06 PDT] Dataset size is 198 files
----------------------------------------------------
validating dataset ....passed
Writting process 06E731CE9999ACCD96C58CDF1ED58CC9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 06E731CE9999ACCD96C58CDF1ED58CC9_1... done.
Writting process 06E731CE9999ACCD96C58CDF1ED58CC9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched06E731CE9999ACCD96C58CDF1ED58CC9.report
Scheduling successful
submit!!!
Job submission for day 133 finished!
134
jobs = 116
day = 134 run = 15134001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134001/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:25:19 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 12:25:19 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:25:19 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:25:19 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:25:19 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 00F4E4AD11202825269B520F09374850_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 00F4E4AD11202825269B520F09374850_1... done.
Writting process 00F4E4AD11202825269B520F09374850_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched00F4E4AD11202825269B520F09374850.report
Scheduling successful
submit!!!
jobs = 111
day = 134 run = 15134002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134002/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:26:32 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 12:26:32 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:26:32 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:26:32 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:26:32 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process F68884C3C5BB117FFAC5B61940E5DBE6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F68884C3C5BB117FFAC5B61940E5DBE6_1... done.
Writting process F68884C3C5BB117FFAC5B61940E5DBE6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF68884C3C5BB117FFAC5B61940E5DBE6.report
Scheduling successful
submit!!!
jobs = 108
day = 134 run = 15134003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134003/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:27:45 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 12:27:45 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:27:45 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:27:45 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:27:45 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 18A8120109342A6A6C8F45B71B8D5E7E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 18A8120109342A6A6C8F45B71B8D5E7E_1... done.
Writting process 18A8120109342A6A6C8F45B71B8D5E7E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched18A8120109342A6A6C8F45B71B8D5E7E.report
Scheduling successful
submit!!!
jobs = 110
day = 134 run = 15134004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134004/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:28:57 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 12:28:57 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:28:57 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:28:57 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:28:57 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process F742E6A8E514D51C9A18A43B63B6B952_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F742E6A8E514D51C9A18A43B63B6B952_1... done.
Writting process F742E6A8E514D51C9A18A43B63B6B952_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF742E6A8E514D51C9A18A43B63B6B952.report
Scheduling successful
submit!!!
jobs = 112
day = 134 run = 15134006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134006/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:30:09 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 12:30:09 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:30:10 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:30:10 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:30:10 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 7DB35D34F13A37744DC160407B5CB36C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7DB35D34F13A37744DC160407B5CB36C_1... done.
Writting process 7DB35D34F13A37744DC160407B5CB36C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7DB35D34F13A37744DC160407B5CB36C.report
Scheduling successful
submit!!!
jobs = 112
day = 134 run = 15134007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134007/*.root.log: No such file or directory
196
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:31:22 PDT] Dataset size is 196 files
Removing files not on site LBL
[2017.09.05 12:31:22 PDT] Dataset size is 196 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:31:22 PDT] Dataset size is 196 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:31:22 PDT] Started with 196 files, current size is 196files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:31:22 PDT] Dataset size is 196 files
----------------------------------------------------
validating dataset ....passed
Writting process 62C570216AB001F82BA1BF8E9B8865C3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 62C570216AB001F82BA1BF8E9B8865C3_1... done.
Writting process 62C570216AB001F82BA1BF8E9B8865C3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched62C570216AB001F82BA1BF8E9B8865C3.report
Scheduling successful
submit!!!
jobs = 113
day = 134 run = 15134008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134008/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:32:33 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 12:32:33 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:32:33 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:32:33 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:32:33 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 3C23512722024BCFBA73114BBA62D618_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3C23512722024BCFBA73114BBA62D618_1... done.
Writting process 3C23512722024BCFBA73114BBA62D618_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3C23512722024BCFBA73114BBA62D618.report
Scheduling successful
submit!!!
jobs = 115
day = 134 run = 15134009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134009/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:33:45 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 12:33:45 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:33:45 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:33:45 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:33:45 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process A79341CE3E1B350850BD01FEC9CD5AF0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A79341CE3E1B350850BD01FEC9CD5AF0_1... done.
Writting process A79341CE3E1B350850BD01FEC9CD5AF0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA79341CE3E1B350850BD01FEC9CD5AF0.report
Scheduling successful
submit!!!
jobs = 118
day = 134 run = 15134010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134010/*.root.log: No such file or directory
90
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:34:54 PDT] Dataset size is 90 files
Removing files not on site LBL
[2017.09.05 12:34:54 PDT] Dataset size is 90 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:34:54 PDT] Dataset size is 90 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:34:54 PDT] Started with 90 files, current size is 90files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:34:54 PDT] Dataset size is 90 files
----------------------------------------------------
validating dataset ....passed
Writting process 1DD1ACBA26B5F6D7CCBFA2062CA536BB_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1DD1ACBA26B5F6D7CCBFA2062CA536BB.report
Scheduling successful
submit!!!
jobs = 118
day = 134 run = 15134057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134057/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:36:06 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 12:36:06 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:36:06 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:36:06 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:36:06 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process 80045E0CB3DC6416AD38C241C7746028_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 80045E0CB3DC6416AD38C241C7746028_1... done.
Writting process 80045E0CB3DC6416AD38C241C7746028_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched80045E0CB3DC6416AD38C241C7746028.report
Scheduling successful
submit!!!
jobs = 119
day = 134 run = 15134058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134058/*.root.log: No such file or directory
102
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:37:15 PDT] Dataset size is 102 files
Removing files not on site LBL
[2017.09.05 12:37:15 PDT] Dataset size is 102 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:37:15 PDT] Dataset size is 102 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:37:15 PDT] Started with 102 files, current size is 102files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:37:15 PDT] Dataset size is 102 files
----------------------------------------------------
validating dataset ....passed
Writting process C279FB363EBEEB73D0546C7CF13C3DDD_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C279FB363EBEEB73D0546C7CF13C3DDD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC279FB363EBEEB73D0546C7CF13C3DDD.report
Scheduling successful
submit!!!
jobs = 117
day = 134 run = 15134060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134060/*.root.log: No such file or directory
80
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:38:24 PDT] Dataset size is 80 files
Removing files not on site LBL
[2017.09.05 12:38:24 PDT] Dataset size is 80 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:38:24 PDT] Dataset size is 80 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:38:24 PDT] Started with 80 files, current size is 80files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:38:24 PDT] Dataset size is 80 files
----------------------------------------------------
validating dataset ....passed
Writting process 2153ADBB5C3EB3CA2703CBE6559FFEF6_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2153ADBB5C3EB3CA2703CBE6559FFEF6.report
Scheduling successful
submit!!!
jobs = 114
day = 134 run = 15134062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134062/*.root.log: No such file or directory
145
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:39:34 PDT] Dataset size is 145 files
Removing files not on site LBL
[2017.09.05 12:39:34 PDT] Dataset size is 145 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:39:34 PDT] Dataset size is 145 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:39:34 PDT] Started with 145 files, current size is 145files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:39:34 PDT] Dataset size is 145 files
----------------------------------------------------
validating dataset ....passed
Writting process 991FFA95F7B35FD31345E71B2C52FA74_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 991FFA95F7B35FD31345E71B2C52FA74_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched991FFA95F7B35FD31345E71B2C52FA74.report
Scheduling successful
submit!!!
jobs = 114
day = 134 run = 15134063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15134063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15134063/*.root.log: No such file or directory
149
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:40:45 PDT] Dataset size is 149 files
Removing files not on site LBL
[2017.09.05 12:40:45 PDT] Dataset size is 149 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:40:45 PDT] Dataset size is 149 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:40:45 PDT] Started with 149 files, current size is 149files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:40:45 PDT] Dataset size is 149 files
----------------------------------------------------
validating dataset ....passed
Writting process ABF57898A1ABB85D2745DEDE28C275C0_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ABF57898A1ABB85D2745DEDE28C275C0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedABF57898A1ABB85D2745DEDE28C275C0.report
Scheduling successful
submit!!!
Job submission for day 134 finished!
135
jobs = 114
day = 135 run = 15135010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15135010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15135010/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:41:57 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 12:41:57 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:41:57 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:41:57 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:41:57 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process F48A67879596B5C84B9170252A605F6C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F48A67879596B5C84B9170252A605F6C_1... done.
Writting process F48A67879596B5C84B9170252A605F6C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF48A67879596B5C84B9170252A605F6C.report
Scheduling successful
submit!!!
jobs = 115
day = 135 run = 15135011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15135011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15135011/*.root.log: No such file or directory
200
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:43:10 PDT] Dataset size is 200 files
Removing files not on site LBL
[2017.09.05 12:43:10 PDT] Dataset size is 200 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:43:10 PDT] Dataset size is 200 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:43:10 PDT] Started with 200 files, current size is 200files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:43:11 PDT] Dataset size is 200 files
----------------------------------------------------
validating dataset ....passed
Writting process 5510B71D6285F330F4F84F79F803C700_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5510B71D6285F330F4F84F79F803C700_2... done.
Writting process 5510B71D6285F330F4F84F79F803C700_1... done.
Writting process 5510B71D6285F330F4F84F79F803C700_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5510B71D6285F330F4F84F79F803C700.report
Scheduling successful
submit!!!
jobs = 117
day = 135 run = 15135012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15135012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15135012/*.root.log: No such file or directory
198
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:44:23 PDT] Dataset size is 198 files
Removing files not on site LBL
[2017.09.05 12:44:23 PDT] Dataset size is 198 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:44:23 PDT] Dataset size is 198 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:44:23 PDT] Started with 198 files, current size is 198files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:44:23 PDT] Dataset size is 198 files
----------------------------------------------------
validating dataset ....passed
Writting process CDC7313789A5BDC2302EF918458AB226_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CDC7313789A5BDC2302EF918458AB226_1... done.
Writting process CDC7313789A5BDC2302EF918458AB226_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCDC7313789A5BDC2302EF918458AB226.report
Scheduling successful
submit!!!
jobs = 118
day = 135 run = 15135013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15135013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15135013/*.root.log: No such file or directory
243
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:45:37 PDT] Dataset size is 243 files
Removing files not on site LBL
[2017.09.05 12:45:37 PDT] Dataset size is 243 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:45:37 PDT] Dataset size is 243 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:45:37 PDT] Started with 243 files, current size is 243files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:45:37 PDT] Dataset size is 243 files
----------------------------------------------------
validating dataset ....passed
Writting process 86588C15C6E5E3ABFDE4D34198E40E37_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 86588C15C6E5E3ABFDE4D34198E40E37_2... done.
Writting process 86588C15C6E5E3ABFDE4D34198E40E37_1... done.
Writting process 86588C15C6E5E3ABFDE4D34198E40E37_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched86588C15C6E5E3ABFDE4D34198E40E37.report
Scheduling successful
submit!!!
jobs = 121
day = 135 run = 15135014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15135014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15135014/*.root.log: No such file or directory
238
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:46:50 PDT] Dataset size is 238 files
Removing files not on site LBL
[2017.09.05 12:46:50 PDT] Dataset size is 238 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:46:51 PDT] Dataset size is 238 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:46:51 PDT] Started with 238 files, current size is 238files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:46:51 PDT] Dataset size is 238 files
----------------------------------------------------
validating dataset ....passed
Writting process 304AAC9AD94FF3DC90A971BF027D34DE_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 304AAC9AD94FF3DC90A971BF027D34DE_2... done.
Writting process 304AAC9AD94FF3DC90A971BF027D34DE_1... done.
Writting process 304AAC9AD94FF3DC90A971BF027D34DE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched304AAC9AD94FF3DC90A971BF027D34DE.report
Scheduling successful
submit!!!
jobs = 121
day = 135 run = 15135015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15135015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15135015/*.root.log: No such file or directory
138
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:48:02 PDT] Dataset size is 138 files
Removing files not on site LBL
[2017.09.05 12:48:02 PDT] Dataset size is 138 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:48:03 PDT] Dataset size is 138 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:48:03 PDT] Started with 138 files, current size is 138files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:48:03 PDT] Dataset size is 138 files
----------------------------------------------------
validating dataset ....passed
Writting process E57D3961110D8136F4FEC21F876B120D_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E57D3961110D8136F4FEC21F876B120D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE57D3961110D8136F4FEC21F876B120D.report
Scheduling successful
submit!!!
jobs = 121
day = 135 run = 15135016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15135016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15135016/*.root.log: No such file or directory
67
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:49:12 PDT] Dataset size is 67 files
Removing files not on site LBL
[2017.09.05 12:49:12 PDT] Dataset size is 67 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:49:12 PDT] Dataset size is 67 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:49:12 PDT] Started with 67 files, current size is 67files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:49:12 PDT] Dataset size is 67 files
----------------------------------------------------
validating dataset ....passed
Writting process 6A95181C9B7742225CBD43AB4DA853FE_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6A95181C9B7742225CBD43AB4DA853FE.report
Scheduling successful
submit!!!
Job submission for day 135 finished!
136
jobs = 120
day = 136 run = 15136003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136003/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:50:23 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 12:50:23 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:50:23 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:50:23 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:50:23 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 2FC18FA6F6EAA8DDB7C5E956295C95AE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2FC18FA6F6EAA8DDB7C5E956295C95AE_1... done.
Writting process 2FC18FA6F6EAA8DDB7C5E956295C95AE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2FC18FA6F6EAA8DDB7C5E956295C95AE.report
Scheduling successful
submit!!!
jobs = 120
day = 136 run = 15136004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136004/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:51:35 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 12:51:35 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:51:35 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:51:35 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:51:35 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process DE2990F2A3C95F23E1C08412A5681E2A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DE2990F2A3C95F23E1C08412A5681E2A_1... done.
Writting process DE2990F2A3C95F23E1C08412A5681E2A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDE2990F2A3C95F23E1C08412A5681E2A.report
Scheduling successful
submit!!!
jobs = 116
day = 136 run = 15136005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136005/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:52:47 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 12:52:47 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:52:47 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:52:47 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:52:47 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process 2E15CB49642E56BAE78FA93512994933_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2E15CB49642E56BAE78FA93512994933_1... done.
Writting process 2E15CB49642E56BAE78FA93512994933_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2E15CB49642E56BAE78FA93512994933.report
Scheduling successful
submit!!!
jobs = 117
day = 136 run = 15136006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136006/*.root.log: No such file or directory
153
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:53:58 PDT] Dataset size is 153 files
Removing files not on site LBL
[2017.09.05 12:53:58 PDT] Dataset size is 153 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:53:58 PDT] Dataset size is 153 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:53:58 PDT] Started with 153 files, current size is 153files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:53:58 PDT] Dataset size is 153 files
----------------------------------------------------
validating dataset ....passed
Writting process 90532FEA9C95A8C712863CBB197DCCFE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 90532FEA9C95A8C712863CBB197DCCFE_1... done.
Writting process 90532FEA9C95A8C712863CBB197DCCFE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched90532FEA9C95A8C712863CBB197DCCFE.report
Scheduling successful
submit!!!
jobs = 116
day = 136 run = 15136007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136007/*.root.log: No such file or directory
156
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:55:09 PDT] Dataset size is 156 files
Removing files not on site LBL
[2017.09.05 12:55:09 PDT] Dataset size is 156 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:55:09 PDT] Dataset size is 156 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:55:09 PDT] Started with 156 files, current size is 156files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:55:09 PDT] Dataset size is 156 files
----------------------------------------------------
validating dataset ....passed
Writting process 50218B56A59BE915FA2B004D16FAA215_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 50218B56A59BE915FA2B004D16FAA215_1... done.
Writting process 50218B56A59BE915FA2B004D16FAA215_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched50218B56A59BE915FA2B004D16FAA215.report
Scheduling successful
submit!!!
jobs = 115
day = 136 run = 15136008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136008/*.root.log: No such file or directory
145
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:56:20 PDT] Dataset size is 145 files
Removing files not on site LBL
[2017.09.05 12:56:20 PDT] Dataset size is 145 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:56:20 PDT] Dataset size is 145 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:56:20 PDT] Started with 145 files, current size is 145files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:56:20 PDT] Dataset size is 145 files
----------------------------------------------------
validating dataset ....passed
Writting process 8756BBD319D86D7D9D92514A201AD721_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8756BBD319D86D7D9D92514A201AD721_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8756BBD319D86D7D9D92514A201AD721.report
Scheduling successful
submit!!!
jobs = 116
day = 136 run = 15136009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136009/*.root.log: No such file or directory
155
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:57:31 PDT] Dataset size is 155 files
Removing files not on site LBL
[2017.09.05 12:57:31 PDT] Dataset size is 155 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:57:31 PDT] Dataset size is 155 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:57:31 PDT] Started with 155 files, current size is 155files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:57:31 PDT] Dataset size is 155 files
----------------------------------------------------
validating dataset ....passed
Writting process 1E1F6318CEAC843709D10D5D7F28A690_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1E1F6318CEAC843709D10D5D7F28A690_1... done.
Writting process 1E1F6318CEAC843709D10D5D7F28A690_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1E1F6318CEAC843709D10D5D7F28A690.report
Scheduling successful
submit!!!
jobs = 117
day = 136 run = 15136011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136011/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:58:42 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 12:58:42 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:58:42 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:58:42 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:58:42 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process DF573C7952F7BFA8819CE30DD85EEC14_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DF573C7952F7BFA8819CE30DD85EEC14_1... done.
Writting process DF573C7952F7BFA8819CE30DD85EEC14_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDF573C7952F7BFA8819CE30DD85EEC14.report
Scheduling successful
submit!!!
jobs = 117
day = 136 run = 15136012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136012/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 12:59:54 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 12:59:54 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 12:59:54 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 12:59:54 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 12:59:54 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process D870B1ED492744A2313A71817CD0B428_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D870B1ED492744A2313A71817CD0B428_1... done.
Writting process D870B1ED492744A2313A71817CD0B428_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD870B1ED492744A2313A71817CD0B428.report
Scheduling successful
submit!!!
jobs = 116
day = 136 run = 15136013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136013/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:01:07 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 13:01:07 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:01:07 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:01:08 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:01:08 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 802ACB698585DD04AEC8FE761298FAA5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 802ACB698585DD04AEC8FE761298FAA5_1... done.
Writting process 802ACB698585DD04AEC8FE761298FAA5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched802ACB698585DD04AEC8FE761298FAA5.report
Scheduling successful
submit!!!
jobs = 116
day = 136 run = 15136014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136014/*.root.log: No such file or directory
156
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:02:19 PDT] Dataset size is 156 files
Removing files not on site LBL
[2017.09.05 13:02:19 PDT] Dataset size is 156 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:02:19 PDT] Dataset size is 156 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:02:20 PDT] Started with 156 files, current size is 156files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:02:20 PDT] Dataset size is 156 files
----------------------------------------------------
validating dataset ....passed
Writting process 9B2847FFD401A16F44ACA218D4CCCC79_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9B2847FFD401A16F44ACA218D4CCCC79_1... done.
Writting process 9B2847FFD401A16F44ACA218D4CCCC79_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9B2847FFD401A16F44ACA218D4CCCC79.report
Scheduling successful
submit!!!
jobs = 119
day = 136 run = 15136015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136015/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:03:31 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 13:03:31 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:03:31 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:03:31 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:03:31 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process 6A174C8C0A8BAB4FCAB2DB8FD06A41A8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6A174C8C0A8BAB4FCAB2DB8FD06A41A8_1... done.
Writting process 6A174C8C0A8BAB4FCAB2DB8FD06A41A8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6A174C8C0A8BAB4FCAB2DB8FD06A41A8.report
Scheduling successful
submit!!!
jobs = 120
day = 136 run = 15136016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136016/*.root.log: No such file or directory
194
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:04:43 PDT] Dataset size is 194 files
Removing files not on site LBL
[2017.09.05 13:04:43 PDT] Dataset size is 194 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:04:43 PDT] Dataset size is 194 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:04:44 PDT] Started with 194 files, current size is 194files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:04:44 PDT] Dataset size is 194 files
----------------------------------------------------
validating dataset ....passed
Writting process 532460BC138E4B607D131B6034EF4525_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 532460BC138E4B607D131B6034EF4525_1... done.
Writting process 532460BC138E4B607D131B6034EF4525_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched532460BC138E4B607D131B6034EF4525.report
Scheduling successful
submit!!!
jobs = 118
day = 136 run = 15136017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136017/*.root.log: No such file or directory
127
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:05:54 PDT] Dataset size is 127 files
Removing files not on site LBL
[2017.09.05 13:05:54 PDT] Dataset size is 127 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:05:54 PDT] Dataset size is 127 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:05:54 PDT] Started with 127 files, current size is 127files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:05:54 PDT] Dataset size is 127 files
----------------------------------------------------
validating dataset ....passed
Writting process C418BF5FA6AEE71D18A1E7F5B4FA46C0_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C418BF5FA6AEE71D18A1E7F5B4FA46C0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC418BF5FA6AEE71D18A1E7F5B4FA46C0.report
Scheduling successful
submit!!!
jobs = 119
day = 136 run = 15136038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136038/*.root.log: No such file or directory
103
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:07:04 PDT] Dataset size is 103 files
Removing files not on site LBL
[2017.09.05 13:07:04 PDT] Dataset size is 103 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:07:04 PDT] Dataset size is 103 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:07:04 PDT] Started with 103 files, current size is 103files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:07:04 PDT] Dataset size is 103 files
----------------------------------------------------
validating dataset ....passed
Writting process 7375FC493DB2D043519A0CCD6A5506C9_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7375FC493DB2D043519A0CCD6A5506C9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7375FC493DB2D043519A0CCD6A5506C9.report
Scheduling successful
submit!!!
jobs = 120
day = 136 run = 15136039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136039/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:08:16 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 13:08:17 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:08:17 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:08:17 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:08:17 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process 24BE743FB43601C30A341B9A7541E4CD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 24BE743FB43601C30A341B9A7541E4CD_1... done.
Writting process 24BE743FB43601C30A341B9A7541E4CD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched24BE743FB43601C30A341B9A7541E4CD.report
Scheduling successful
submit!!!
jobs = 123
day = 136 run = 15136040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136040/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:09:29 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 13:09:29 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:09:30 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:09:30 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:09:30 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process AB054C177F56B9783FC8F2CF710F9AC2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AB054C177F56B9783FC8F2CF710F9AC2_1... done.
Writting process AB054C177F56B9783FC8F2CF710F9AC2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAB054C177F56B9783FC8F2CF710F9AC2.report
Scheduling successful
submit!!!
jobs = 123
day = 136 run = 15136041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136041/*.root.log: No such file or directory
233
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:10:44 PDT] Dataset size is 233 files
Removing files not on site LBL
[2017.09.05 13:10:44 PDT] Dataset size is 233 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:10:44 PDT] Dataset size is 233 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:10:44 PDT] Started with 233 files, current size is 233files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:10:44 PDT] Dataset size is 233 files
----------------------------------------------------
validating dataset ....passed
Writting process 9B54FBD53C70811E6E584A4349D125AF_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9B54FBD53C70811E6E584A4349D125AF_2... done.
Writting process 9B54FBD53C70811E6E584A4349D125AF_1... done.
Writting process 9B54FBD53C70811E6E584A4349D125AF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9B54FBD53C70811E6E584A4349D125AF.report
Scheduling successful
submit!!!
jobs = 126
day = 136 run = 15136042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15136042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15136042/*.root.log: No such file or directory
144
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:11:55 PDT] Dataset size is 144 files
Removing files not on site LBL
[2017.09.05 13:11:55 PDT] Dataset size is 144 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:11:55 PDT] Dataset size is 144 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:11:56 PDT] Started with 144 files, current size is 144files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:11:56 PDT] Dataset size is 144 files
----------------------------------------------------
validating dataset ....passed
Writting process 3BB4C59A3D197B55D1BD86EA4FF1EF13_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3BB4C59A3D197B55D1BD86EA4FF1EF13_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3BB4C59A3D197B55D1BD86EA4FF1EF13.report
Scheduling successful
submit!!!
Job submission for day 136 finished!
137
jobs = 126
day = 137 run = 15137032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15137032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15137032/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:13:08 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.05 13:13:08 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:13:08 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:13:08 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:13:08 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process 8A528A2408D098A549FDF4BD8DDBFCAA_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8A528A2408D098A549FDF4BD8DDBFCAA_2... done.
Writting process 8A528A2408D098A549FDF4BD8DDBFCAA_1... done.
Writting process 8A528A2408D098A549FDF4BD8DDBFCAA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8A528A2408D098A549FDF4BD8DDBFCAA.report
Scheduling successful
submit!!!
jobs = 129
day = 137 run = 15137033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15137033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15137033/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:14:20 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 13:14:20 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:14:20 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:14:20 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:14:20 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 7DBA6176C04C20CC1EF7604B6F420ED0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7DBA6176C04C20CC1EF7604B6F420ED0_1... done.
Writting process 7DBA6176C04C20CC1EF7604B6F420ED0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7DBA6176C04C20CC1EF7604B6F420ED0.report
Scheduling successful
submit!!!
jobs = 130
day = 137 run = 15137034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15137034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15137034/*.root.log: No such file or directory
209
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:15:33 PDT] Dataset size is 209 files
Removing files not on site LBL
[2017.09.05 13:15:33 PDT] Dataset size is 209 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:15:33 PDT] Dataset size is 209 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:15:33 PDT] Started with 209 files, current size is 209files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:15:33 PDT] Dataset size is 209 files
----------------------------------------------------
validating dataset ....passed
Writting process 038E1AE282908FFC0FD7BDAA187F4F42_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 038E1AE282908FFC0FD7BDAA187F4F42_2... done.
Writting process 038E1AE282908FFC0FD7BDAA187F4F42_1... done.
Writting process 038E1AE282908FFC0FD7BDAA187F4F42_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched038E1AE282908FFC0FD7BDAA187F4F42.report
Scheduling successful
submit!!!
jobs = 133
day = 137 run = 15137035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15137035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15137035/*.root.log: No such file or directory
226
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:16:47 PDT] Dataset size is 226 files
Removing files not on site LBL
[2017.09.05 13:16:47 PDT] Dataset size is 226 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:16:47 PDT] Dataset size is 226 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:16:47 PDT] Started with 226 files, current size is 226files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:16:47 PDT] Dataset size is 226 files
----------------------------------------------------
validating dataset ....passed
Writting process B8B0059B563481627A5DEC5F3BA48098_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B8B0059B563481627A5DEC5F3BA48098_2... done.
Writting process B8B0059B563481627A5DEC5F3BA48098_1... done.
Writting process B8B0059B563481627A5DEC5F3BA48098_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB8B0059B563481627A5DEC5F3BA48098.report
Scheduling successful
submit!!!
jobs = 134
day = 137 run = 15137036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15137036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15137036/*.root.log: No such file or directory
250
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:18:01 PDT] Dataset size is 250 files
Removing files not on site LBL
[2017.09.05 13:18:01 PDT] Dataset size is 250 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:18:01 PDT] Dataset size is 250 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:18:02 PDT] Started with 250 files, current size is 250files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:18:02 PDT] Dataset size is 250 files
----------------------------------------------------
validating dataset ....passed
Writting process 66B83FEF2E7A71EEB2A5ED6E78CC36D8_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 66B83FEF2E7A71EEB2A5ED6E78CC36D8_3... done.
Writting process 66B83FEF2E7A71EEB2A5ED6E78CC36D8_2... done.
Writting process 66B83FEF2E7A71EEB2A5ED6E78CC36D8_1... done.
Writting process 66B83FEF2E7A71EEB2A5ED6E78CC36D8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched66B83FEF2E7A71EEB2A5ED6E78CC36D8.report
Scheduling successful
submit!!!
jobs = 138
day = 137 run = 15137037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15137037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15137037/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:19:13 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 13:19:14 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:19:14 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:19:16 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:19:17 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process A3AD41A44F0EA0FB770DCA87325B0614_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A3AD41A44F0EA0FB770DCA87325B0614_1... done.
Writting process A3AD41A44F0EA0FB770DCA87325B0614_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA3AD41A44F0EA0FB770DCA87325B0614.report
Scheduling successful
submit!!!
jobs = 138
day = 137 run = 15137038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15137038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15137038/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:20:28 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 13:20:28 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:20:28 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:20:28 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:20:28 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process CEF29A092340058BA0FA3EC52283E927_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CEF29A092340058BA0FA3EC52283E927_1... done.
Writting process CEF29A092340058BA0FA3EC52283E927_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCEF29A092340058BA0FA3EC52283E927.report
Scheduling successful
submit!!!
Job submission for day 137 finished!
138
jobs = 132
day = 138 run = 15138062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138062/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:21:40 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 13:21:40 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:21:40 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:21:40 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:21:41 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process B072F3969D6B143CD502F835F01F698A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B072F3969D6B143CD502F835F01F698A_1... done.
Writting process B072F3969D6B143CD502F835F01F698A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB072F3969D6B143CD502F835F01F698A.report
Scheduling successful
submit!!!
jobs = 133
day = 138 run = 15138063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138063/*.root.log: No such file or directory
128
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:22:51 PDT] Dataset size is 128 files
Removing files not on site LBL
[2017.09.05 13:22:51 PDT] Dataset size is 128 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:22:51 PDT] Dataset size is 128 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:22:51 PDT] Started with 128 files, current size is 128files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:22:51 PDT] Dataset size is 128 files
----------------------------------------------------
validating dataset ....passed
Writting process 3AF5617D5F6F256E42083A21B268E926_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3AF5617D5F6F256E42083A21B268E926_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3AF5617D5F6F256E42083A21B268E926.report
Scheduling successful
submit!!!
jobs = 130
day = 138 run = 15138064
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138064/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138064/*.root.log: No such file or directory
211
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:24:04 PDT] Dataset size is 211 files
Removing files not on site LBL
[2017.09.05 13:24:04 PDT] Dataset size is 211 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:24:04 PDT] Dataset size is 211 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:24:04 PDT] Started with 211 files, current size is 211files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:24:04 PDT] Dataset size is 211 files
----------------------------------------------------
validating dataset ....passed
Writting process 180E6EA3AC6E19C66F599310854A15F6_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 180E6EA3AC6E19C66F599310854A15F6_2... done.
Writting process 180E6EA3AC6E19C66F599310854A15F6_1... done.
Writting process 180E6EA3AC6E19C66F599310854A15F6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched180E6EA3AC6E19C66F599310854A15F6.report
Scheduling successful
submit!!!
jobs = 131
day = 138 run = 15138065
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138065/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138065/*.root.log: No such file or directory
236
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:25:17 PDT] Dataset size is 236 files
Removing files not on site LBL
[2017.09.05 13:25:17 PDT] Dataset size is 236 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:25:18 PDT] Dataset size is 236 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:25:18 PDT] Started with 236 files, current size is 236files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:25:18 PDT] Dataset size is 236 files
----------------------------------------------------
validating dataset ....passed
Writting process 951CC2611A0BB333B2D56E7495D78EBF_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 951CC2611A0BB333B2D56E7495D78EBF_2... done.
Writting process 951CC2611A0BB333B2D56E7495D78EBF_1... done.
Writting process 951CC2611A0BB333B2D56E7495D78EBF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched951CC2611A0BB333B2D56E7495D78EBF.report
Scheduling successful
submit!!!
jobs = 134
day = 138 run = 15138066
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138066/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138066/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:26:29 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 13:26:29 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:26:29 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:26:29 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:26:29 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 870D93729CF2E7DB3D792C02C3FB19D1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 870D93729CF2E7DB3D792C02C3FB19D1_1... done.
Writting process 870D93729CF2E7DB3D792C02C3FB19D1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched870D93729CF2E7DB3D792C02C3FB19D1.report
Scheduling successful
submit!!!
jobs = 136
day = 138 run = 15138067
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138067/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138067/*.root.log: No such file or directory
140
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:27:39 PDT] Dataset size is 140 files
Removing files not on site LBL
[2017.09.05 13:27:40 PDT] Dataset size is 140 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:27:40 PDT] Dataset size is 140 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:27:40 PDT] Started with 140 files, current size is 140files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:27:40 PDT] Dataset size is 140 files
----------------------------------------------------
validating dataset ....passed
Writting process 1CE0802E4A29B7A840F314DE68050F97_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1CE0802E4A29B7A840F314DE68050F97_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1CE0802E4A29B7A840F314DE68050F97.report
Scheduling successful
submit!!!
jobs = 137
day = 138 run = 15138068
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138068/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138068/*.root.log: No such file or directory
151
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:28:51 PDT] Dataset size is 151 files
Removing files not on site LBL
[2017.09.05 13:28:51 PDT] Dataset size is 151 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:28:51 PDT] Dataset size is 151 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:28:51 PDT] Started with 151 files, current size is 151files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:28:51 PDT] Dataset size is 151 files
----------------------------------------------------
validating dataset ....passed
Writting process 014E636E08CDEB48FAA495F528DDD926_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 014E636E08CDEB48FAA495F528DDD926_1... done.
Writting process 014E636E08CDEB48FAA495F528DDD926_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched014E636E08CDEB48FAA495F528DDD926.report
Scheduling successful
submit!!!
jobs = 137
day = 138 run = 15138069
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138069/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138069/*.root.log: No such file or directory
49
49 49
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:29:59 PDT] Dataset size is 49 files
Removing files not on site LBL
[2017.09.05 13:29:59 PDT] Dataset size is 49 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:29:59 PDT] Dataset size is 49 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:29:59 PDT] Started with 49 files, current size is 49files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=49 ,maxSize=49 )
[2017.09.05 13:29:59 PDT] Dataset size is 49 files
----------------------------------------------------
validating dataset ....passed
Writting process DEA68798D4417417084D6BE898EE9D89_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDEA68798D4417417084D6BE898EE9D89.report
Scheduling successful
submit!!!
jobs = 135
day = 138 run = 15138070
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138070/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138070/*.root.log: No such file or directory
164
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:31:10 PDT] Dataset size is 164 files
Removing files not on site LBL
[2017.09.05 13:31:10 PDT] Dataset size is 164 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:31:10 PDT] Dataset size is 164 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:31:11 PDT] Started with 164 files, current size is 164files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:31:11 PDT] Dataset size is 164 files
----------------------------------------------------
validating dataset ....passed
Writting process DC543E4B66C735461259C301297B93DC_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DC543E4B66C735461259C301297B93DC_1... done.
Writting process DC543E4B66C735461259C301297B93DC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDC543E4B66C735461259C301297B93DC.report
Scheduling successful
submit!!!
jobs = 136
day = 138 run = 15138071
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138071/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138071/*.root.log: No such file or directory
135
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:32:21 PDT] Dataset size is 135 files
Removing files not on site LBL
[2017.09.05 13:32:21 PDT] Dataset size is 135 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:32:21 PDT] Dataset size is 135 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:32:21 PDT] Started with 135 files, current size is 135files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:32:21 PDT] Dataset size is 135 files
----------------------------------------------------
validating dataset ....passed
Writting process 1B8E1FAD275A3194AC5F288B3B589762_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1B8E1FAD275A3194AC5F288B3B589762_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1B8E1FAD275A3194AC5F288B3B589762.report
Scheduling successful
submit!!!
jobs = 136
day = 138 run = 15138074
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138074/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138074/*.root.log: No such file or directory
96
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:33:30 PDT] Dataset size is 96 files
Removing files not on site LBL
[2017.09.05 13:33:30 PDT] Dataset size is 96 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:33:30 PDT] Dataset size is 96 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:33:30 PDT] Started with 96 files, current size is 96files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:33:30 PDT] Dataset size is 96 files
----------------------------------------------------
validating dataset ....passed
Writting process 634AB7A4AB8F8ACF8F4A41287EFB35A1_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched634AB7A4AB8F8ACF8F4A41287EFB35A1.report
Scheduling successful
submit!!!
jobs = 130
day = 138 run = 15138075
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15138075/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15138075/*.root.log: No such file or directory
221
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:34:43 PDT] Dataset size is 221 files
Removing files not on site LBL
[2017.09.05 13:34:43 PDT] Dataset size is 221 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:34:43 PDT] Dataset size is 221 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:34:43 PDT] Started with 221 files, current size is 221files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:34:43 PDT] Dataset size is 221 files
----------------------------------------------------
validating dataset ....passed
Writting process 884322B6BE66100EC4938E41B73704A6_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 884322B6BE66100EC4938E41B73704A6_2... done.
Writting process 884322B6BE66100EC4938E41B73704A6_1... done.
Writting process 884322B6BE66100EC4938E41B73704A6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched884322B6BE66100EC4938E41B73704A6.report
Scheduling successful
submit!!!
Job submission for day 138 finished!
139
jobs = 129
day = 139 run = 15139016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139016/*.root.log: No such file or directory
143
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:35:54 PDT] Dataset size is 143 files
Removing files not on site LBL
[2017.09.05 13:35:54 PDT] Dataset size is 143 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:35:54 PDT] Dataset size is 143 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:35:54 PDT] Started with 143 files, current size is 143files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:35:54 PDT] Dataset size is 143 files
----------------------------------------------------
validating dataset ....passed
Writting process 55DA5544EAD8147A5CE162C7F7F0D893_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 55DA5544EAD8147A5CE162C7F7F0D893_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched55DA5544EAD8147A5CE162C7F7F0D893.report
Scheduling successful
submit!!!
jobs = 121
day = 139 run = 15139017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139017/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:37:07 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 13:37:07 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:37:07 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:37:08 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:37:08 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process CDC6257853E986CD15902A9A3E77EEAD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CDC6257853E986CD15902A9A3E77EEAD_1... done.
Writting process CDC6257853E986CD15902A9A3E77EEAD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCDC6257853E986CD15902A9A3E77EEAD.report
Scheduling successful
submit!!!
jobs = 120
day = 139 run = 15139018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139018/*.root.log: No such file or directory
212
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:38:21 PDT] Dataset size is 212 files
Removing files not on site LBL
[2017.09.05 13:38:21 PDT] Dataset size is 212 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:38:21 PDT] Dataset size is 212 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:38:22 PDT] Started with 212 files, current size is 212files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:38:22 PDT] Dataset size is 212 files
----------------------------------------------------
validating dataset ....passed
Writting process AD0892E1882D7977691B262268D08C17_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AD0892E1882D7977691B262268D08C17_2... done.
Writting process AD0892E1882D7977691B262268D08C17_1... done.
Writting process AD0892E1882D7977691B262268D08C17_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD0892E1882D7977691B262268D08C17.report
Scheduling successful
submit!!!
jobs = 118
day = 139 run = 15139020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139020/*.root.log: No such file or directory
219
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:39:36 PDT] Dataset size is 219 files
Removing files not on site LBL
[2017.09.05 13:39:36 PDT] Dataset size is 219 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:39:36 PDT] Dataset size is 219 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:39:36 PDT] Started with 219 files, current size is 219files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:39:36 PDT] Dataset size is 219 files
----------------------------------------------------
validating dataset ....passed
Writting process FAE614FF3593C18FE6EE1FAB56B3428D_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FAE614FF3593C18FE6EE1FAB56B3428D_2... done.
Writting process FAE614FF3593C18FE6EE1FAB56B3428D_1... done.
Writting process FAE614FF3593C18FE6EE1FAB56B3428D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFAE614FF3593C18FE6EE1FAB56B3428D.report
Scheduling successful
submit!!!
jobs = 120
day = 139 run = 15139021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139021/*.root.log: No such file or directory
219
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:40:49 PDT] Dataset size is 219 files
Removing files not on site LBL
[2017.09.05 13:40:49 PDT] Dataset size is 219 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:40:49 PDT] Dataset size is 219 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:40:49 PDT] Started with 219 files, current size is 219files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:40:49 PDT] Dataset size is 219 files
----------------------------------------------------
validating dataset ....passed
Writting process 686729EC432DD0A1087CC921B10C9CC3_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 686729EC432DD0A1087CC921B10C9CC3_2... done.
Writting process 686729EC432DD0A1087CC921B10C9CC3_1... done.
Writting process 686729EC432DD0A1087CC921B10C9CC3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched686729EC432DD0A1087CC921B10C9CC3.report
Scheduling successful
submit!!!
jobs = 122
day = 139 run = 15139022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139022/*.root.log: No such file or directory
288
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:42:04 PDT] Dataset size is 288 files
Removing files not on site LBL
[2017.09.05 13:42:04 PDT] Dataset size is 288 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:42:04 PDT] Dataset size is 288 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:42:04 PDT] Started with 288 files, current size is 288files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:42:04 PDT] Dataset size is 288 files
----------------------------------------------------
validating dataset ....passed
Writting process D46FDC18C7D1470546D88ED6F6AA5A45_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D46FDC18C7D1470546D88ED6F6AA5A45_3... done.
Writting process D46FDC18C7D1470546D88ED6F6AA5A45_2... done.
Writting process D46FDC18C7D1470546D88ED6F6AA5A45_1... done.
Writting process D46FDC18C7D1470546D88ED6F6AA5A45_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD46FDC18C7D1470546D88ED6F6AA5A45.report
Scheduling successful
submit!!!
jobs = 126
day = 139 run = 15139023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139023/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:43:16 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 13:43:16 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:43:16 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:43:16 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:43:16 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 25E5A4185F84883E5789CD939657196A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 25E5A4185F84883E5789CD939657196A_1... done.
Writting process 25E5A4185F84883E5789CD939657196A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched25E5A4185F84883E5789CD939657196A.report
Scheduling successful
submit!!!
jobs = 126
day = 139 run = 15139024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139024/*.root.log: No such file or directory
236
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:44:29 PDT] Dataset size is 236 files
Removing files not on site LBL
[2017.09.05 13:44:29 PDT] Dataset size is 236 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:44:29 PDT] Dataset size is 236 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:44:30 PDT] Started with 236 files, current size is 236files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:44:30 PDT] Dataset size is 236 files
----------------------------------------------------
validating dataset ....passed
Writting process B0FCCE0E24E863D649240DB159928DCF_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B0FCCE0E24E863D649240DB159928DCF_2... done.
Writting process B0FCCE0E24E863D649240DB159928DCF_1... done.
Writting process B0FCCE0E24E863D649240DB159928DCF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB0FCCE0E24E863D649240DB159928DCF.report
Scheduling successful
submit!!!
jobs = 128
day = 139 run = 15139025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139025/*.root.log: No such file or directory
254
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:45:44 PDT] Dataset size is 254 files
Removing files not on site LBL
[2017.09.05 13:45:44 PDT] Dataset size is 254 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:45:44 PDT] Dataset size is 254 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:45:44 PDT] Started with 254 files, current size is 254files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:45:44 PDT] Dataset size is 254 files
----------------------------------------------------
validating dataset ....passed
Writting process 1FD0A39B8BF19644A45156067F26A8BA_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1FD0A39B8BF19644A45156067F26A8BA_3... done.
Writting process 1FD0A39B8BF19644A45156067F26A8BA_2... done.
Writting process 1FD0A39B8BF19644A45156067F26A8BA_1... done.
Writting process 1FD0A39B8BF19644A45156067F26A8BA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1FD0A39B8BF19644A45156067F26A8BA.report
Scheduling successful
submit!!!
jobs = 129
day = 139 run = 15139026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139026/*.root.log: No such file or directory
254
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:46:58 PDT] Dataset size is 254 files
Removing files not on site LBL
[2017.09.05 13:46:58 PDT] Dataset size is 254 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:46:58 PDT] Dataset size is 254 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:46:59 PDT] Started with 254 files, current size is 254files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:46:59 PDT] Dataset size is 254 files
----------------------------------------------------
validating dataset ....passed
Writting process AC6217CF00440C850324C3FD8CC5172B_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AC6217CF00440C850324C3FD8CC5172B_3... done.
Writting process AC6217CF00440C850324C3FD8CC5172B_2... done.
Writting process AC6217CF00440C850324C3FD8CC5172B_1... done.
Writting process AC6217CF00440C850324C3FD8CC5172B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAC6217CF00440C850324C3FD8CC5172B.report
Scheduling successful
submit!!!
jobs = 131
day = 139 run = 15139044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139044/*.root.log: No such file or directory
145
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:48:10 PDT] Dataset size is 145 files
Removing files not on site LBL
[2017.09.05 13:48:10 PDT] Dataset size is 145 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:48:10 PDT] Dataset size is 145 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:48:10 PDT] Started with 145 files, current size is 145files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:48:10 PDT] Dataset size is 145 files
----------------------------------------------------
validating dataset ....passed
Writting process 13278470828A6DD584F9A99D30F4B06D_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 13278470828A6DD584F9A99D30F4B06D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched13278470828A6DD584F9A99D30F4B06D.report
Scheduling successful
submit!!!
jobs = 132
day = 139 run = 15139045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139045/*.root.log: No such file or directory
149
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:49:21 PDT] Dataset size is 149 files
Removing files not on site LBL
[2017.09.05 13:49:21 PDT] Dataset size is 149 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:49:21 PDT] Dataset size is 149 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:49:21 PDT] Started with 149 files, current size is 149files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:49:21 PDT] Dataset size is 149 files
----------------------------------------------------
validating dataset ....passed
Writting process 95C1F40F8F284125412A093A3B530766_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 95C1F40F8F284125412A093A3B530766_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched95C1F40F8F284125412A093A3B530766.report
Scheduling successful
submit!!!
jobs = 129
day = 139 run = 15139046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139046/*.root.log: No such file or directory
236
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:50:35 PDT] Dataset size is 236 files
Removing files not on site LBL
[2017.09.05 13:50:36 PDT] Dataset size is 236 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:50:36 PDT] Dataset size is 236 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:50:36 PDT] Started with 236 files, current size is 236files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:50:37 PDT] Dataset size is 236 files
----------------------------------------------------
validating dataset ....passed
Writting process 300A951AC4C9145A2C0BBEA8EB56CBDE_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 300A951AC4C9145A2C0BBEA8EB56CBDE_2... done.
Writting process 300A951AC4C9145A2C0BBEA8EB56CBDE_1... done.
Writting process 300A951AC4C9145A2C0BBEA8EB56CBDE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched300A951AC4C9145A2C0BBEA8EB56CBDE.report
Scheduling successful
submit!!!
jobs = 127
day = 139 run = 15139047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139047/*.root.log: No such file or directory
230
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:51:51 PDT] Dataset size is 230 files
Removing files not on site LBL
[2017.09.05 13:51:51 PDT] Dataset size is 230 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:51:51 PDT] Dataset size is 230 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:51:52 PDT] Started with 230 files, current size is 230files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:51:52 PDT] Dataset size is 230 files
----------------------------------------------------
validating dataset ....passed
Writting process 6CDFA348FAF32E2F9FA6D8844A0EE3A7_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6CDFA348FAF32E2F9FA6D8844A0EE3A7_2... done.
Writting process 6CDFA348FAF32E2F9FA6D8844A0EE3A7_1... done.
Writting process 6CDFA348FAF32E2F9FA6D8844A0EE3A7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6CDFA348FAF32E2F9FA6D8844A0EE3A7.report
Scheduling successful
submit!!!
jobs = 126
day = 139 run = 15139050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139050/*.root.log: No such file or directory
248
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:53:06 PDT] Dataset size is 248 files
Removing files not on site LBL
[2017.09.05 13:53:06 PDT] Dataset size is 248 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:53:06 PDT] Dataset size is 248 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:53:07 PDT] Started with 248 files, current size is 248files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:53:07 PDT] Dataset size is 248 files
----------------------------------------------------
validating dataset ....passed
Writting process ADD055B96A53E1050131CDE88E58A0FE_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ADD055B96A53E1050131CDE88E58A0FE_2... done.
Writting process ADD055B96A53E1050131CDE88E58A0FE_1... done.
Writting process ADD055B96A53E1050131CDE88E58A0FE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedADD055B96A53E1050131CDE88E58A0FE.report
Scheduling successful
submit!!!
jobs = 125
day = 139 run = 15139051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139051/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:54:20 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 13:54:20 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:54:20 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:54:21 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:54:21 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process E0BE3C372BE3770086034E18763D4CAB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E0BE3C372BE3770086034E18763D4CAB_1... done.
Writting process E0BE3C372BE3770086034E18763D4CAB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE0BE3C372BE3770086034E18763D4CAB.report
Scheduling successful
submit!!!
jobs = 123
day = 139 run = 15139052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15139052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15139052/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:55:32 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 13:55:32 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:55:32 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:55:32 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:55:32 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 64B5849E707F5443AB26EFECF7DCDDC2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 64B5849E707F5443AB26EFECF7DCDDC2_1... done.
Writting process 64B5849E707F5443AB26EFECF7DCDDC2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched64B5849E707F5443AB26EFECF7DCDDC2.report
Scheduling successful
submit!!!
Job submission for day 139 finished!
140
jobs = 120
day = 140 run = 15140002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140002/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:56:44 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 13:56:44 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:56:44 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:56:45 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:56:45 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process F8A9481673DD6D56DB36968DC58D85E6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F8A9481673DD6D56DB36968DC58D85E6_1... done.
Writting process F8A9481673DD6D56DB36968DC58D85E6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF8A9481673DD6D56DB36968DC58D85E6.report
Scheduling successful
submit!!!
jobs = 119
day = 140 run = 15140003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140003/*.root.log: No such file or directory
117
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:57:55 PDT] Dataset size is 117 files
Removing files not on site LBL
[2017.09.05 13:57:55 PDT] Dataset size is 117 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:57:55 PDT] Dataset size is 117 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:57:55 PDT] Started with 117 files, current size is 117files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:57:55 PDT] Dataset size is 117 files
----------------------------------------------------
validating dataset ....passed
Writting process 4BCADC770B6E2AE86D3601C64E157F28_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4BCADC770B6E2AE86D3601C64E157F28_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4BCADC770B6E2AE86D3601C64E157F28.report
Scheduling successful
submit!!!
jobs = 117
day = 140 run = 15140004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140004/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 13:59:07 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 13:59:08 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 13:59:08 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 13:59:08 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 13:59:09 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 750209ACA41345E61E3D4B5E5ABA3D33_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 750209ACA41345E61E3D4B5E5ABA3D33_1... done.
Writting process 750209ACA41345E61E3D4B5E5ABA3D33_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched750209ACA41345E61E3D4B5E5ABA3D33.report
Scheduling successful
submit!!!
jobs = 115
day = 140 run = 15140005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140005/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:00:24 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 14:00:24 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:00:24 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:00:24 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:00:24 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process AB0DE7F30218BB2F8E6596C14FFBBD25_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AB0DE7F30218BB2F8E6596C14FFBBD25_1... done.
Writting process AB0DE7F30218BB2F8E6596C14FFBBD25_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAB0DE7F30218BB2F8E6596C14FFBBD25.report
Scheduling successful
submit!!!
jobs = 115
day = 140 run = 15140006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140006/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:01:38 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 14:01:38 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:01:38 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:01:38 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:01:38 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process B742E877AE9D256E5B2B1473C2A781A8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B742E877AE9D256E5B2B1473C2A781A8_1... done.
Writting process B742E877AE9D256E5B2B1473C2A781A8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB742E877AE9D256E5B2B1473C2A781A8.report
Scheduling successful
submit!!!
jobs = 113
day = 140 run = 15140007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140007/*.root.log: No such file or directory
155
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:02:53 PDT] Dataset size is 155 files
Removing files not on site LBL
[2017.09.05 14:02:53 PDT] Dataset size is 155 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:02:53 PDT] Dataset size is 155 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:02:54 PDT] Started with 155 files, current size is 155files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:02:54 PDT] Dataset size is 155 files
----------------------------------------------------
validating dataset ....passed
Writting process D35245810B93F45AB3FBF8F7B9E03C98_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D35245810B93F45AB3FBF8F7B9E03C98_1... done.
Writting process D35245810B93F45AB3FBF8F7B9E03C98_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD35245810B93F45AB3FBF8F7B9E03C98.report
Scheduling successful
submit!!!
jobs = 111
day = 140 run = 15140018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140018/*.root.log: No such file or directory
160
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:04:06 PDT] Dataset size is 160 files
Removing files not on site LBL
[2017.09.05 14:04:07 PDT] Dataset size is 160 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:04:07 PDT] Dataset size is 160 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:04:08 PDT] Started with 160 files, current size is 160files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:04:08 PDT] Dataset size is 160 files
----------------------------------------------------
validating dataset ....passed
Writting process 9E1A88CFC04AAD255DA22628D9C1E7CB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9E1A88CFC04AAD255DA22628D9C1E7CB_1... done.
Writting process 9E1A88CFC04AAD255DA22628D9C1E7CB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9E1A88CFC04AAD255DA22628D9C1E7CB.report
Scheduling successful
submit!!!
jobs = 113
day = 140 run = 15140019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140019/*.root.log: No such file or directory
69
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:05:17 PDT] Dataset size is 69 files
Removing files not on site LBL
[2017.09.05 14:05:17 PDT] Dataset size is 69 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:05:17 PDT] Dataset size is 69 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:05:17 PDT] Started with 69 files, current size is 69files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:05:18 PDT] Dataset size is 69 files
----------------------------------------------------
validating dataset ....passed
Writting process E7FD3566B349157AABFE8A8B70F65627_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE7FD3566B349157AABFE8A8B70F65627.report
Scheduling successful
submit!!!
jobs = 113
day = 140 run = 15140020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140020/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:06:29 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 14:06:29 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:06:29 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:06:30 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:06:30 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process 283CE41AB50D0F428FD47B3826D14E23_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 283CE41AB50D0F428FD47B3826D14E23_1... done.
Writting process 283CE41AB50D0F428FD47B3826D14E23_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched283CE41AB50D0F428FD47B3826D14E23.report
Scheduling successful
submit!!!
jobs = 112
day = 140 run = 15140021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140021/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:07:41 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 14:07:42 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:07:42 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:07:42 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:07:42 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 0E9C6BCF50E356BB7C9DC2EE39E0E67A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0E9C6BCF50E356BB7C9DC2EE39E0E67A_1... done.
Writting process 0E9C6BCF50E356BB7C9DC2EE39E0E67A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0E9C6BCF50E356BB7C9DC2EE39E0E67A.report
Scheduling successful
submit!!!
jobs = 108
day = 140 run = 15140022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140022/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:08:54 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 14:08:54 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:08:54 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:08:55 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:08:55 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 798A988F4D1D7A487B773BB0D97CC0F2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 798A988F4D1D7A487B773BB0D97CC0F2_1... done.
Writting process 798A988F4D1D7A487B773BB0D97CC0F2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched798A988F4D1D7A487B773BB0D97CC0F2.report
Scheduling successful
submit!!!
jobs = 104
day = 140 run = 15140023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140023/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:10:06 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 14:10:06 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:10:06 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:10:06 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:10:06 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 4119B6E420F259EE82DF88A16263851E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4119B6E420F259EE82DF88A16263851E_1... done.
Writting process 4119B6E420F259EE82DF88A16263851E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4119B6E420F259EE82DF88A16263851E.report
Scheduling successful
submit!!!
jobs = 105
day = 140 run = 15140025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140025/*.root.log: No such file or directory
32
32 32
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:11:13 PDT] Dataset size is 32 files
Removing files not on site LBL
[2017.09.05 14:11:13 PDT] Dataset size is 32 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:11:13 PDT] Dataset size is 32 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:11:13 PDT] Started with 32 files, current size is 32files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=32 ,maxSize=32 )
[2017.09.05 14:11:13 PDT] Dataset size is 32 files
----------------------------------------------------
validating dataset ....passed
Writting process F4A9E4D94272DFCABCFDED21F1F51A75_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF4A9E4D94272DFCABCFDED21F1F51A75.report
Scheduling successful
submit!!!
jobs = 103
day = 140 run = 15140027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140027/*.root.log: No such file or directory
30
30 30
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:12:21 PDT] Dataset size is 30 files
Removing files not on site LBL
[2017.09.05 14:12:21 PDT] Dataset size is 30 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:12:21 PDT] Dataset size is 30 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:12:21 PDT] Started with 30 files, current size is 30files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=30 ,maxSize=30 )
[2017.09.05 14:12:21 PDT] Dataset size is 30 files
----------------------------------------------------
validating dataset ....passed
Writting process 0A1FC43ADB3245717316BFFEC60BF119_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0A1FC43ADB3245717316BFFEC60BF119.report
Scheduling successful
submit!!!
jobs = 104
day = 140 run = 15140028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140028/*.root.log: No such file or directory
135
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:13:31 PDT] Dataset size is 135 files
Removing files not on site LBL
[2017.09.05 14:13:32 PDT] Dataset size is 135 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:13:32 PDT] Dataset size is 135 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:13:32 PDT] Started with 135 files, current size is 135files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:13:32 PDT] Dataset size is 135 files
----------------------------------------------------
validating dataset ....passed
Writting process 71D21BBE892319B6D86BF65220F39E21_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 71D21BBE892319B6D86BF65220F39E21_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched71D21BBE892319B6D86BF65220F39E21.report
Scheduling successful
submit!!!
jobs = 102
day = 140 run = 15140029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140029/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:14:43 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 14:14:43 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:14:43 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:14:43 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:14:43 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process 0E0DA636605A3CE3A9F4532FFAF73A3E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0E0DA636605A3CE3A9F4532FFAF73A3E_1... done.
Writting process 0E0DA636605A3CE3A9F4532FFAF73A3E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0E0DA636605A3CE3A9F4532FFAF73A3E.report
Scheduling successful
submit!!!
jobs = 103
day = 140 run = 15140030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140030/*.root.log: No such file or directory
244
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:15:57 PDT] Dataset size is 244 files
Removing files not on site LBL
[2017.09.05 14:15:57 PDT] Dataset size is 244 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:15:57 PDT] Dataset size is 244 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:15:58 PDT] Started with 244 files, current size is 244files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:15:58 PDT] Dataset size is 244 files
----------------------------------------------------
validating dataset ....passed
Writting process 7BDAB041862287B24836DED8E6104D10_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7BDAB041862287B24836DED8E6104D10_2... done.
Writting process 7BDAB041862287B24836DED8E6104D10_1... done.
Writting process 7BDAB041862287B24836DED8E6104D10_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7BDAB041862287B24836DED8E6104D10.report
Scheduling successful
submit!!!
jobs = 104
day = 140 run = 15140031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140031/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:17:09 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 14:17:09 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:17:10 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:17:10 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:17:10 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 5184383381BBB8F2B42F7BF994AA2EC7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5184383381BBB8F2B42F7BF994AA2EC7_1... done.
Writting process 5184383381BBB8F2B42F7BF994AA2EC7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5184383381BBB8F2B42F7BF994AA2EC7.report
Scheduling successful
submit!!!
jobs = 106
day = 140 run = 15140032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140032/*.root.log: No such file or directory
163
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:18:21 PDT] Dataset size is 163 files
Removing files not on site LBL
[2017.09.05 14:18:21 PDT] Dataset size is 163 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:18:21 PDT] Dataset size is 163 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:18:21 PDT] Started with 163 files, current size is 163files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:18:21 PDT] Dataset size is 163 files
----------------------------------------------------
validating dataset ....passed
Writting process 50028E1F90E98A1790368BCA4F117C49_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 50028E1F90E98A1790368BCA4F117C49_1... done.
Writting process 50028E1F90E98A1790368BCA4F117C49_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched50028E1F90E98A1790368BCA4F117C49.report
Scheduling successful
submit!!!
jobs = 109
day = 140 run = 15140034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140034/*.root.log: No such file or directory
163
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:19:33 PDT] Dataset size is 163 files
Removing files not on site LBL
[2017.09.05 14:19:33 PDT] Dataset size is 163 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:19:33 PDT] Dataset size is 163 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:19:33 PDT] Started with 163 files, current size is 163files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:19:33 PDT] Dataset size is 163 files
----------------------------------------------------
validating dataset ....passed
Writting process 5A747BBB09DF6A56C6165FFEB374ED04_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5A747BBB09DF6A56C6165FFEB374ED04_1... done.
Writting process 5A747BBB09DF6A56C6165FFEB374ED04_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5A747BBB09DF6A56C6165FFEB374ED04.report
Scheduling successful
submit!!!
jobs = 109
day = 140 run = 15140035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140035/*.root.log: No such file or directory
74
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:20:41 PDT] Dataset size is 74 files
Removing files not on site LBL
[2017.09.05 14:20:41 PDT] Dataset size is 74 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:20:41 PDT] Dataset size is 74 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:20:41 PDT] Started with 74 files, current size is 74files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:20:41 PDT] Dataset size is 74 files
----------------------------------------------------
validating dataset ....passed
Writting process 230C8C5ED6CF93AB89BB20B6BDDBE0DD_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched230C8C5ED6CF93AB89BB20B6BDDBE0DD.report
Scheduling successful
submit!!!
jobs = 106
day = 140 run = 15140036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140036/*.root.log: No such file or directory
128
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:21:51 PDT] Dataset size is 128 files
Removing files not on site LBL
[2017.09.05 14:21:51 PDT] Dataset size is 128 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:21:51 PDT] Dataset size is 128 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:21:51 PDT] Started with 128 files, current size is 128files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:21:51 PDT] Dataset size is 128 files
----------------------------------------------------
validating dataset ....passed
Writting process 2495DDDD5E7C562A8F899E124E5F29D1_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2495DDDD5E7C562A8F899E124E5F29D1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2495DDDD5E7C562A8F899E124E5F29D1.report
Scheduling successful
submit!!!
jobs = 104
day = 140 run = 15140037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140037/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:23:02 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 14:23:03 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:23:03 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:23:03 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:23:03 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process FD23B3FA7AF40FACC0AA3EABCBC20AD6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FD23B3FA7AF40FACC0AA3EABCBC20AD6_1... done.
Writting process FD23B3FA7AF40FACC0AA3EABCBC20AD6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFD23B3FA7AF40FACC0AA3EABCBC20AD6.report
Scheduling successful
submit!!!
jobs = 102
day = 140 run = 15140050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140050/*.root.log: No such file or directory
62
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:24:11 PDT] Dataset size is 62 files
Removing files not on site LBL
[2017.09.05 14:24:11 PDT] Dataset size is 62 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:24:12 PDT] Dataset size is 62 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:24:12 PDT] Started with 62 files, current size is 62files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:24:13 PDT] Dataset size is 62 files
----------------------------------------------------
validating dataset ....passed
Writting process F3AD5A0324DB0391B3BFCF74C1378A5E_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF3AD5A0324DB0391B3BFCF74C1378A5E.report
Scheduling successful
submit!!!
jobs = 101
day = 140 run = 15140051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140051/*.root.log: No such file or directory
169
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:25:24 PDT] Dataset size is 169 files
Removing files not on site LBL
[2017.09.05 14:25:24 PDT] Dataset size is 169 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:25:24 PDT] Dataset size is 169 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:25:24 PDT] Started with 169 files, current size is 169files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:25:24 PDT] Dataset size is 169 files
----------------------------------------------------
validating dataset ....passed
Writting process 647BA925F72AF38B6FECB270C67615EB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 647BA925F72AF38B6FECB270C67615EB_1... done.
Writting process 647BA925F72AF38B6FECB270C67615EB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched647BA925F72AF38B6FECB270C67615EB.report
Scheduling successful
submit!!!
jobs = 101
day = 140 run = 15140052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140052/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:26:35 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 14:26:35 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:26:35 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:26:35 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:26:35 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process 90D9F80EBA7803C3AE9845BE56693D8A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 90D9F80EBA7803C3AE9845BE56693D8A_1... done.
Writting process 90D9F80EBA7803C3AE9845BE56693D8A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched90D9F80EBA7803C3AE9845BE56693D8A.report
Scheduling successful
submit!!!
jobs = 102
day = 140 run = 15140053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140053/*.root.log: No such file or directory
140
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:27:46 PDT] Dataset size is 140 files
Removing files not on site LBL
[2017.09.05 14:27:46 PDT] Dataset size is 140 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:27:46 PDT] Dataset size is 140 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:27:47 PDT] Started with 140 files, current size is 140files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:27:47 PDT] Dataset size is 140 files
----------------------------------------------------
validating dataset ....passed
Writting process AD625072C6F0B4245AF1D4E962DD4477_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AD625072C6F0B4245AF1D4E962DD4477_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD625072C6F0B4245AF1D4E962DD4477.report
Scheduling successful
submit!!!
jobs = 97
day = 140 run = 15140054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140054/*.root.log: No such file or directory
61
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:28:56 PDT] Dataset size is 61 files
Removing files not on site LBL
[2017.09.05 14:28:56 PDT] Dataset size is 61 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:28:56 PDT] Dataset size is 61 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:28:56 PDT] Started with 61 files, current size is 61files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:28:56 PDT] Dataset size is 61 files
----------------------------------------------------
validating dataset ....passed
Writting process 93C17C2322B19B74D225C13A250D3395_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched93C17C2322B19B74D225C13A250D3395.report
Scheduling successful
submit!!!
jobs = 97
day = 140 run = 15140055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15140055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15140055/*.root.log: No such file or directory
104
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:30:06 PDT] Dataset size is 104 files
Removing files not on site LBL
[2017.09.05 14:30:06 PDT] Dataset size is 104 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:30:06 PDT] Dataset size is 104 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:30:06 PDT] Started with 104 files, current size is 104files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:30:06 PDT] Dataset size is 104 files
----------------------------------------------------
validating dataset ....passed
Writting process 4D8C558FD3655324B31A671FE9302100_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4D8C558FD3655324B31A671FE9302100_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4D8C558FD3655324B31A671FE9302100.report
Scheduling successful
submit!!!
Job submission for day 140 finished!
141
jobs = 94
day = 141 run = 15141001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141001/*.root.log: No such file or directory
145
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:31:16 PDT] Dataset size is 145 files
Removing files not on site LBL
[2017.09.05 14:31:16 PDT] Dataset size is 145 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:31:16 PDT] Dataset size is 145 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:31:17 PDT] Started with 145 files, current size is 145files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:31:17 PDT] Dataset size is 145 files
----------------------------------------------------
validating dataset ....passed
Writting process 0BA99DB7074FF2678CF6AA8B2F176128_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0BA99DB7074FF2678CF6AA8B2F176128_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0BA99DB7074FF2678CF6AA8B2F176128.report
Scheduling successful
submit!!!
jobs = 91
day = 141 run = 15141002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141002/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:32:28 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 14:32:28 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:32:28 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:32:28 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:32:28 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process C1B5DB8552DAED7899199FC8068D2E53_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C1B5DB8552DAED7899199FC8068D2E53_1... done.
Writting process C1B5DB8552DAED7899199FC8068D2E53_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC1B5DB8552DAED7899199FC8068D2E53.report
Scheduling successful
submit!!!
jobs = 91
day = 141 run = 15141003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141003/*.root.log: No such file or directory
135
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:33:38 PDT] Dataset size is 135 files
Removing files not on site LBL
[2017.09.05 14:33:38 PDT] Dataset size is 135 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:33:38 PDT] Dataset size is 135 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:33:38 PDT] Started with 135 files, current size is 135files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:33:39 PDT] Dataset size is 135 files
----------------------------------------------------
validating dataset ....passed
Writting process 28017A55B7D3FA6324E4B4CFD9AAB9FB_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 28017A55B7D3FA6324E4B4CFD9AAB9FB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched28017A55B7D3FA6324E4B4CFD9AAB9FB.report
Scheduling successful
submit!!!
jobs = 90
day = 141 run = 15141004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141004/*.root.log: No such file or directory
138
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:34:49 PDT] Dataset size is 138 files
Removing files not on site LBL
[2017.09.05 14:34:49 PDT] Dataset size is 138 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:34:49 PDT] Dataset size is 138 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:34:49 PDT] Started with 138 files, current size is 138files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:34:49 PDT] Dataset size is 138 files
----------------------------------------------------
validating dataset ....passed
Writting process F38166E0AC0485DE8CAE6ADB57DE0A29_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F38166E0AC0485DE8CAE6ADB57DE0A29_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF38166E0AC0485DE8CAE6ADB57DE0A29.report
Scheduling successful
submit!!!
jobs = 89
day = 141 run = 15141006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141006/*.root.log: No such file or directory
143
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:35:59 PDT] Dataset size is 143 files
Removing files not on site LBL
[2017.09.05 14:35:59 PDT] Dataset size is 143 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:35:59 PDT] Dataset size is 143 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:35:59 PDT] Started with 143 files, current size is 143files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:35:59 PDT] Dataset size is 143 files
----------------------------------------------------
validating dataset ....passed
Writting process 6112590591FE4C5FFAB49A5D0E6EDD15_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6112590591FE4C5FFAB49A5D0E6EDD15_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6112590591FE4C5FFAB49A5D0E6EDD15.report
Scheduling successful
submit!!!
jobs = 89
day = 141 run = 15141007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141007/*.root.log: No such file or directory
116
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:37:09 PDT] Dataset size is 116 files
Removing files not on site LBL
[2017.09.05 14:37:09 PDT] Dataset size is 116 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:37:10 PDT] Dataset size is 116 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:37:10 PDT] Started with 116 files, current size is 116files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:37:10 PDT] Dataset size is 116 files
----------------------------------------------------
validating dataset ....passed
Writting process 8FBF079D1EF65A04AC07B2ECBF8D77FF_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8FBF079D1EF65A04AC07B2ECBF8D77FF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8FBF079D1EF65A04AC07B2ECBF8D77FF.report
Scheduling successful
submit!!!
jobs = 88
day = 141 run = 15141010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141010/*.root.log: No such file or directory
164
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:38:23 PDT] Dataset size is 164 files
Removing files not on site LBL
[2017.09.05 14:38:23 PDT] Dataset size is 164 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:38:24 PDT] Dataset size is 164 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:38:24 PDT] Started with 164 files, current size is 164files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:38:24 PDT] Dataset size is 164 files
----------------------------------------------------
validating dataset ....passed
Writting process 83A60A7C1E78E345AE039FD177F9EEA6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 83A60A7C1E78E345AE039FD177F9EEA6_1... done.
Writting process 83A60A7C1E78E345AE039FD177F9EEA6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched83A60A7C1E78E345AE039FD177F9EEA6.report
Scheduling successful
submit!!!
jobs = 84
day = 141 run = 15141011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141011/*.root.log: No such file or directory
133
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:39:34 PDT] Dataset size is 133 files
Removing files not on site LBL
[2017.09.05 14:39:34 PDT] Dataset size is 133 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:39:34 PDT] Dataset size is 133 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:39:34 PDT] Started with 133 files, current size is 133files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:39:34 PDT] Dataset size is 133 files
----------------------------------------------------
validating dataset ....passed
Writting process 882989A7EDA3112AC948A09521C321F5_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 882989A7EDA3112AC948A09521C321F5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched882989A7EDA3112AC948A09521C321F5.report
Scheduling successful
submit!!!
jobs = 85
day = 141 run = 15141012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141012/*.root.log: No such file or directory
56
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:40:41 PDT] Dataset size is 56 files
Removing files not on site LBL
[2017.09.05 14:40:42 PDT] Dataset size is 56 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:40:42 PDT] Dataset size is 56 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:40:42 PDT] Started with 56 files, current size is 56files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:40:42 PDT] Dataset size is 56 files
----------------------------------------------------
validating dataset ....passed
Writting process 764915FBE025A7C6DC531E81BFBA2DA5_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched764915FBE025A7C6DC531E81BFBA2DA5.report
Scheduling successful
submit!!!
jobs = 85
day = 141 run = 15141013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15141013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15141013/*.root.log: No such file or directory
101
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:41:51 PDT] Dataset size is 101 files
Removing files not on site LBL
[2017.09.05 14:41:51 PDT] Dataset size is 101 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:41:51 PDT] Dataset size is 101 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:41:51 PDT] Started with 101 files, current size is 101files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:41:51 PDT] Dataset size is 101 files
----------------------------------------------------
validating dataset ....passed
Writting process 4D1EF7F1621FD9EAF37A07A6676B62CF_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4D1EF7F1621FD9EAF37A07A6676B62CF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4D1EF7F1621FD9EAF37A07A6676B62CF.report
Scheduling successful
submit!!!
Job submission for day 141 finished!
142
jobs = 84
day = 142 run = 15142008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142008/*.root.log: No such file or directory
154
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:43:01 PDT] Dataset size is 154 files
Removing files not on site LBL
[2017.09.05 14:43:01 PDT] Dataset size is 154 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:43:01 PDT] Dataset size is 154 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:43:02 PDT] Started with 154 files, current size is 154files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:43:02 PDT] Dataset size is 154 files
----------------------------------------------------
validating dataset ....passed
Writting process 45C2D05257DBDD8E24EB74FB80B44F65_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 45C2D05257DBDD8E24EB74FB80B44F65_1... done.
Writting process 45C2D05257DBDD8E24EB74FB80B44F65_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched45C2D05257DBDD8E24EB74FB80B44F65.report
Scheduling successful
submit!!!
jobs = 86
day = 142 run = 15142011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142011/*.root.log: No such file or directory
159
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:44:12 PDT] Dataset size is 159 files
Removing files not on site LBL
[2017.09.05 14:44:12 PDT] Dataset size is 159 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:44:12 PDT] Dataset size is 159 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:44:13 PDT] Started with 159 files, current size is 159files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:44:13 PDT] Dataset size is 159 files
----------------------------------------------------
validating dataset ....passed
Writting process 923E161B5A81813E44F9B059DA86D123_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 923E161B5A81813E44F9B059DA86D123_1... done.
Writting process 923E161B5A81813E44F9B059DA86D123_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched923E161B5A81813E44F9B059DA86D123.report
Scheduling successful
submit!!!
jobs = 87
day = 142 run = 15142012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142012/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:45:24 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 14:45:24 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:45:24 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:45:24 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:45:24 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process 52B7DCACA1D752B68D70109C3343F61D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 52B7DCACA1D752B68D70109C3343F61D_1... done.
Writting process 52B7DCACA1D752B68D70109C3343F61D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched52B7DCACA1D752B68D70109C3343F61D.report
Scheduling successful
submit!!!
jobs = 87
day = 142 run = 15142013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142013/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:46:35 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 14:46:35 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:46:35 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:46:35 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:46:35 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process 96585ABB41DD224D7D308DE3C22F3AB3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 96585ABB41DD224D7D308DE3C22F3AB3_1... done.
Writting process 96585ABB41DD224D7D308DE3C22F3AB3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched96585ABB41DD224D7D308DE3C22F3AB3.report
Scheduling successful
submit!!!
jobs = 86
day = 142 run = 15142014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142014/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:47:46 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 14:47:46 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:47:46 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:47:46 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:47:46 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process BD68EF8FE910AB62738D25D4708DCBB5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BD68EF8FE910AB62738D25D4708DCBB5_1... done.
Writting process BD68EF8FE910AB62738D25D4708DCBB5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBD68EF8FE910AB62738D25D4708DCBB5.report
Scheduling successful
submit!!!
jobs = 88
day = 142 run = 15142015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142015/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:48:58 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 14:48:58 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:48:58 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:48:58 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:48:58 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process 55A8C1611E4C6DE08FD3C018432037A3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 55A8C1611E4C6DE08FD3C018432037A3_1... done.
Writting process 55A8C1611E4C6DE08FD3C018432037A3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched55A8C1611E4C6DE08FD3C018432037A3.report
Scheduling successful
submit!!!
jobs = 89
day = 142 run = 15142018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142018/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:50:10 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 14:50:10 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:50:10 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:50:10 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:50:10 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process 57AF19C54BA2328E335240CE64FD78DE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 57AF19C54BA2328E335240CE64FD78DE_1... done.
Writting process 57AF19C54BA2328E335240CE64FD78DE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched57AF19C54BA2328E335240CE64FD78DE.report
Scheduling successful
submit!!!
jobs = 87
day = 142 run = 15142021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142021/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:51:21 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 14:51:21 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:51:21 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:51:21 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:51:21 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process A877682741F1DA29D90F8A2EAB87F92A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A877682741F1DA29D90F8A2EAB87F92A_1... done.
Writting process A877682741F1DA29D90F8A2EAB87F92A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA877682741F1DA29D90F8A2EAB87F92A.report
Scheduling successful
submit!!!
jobs = 87
day = 142 run = 15142022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142022/*.root.log: No such file or directory
123
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:52:31 PDT] Dataset size is 123 files
Removing files not on site LBL
[2017.09.05 14:52:31 PDT] Dataset size is 123 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:52:31 PDT] Dataset size is 123 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:52:31 PDT] Started with 123 files, current size is 123files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:52:31 PDT] Dataset size is 123 files
----------------------------------------------------
validating dataset ....passed
Writting process F33DFAEE423AE8A7DFED21780911BE65_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F33DFAEE423AE8A7DFED21780911BE65_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF33DFAEE423AE8A7DFED21780911BE65.report
Scheduling successful
submit!!!
jobs = 83
day = 142 run = 15142025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15142025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15142025/*.root.log: No such file or directory
42
42 42
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:53:38 PDT] Dataset size is 42 files
Removing files not on site LBL
[2017.09.05 14:53:38 PDT] Dataset size is 42 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:53:38 PDT] Dataset size is 42 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:53:39 PDT] Started with 42 files, current size is 42files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=42 ,maxSize=42 )
[2017.09.05 14:53:39 PDT] Dataset size is 42 files
----------------------------------------------------
validating dataset ....passed
Writting process D3A721CC2836AD1E3DCFA7CF028D3B90_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD3A721CC2836AD1E3DCFA7CF028D3B90.report
Scheduling successful
submit!!!
Job submission for day 142 finished!
143
jobs = 82
day = 143 run = 15143032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143032/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:54:50 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 14:54:50 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:54:50 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:54:50 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:54:50 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 6BBBF75B5026FE2E700FB4ECC5629CC3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6BBBF75B5026FE2E700FB4ECC5629CC3_1... done.
Writting process 6BBBF75B5026FE2E700FB4ECC5629CC3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6BBBF75B5026FE2E700FB4ECC5629CC3.report
Scheduling successful
submit!!!
jobs = 84
day = 143 run = 15143033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143033/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:56:02 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 14:56:02 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:56:02 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:56:02 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:56:02 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process A057F4AD75FF4BD81688FA0139FA6424_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A057F4AD75FF4BD81688FA0139FA6424_1... done.
Writting process A057F4AD75FF4BD81688FA0139FA6424_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA057F4AD75FF4BD81688FA0139FA6424.report
Scheduling successful
submit!!!
jobs = 86
day = 143 run = 15143034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143034/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:57:14 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 14:57:14 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:57:14 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:57:14 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:57:14 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 647A7E270BA714E2930D4458CD3F1282_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 647A7E270BA714E2930D4458CD3F1282_1... done.
Writting process 647A7E270BA714E2930D4458CD3F1282_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched647A7E270BA714E2930D4458CD3F1282.report
Scheduling successful
submit!!!
jobs = 88
day = 143 run = 15143035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143035/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:58:26 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 14:58:26 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:58:26 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:58:26 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:58:26 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 06F0BE1CAFA1B28BD526AD4645EDAE1E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 06F0BE1CAFA1B28BD526AD4645EDAE1E_1... done.
Writting process 06F0BE1CAFA1B28BD526AD4645EDAE1E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched06F0BE1CAFA1B28BD526AD4645EDAE1E.report
Scheduling successful
submit!!!
jobs = 89
day = 143 run = 15143036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143036/*.root.log: No such file or directory
98
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 14:59:34 PDT] Dataset size is 98 files
Removing files not on site LBL
[2017.09.05 14:59:34 PDT] Dataset size is 98 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 14:59:35 PDT] Dataset size is 98 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 14:59:35 PDT] Started with 98 files, current size is 98files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 14:59:35 PDT] Dataset size is 98 files
----------------------------------------------------
validating dataset ....passed
Writting process 97BA4C8C017D720BD162A76F53B860F2_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched97BA4C8C017D720BD162A76F53B860F2.report
Scheduling successful
submit!!!
jobs = 88
day = 143 run = 15143037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143037/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:00:48 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 15:00:48 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:00:48 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:00:48 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:00:48 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 6E8B4D99AAF110F3053A727B2D62B8BB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6E8B4D99AAF110F3053A727B2D62B8BB_1... done.
Writting process 6E8B4D99AAF110F3053A727B2D62B8BB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6E8B4D99AAF110F3053A727B2D62B8BB.report
Scheduling successful
submit!!!
jobs = 88
day = 143 run = 15143038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143038/*.root.log: No such file or directory
135
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:01:58 PDT] Dataset size is 135 files
Removing files not on site LBL
[2017.09.05 15:01:58 PDT] Dataset size is 135 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:01:58 PDT] Dataset size is 135 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:01:58 PDT] Started with 135 files, current size is 135files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:01:59 PDT] Dataset size is 135 files
----------------------------------------------------
validating dataset ....passed
Writting process AD225EF4AE4775C7CCCB6B47785BBEA6_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AD225EF4AE4775C7CCCB6B47785BBEA6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD225EF4AE4775C7CCCB6B47785BBEA6.report
Scheduling successful
submit!!!
jobs = 89
day = 143 run = 15143039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143039/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:03:10 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 15:03:10 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:03:10 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:03:10 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:03:10 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process EE404F4C0FDCD587331C2431877AE62E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EE404F4C0FDCD587331C2431877AE62E_1... done.
Writting process EE404F4C0FDCD587331C2431877AE62E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEE404F4C0FDCD587331C2431877AE62E.report
Scheduling successful
submit!!!
jobs = 88
day = 143 run = 15143040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15143040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15143040/*.root.log: No such file or directory
248
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:04:23 PDT] Dataset size is 248 files
Removing files not on site LBL
[2017.09.05 15:04:23 PDT] Dataset size is 248 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:04:23 PDT] Dataset size is 248 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:04:24 PDT] Started with 248 files, current size is 248files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:04:24 PDT] Dataset size is 248 files
----------------------------------------------------
validating dataset ....passed
Writting process 6A88EEA913730D51C786AB714E050C6A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6A88EEA913730D51C786AB714E050C6A_2... done.
Writting process 6A88EEA913730D51C786AB714E050C6A_1... done.
Writting process 6A88EEA913730D51C786AB714E050C6A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6A88EEA913730D51C786AB714E050C6A.report
Scheduling successful
submit!!!
Job submission for day 143 finished!
144
jobs = 86
day = 144 run = 15144005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144005/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:05:35 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 15:05:35 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:05:35 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:05:35 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:05:35 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 889A39DD59F1BEC1B33B75E2521AA88D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 889A39DD59F1BEC1B33B75E2521AA88D_1... done.
Writting process 889A39DD59F1BEC1B33B75E2521AA88D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched889A39DD59F1BEC1B33B75E2521AA88D.report
Scheduling successful
submit!!!
jobs = 84
day = 144 run = 15144006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144006/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:06:47 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 15:06:47 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:06:47 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:06:47 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:06:47 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process FB83C9C949535F435FA317F2AD815A19_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FB83C9C949535F435FA317F2AD815A19_1... done.
Writting process FB83C9C949535F435FA317F2AD815A19_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFB83C9C949535F435FA317F2AD815A19.report
Scheduling successful
submit!!!
jobs = 84
day = 144 run = 15144007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144007/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:07:59 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 15:07:59 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:07:59 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:07:59 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:07:59 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process A6A4AD727D4AA35D54D8ADFDBECD45E7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A6A4AD727D4AA35D54D8ADFDBECD45E7_1... done.
Writting process A6A4AD727D4AA35D54D8ADFDBECD45E7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA6A4AD727D4AA35D54D8ADFDBECD45E7.report
Scheduling successful
submit!!!
jobs = 86
day = 144 run = 15144008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144008/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:09:11 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 15:09:11 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:09:11 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:09:11 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:09:11 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 7B64B420C105DCBAE2AD220D7D0BA027_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7B64B420C105DCBAE2AD220D7D0BA027_1... done.
Writting process 7B64B420C105DCBAE2AD220D7D0BA027_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7B64B420C105DCBAE2AD220D7D0BA027.report
Scheduling successful
submit!!!
jobs = 86
day = 144 run = 15144009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144009/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:10:23 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 15:10:23 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:10:23 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:10:23 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:10:23 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process 156FCE9453B78C8691C069DFA9E8C452_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 156FCE9453B78C8691C069DFA9E8C452_1... done.
Writting process 156FCE9453B78C8691C069DFA9E8C452_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched156FCE9453B78C8691C069DFA9E8C452.report
Scheduling successful
submit!!!
jobs = 89
day = 144 run = 15144010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144010/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:11:34 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 15:11:34 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:11:34 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:11:35 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:11:35 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 3798859C6BA8E4BAC8B0C5E01DACD8B6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3798859C6BA8E4BAC8B0C5E01DACD8B6_1... done.
Writting process 3798859C6BA8E4BAC8B0C5E01DACD8B6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3798859C6BA8E4BAC8B0C5E01DACD8B6.report
Scheduling successful
submit!!!
jobs = 88
day = 144 run = 15144011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144011/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:12:46 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 15:12:46 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:12:46 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:12:46 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:12:46 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 62250E527658C641DF924E97760681F7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 62250E527658C641DF924E97760681F7_1... done.
Writting process 62250E527658C641DF924E97760681F7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched62250E527658C641DF924E97760681F7.report
Scheduling successful
submit!!!
jobs = 88
day = 144 run = 15144012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144012/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:13:58 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 15:13:58 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:13:58 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:13:58 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:13:58 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process F18528F252D13976029685B50D1ABC82_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F18528F252D13976029685B50D1ABC82_1... done.
Writting process F18528F252D13976029685B50D1ABC82_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF18528F252D13976029685B50D1ABC82.report
Scheduling successful
submit!!!
jobs = 87
day = 144 run = 15144013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144013/*.root.log: No such file or directory
218
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:15:11 PDT] Dataset size is 218 files
Removing files not on site LBL
[2017.09.05 15:15:11 PDT] Dataset size is 218 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:15:11 PDT] Dataset size is 218 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:15:11 PDT] Started with 218 files, current size is 218files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:15:11 PDT] Dataset size is 218 files
----------------------------------------------------
validating dataset ....passed
Writting process 9FC070DCAC415E161E51B96DA987DA78_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9FC070DCAC415E161E51B96DA987DA78_2... done.
Writting process 9FC070DCAC415E161E51B96DA987DA78_1... done.
Writting process 9FC070DCAC415E161E51B96DA987DA78_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9FC070DCAC415E161E51B96DA987DA78.report
Scheduling successful
submit!!!
jobs = 89
day = 144 run = 15144014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144014/*.root.log: No such file or directory
207
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:16:23 PDT] Dataset size is 207 files
Removing files not on site LBL
[2017.09.05 15:16:23 PDT] Dataset size is 207 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:16:23 PDT] Dataset size is 207 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:16:24 PDT] Started with 207 files, current size is 207files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:16:24 PDT] Dataset size is 207 files
----------------------------------------------------
validating dataset ....passed
Writting process 8382C8B84F40AB20D027744CD30B00BA_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8382C8B84F40AB20D027744CD30B00BA_2... done.
Writting process 8382C8B84F40AB20D027744CD30B00BA_1... done.
Writting process 8382C8B84F40AB20D027744CD30B00BA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8382C8B84F40AB20D027744CD30B00BA.report
Scheduling successful
submit!!!
jobs = 92
day = 144 run = 15144015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144015/*.root.log: No such file or directory
200
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:17:36 PDT] Dataset size is 200 files
Removing files not on site LBL
[2017.09.05 15:17:36 PDT] Dataset size is 200 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:17:36 PDT] Dataset size is 200 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:17:36 PDT] Started with 200 files, current size is 200files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:17:36 PDT] Dataset size is 200 files
----------------------------------------------------
validating dataset ....passed
Writting process 883416F16C503D6B207FB11CE85E2545_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 883416F16C503D6B207FB11CE85E2545_2... done.
Writting process 883416F16C503D6B207FB11CE85E2545_1... done.
Writting process 883416F16C503D6B207FB11CE85E2545_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched883416F16C503D6B207FB11CE85E2545.report
Scheduling successful
submit!!!
jobs = 96
day = 144 run = 15144017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144017/*.root.log: No such file or directory
145
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:18:46 PDT] Dataset size is 145 files
Removing files not on site LBL
[2017.09.05 15:18:46 PDT] Dataset size is 145 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:18:46 PDT] Dataset size is 145 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:18:47 PDT] Started with 145 files, current size is 145files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:18:47 PDT] Dataset size is 145 files
----------------------------------------------------
validating dataset ....passed
Writting process D1E5F4F401CE31E656006F383FD7436B_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D1E5F4F401CE31E656006F383FD7436B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD1E5F4F401CE31E656006F383FD7436B.report
Scheduling successful
submit!!!
jobs = 96
day = 144 run = 15144018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144018/*.root.log: No such file or directory
74
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:19:55 PDT] Dataset size is 74 files
Removing files not on site LBL
[2017.09.05 15:19:55 PDT] Dataset size is 74 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:19:55 PDT] Dataset size is 74 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:19:55 PDT] Started with 74 files, current size is 74files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:19:55 PDT] Dataset size is 74 files
----------------------------------------------------
validating dataset ....passed
Writting process F64D100F44197900938006ECFFB7C563_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF64D100F44197900938006ECFFB7C563.report
Scheduling successful
submit!!!
jobs = 95
day = 144 run = 15144039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144039/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:21:06 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 15:21:06 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:21:06 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:21:06 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:21:06 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 5368ADEF3D32F16114D826DD50011E9C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5368ADEF3D32F16114D826DD50011E9C_1... done.
Writting process 5368ADEF3D32F16114D826DD50011E9C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5368ADEF3D32F16114D826DD50011E9C.report
Scheduling successful
submit!!!
jobs = 95
day = 144 run = 15144040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144040/*.root.log: No such file or directory
134
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:22:16 PDT] Dataset size is 134 files
Removing files not on site LBL
[2017.09.05 15:22:16 PDT] Dataset size is 134 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:22:16 PDT] Dataset size is 134 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:22:17 PDT] Started with 134 files, current size is 134files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:22:17 PDT] Dataset size is 134 files
----------------------------------------------------
validating dataset ....passed
Writting process E756868A1FAA3603160F2D6763893A7E_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E756868A1FAA3603160F2D6763893A7E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE756868A1FAA3603160F2D6763893A7E.report
Scheduling successful
submit!!!
jobs = 95
day = 144 run = 15144043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144043/*.root.log: No such file or directory
154
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:23:28 PDT] Dataset size is 154 files
Removing files not on site LBL
[2017.09.05 15:23:28 PDT] Dataset size is 154 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:23:28 PDT] Dataset size is 154 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:23:28 PDT] Started with 154 files, current size is 154files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:23:28 PDT] Dataset size is 154 files
----------------------------------------------------
validating dataset ....passed
Writting process 1F944B27407855ADB3A7EBD249F5CD42_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1F944B27407855ADB3A7EBD249F5CD42_1... done.
Writting process 1F944B27407855ADB3A7EBD249F5CD42_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1F944B27407855ADB3A7EBD249F5CD42.report
Scheduling successful
submit!!!
jobs = 95
day = 144 run = 15144044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144044/*.root.log: No such file or directory
155
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:24:44 PDT] Dataset size is 155 files
Removing files not on site LBL
[2017.09.05 15:24:44 PDT] Dataset size is 155 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:24:44 PDT] Dataset size is 155 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:24:44 PDT] Started with 155 files, current size is 155files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:24:44 PDT] Dataset size is 155 files
----------------------------------------------------
validating dataset ....passed
Writting process F904820DB9BEC600845FF23BC8AA339E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F904820DB9BEC600845FF23BC8AA339E_1... done.
Writting process F904820DB9BEC600845FF23BC8AA339E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF904820DB9BEC600845FF23BC8AA339E.report
Scheduling successful
submit!!!
jobs = 95
day = 144 run = 15144046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144046/*.root.log: No such file or directory
149
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:26:02 PDT] Dataset size is 149 files
Removing files not on site LBL
[2017.09.05 15:26:06 PDT] Dataset size is 149 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:26:08 PDT] Dataset size is 149 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:26:10 PDT] Started with 149 files, current size is 149files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:26:10 PDT] Dataset size is 149 files
----------------------------------------------------
validating dataset ....passed
Writting process B1EBCF115FC1DAB924BCD9D9726B18FF_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B1EBCF115FC1DAB924BCD9D9726B18FF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB1EBCF115FC1DAB924BCD9D9726B18FF.report
Scheduling successful
submit!!!
jobs = 91
day = 144 run = 15144047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144047/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:27:23 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 15:27:24 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:27:24 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:27:26 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:27:27 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 0C9F3AFA0A0F52E103B134E4A53C79BF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0C9F3AFA0A0F52E103B134E4A53C79BF_1... done.
Writting process 0C9F3AFA0A0F52E103B134E4A53C79BF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0C9F3AFA0A0F52E103B134E4A53C79BF.report
Scheduling successful
submit!!!
jobs = 89
day = 144 run = 15144049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144049/*.root.log: No such file or directory
227
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:28:42 PDT] Dataset size is 227 files
Removing files not on site LBL
[2017.09.05 15:28:45 PDT] Dataset size is 227 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:28:47 PDT] Dataset size is 227 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:28:50 PDT] Started with 227 files, current size is 227files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:28:50 PDT] Dataset size is 227 files
----------------------------------------------------
validating dataset ....passed
Writting process E8C9173849C4BF380AEB0E2DF780D4D9_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E8C9173849C4BF380AEB0E2DF780D4D9_2... done.
Writting process E8C9173849C4BF380AEB0E2DF780D4D9_1... done.
Writting process E8C9173849C4BF380AEB0E2DF780D4D9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE8C9173849C4BF380AEB0E2DF780D4D9.report
Scheduling successful
submit!!!
jobs = 93
day = 144 run = 15144052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144052/*.root.log: No such file or directory
217
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:30:09 PDT] Dataset size is 217 files
Removing files not on site LBL
[2017.09.05 15:30:10 PDT] Dataset size is 217 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:30:10 PDT] Dataset size is 217 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:30:10 PDT] Started with 217 files, current size is 217files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:30:10 PDT] Dataset size is 217 files
----------------------------------------------------
validating dataset ....passed
Writting process 37274293196C8A583C468E3BCCDA864A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 37274293196C8A583C468E3BCCDA864A_2... done.
Writting process 37274293196C8A583C468E3BCCDA864A_1... done.
Writting process 37274293196C8A583C468E3BCCDA864A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched37274293196C8A583C468E3BCCDA864A.report
Scheduling successful
submit!!!
jobs = 94
day = 144 run = 15144054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144054/*.root.log: No such file or directory
278
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:31:31 PDT] Dataset size is 278 files
Removing files not on site LBL
[2017.09.05 15:31:31 PDT] Dataset size is 278 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:31:31 PDT] Dataset size is 278 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:31:31 PDT] Started with 278 files, current size is 278files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:31:31 PDT] Dataset size is 278 files
----------------------------------------------------
validating dataset ....passed
Writting process 746AD3BE5CC6DD2CAC374BA3E88EA590_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 746AD3BE5CC6DD2CAC374BA3E88EA590_3... done.
Writting process 746AD3BE5CC6DD2CAC374BA3E88EA590_2... done.
Writting process 746AD3BE5CC6DD2CAC374BA3E88EA590_1... done.
Writting process 746AD3BE5CC6DD2CAC374BA3E88EA590_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched746AD3BE5CC6DD2CAC374BA3E88EA590.report
Scheduling successful
submit!!!
jobs = 97
day = 144 run = 15144056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144056/*.root.log: No such file or directory
107
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:32:42 PDT] Dataset size is 107 files
Removing files not on site LBL
[2017.09.05 15:32:42 PDT] Dataset size is 107 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:32:42 PDT] Dataset size is 107 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:32:42 PDT] Started with 107 files, current size is 107files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:32:42 PDT] Dataset size is 107 files
----------------------------------------------------
validating dataset ....passed
Writting process E678D1A56A4E09EE1721B9803C290F00_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E678D1A56A4E09EE1721B9803C290F00_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE678D1A56A4E09EE1721B9803C290F00.report
Scheduling successful
submit!!!
jobs = 95
day = 144 run = 15144058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144058/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:33:53 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 15:33:53 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:33:53 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:33:53 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:33:53 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 8B76D8C63B1DF14B9F0CAD8ACBF0E057_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8B76D8C63B1DF14B9F0CAD8ACBF0E057_1... done.
Writting process 8B76D8C63B1DF14B9F0CAD8ACBF0E057_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8B76D8C63B1DF14B9F0CAD8ACBF0E057.report
Scheduling successful
submit!!!
jobs = 96
day = 144 run = 15144060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144060/*.root.log: No such file or directory
127
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:35:06 PDT] Dataset size is 127 files
Removing files not on site LBL
[2017.09.05 15:35:06 PDT] Dataset size is 127 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:35:06 PDT] Dataset size is 127 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:35:06 PDT] Started with 127 files, current size is 127files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:35:06 PDT] Dataset size is 127 files
----------------------------------------------------
validating dataset ....passed
Writting process C34CE9265F2016686F47EB2C4DD95F12_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C34CE9265F2016686F47EB2C4DD95F12_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC34CE9265F2016686F47EB2C4DD95F12.report
Scheduling successful
submit!!!
jobs = 96
day = 144 run = 15144070
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15144070/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15144070/*.root.log: No such file or directory
153
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:36:17 PDT] Dataset size is 153 files
Removing files not on site LBL
[2017.09.05 15:36:17 PDT] Dataset size is 153 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:36:17 PDT] Dataset size is 153 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:36:17 PDT] Started with 153 files, current size is 153files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:36:17 PDT] Dataset size is 153 files
----------------------------------------------------
validating dataset ....passed
Writting process ED33B01F453A4A99300A619285471F2F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ED33B01F453A4A99300A619285471F2F_1... done.
Writting process ED33B01F453A4A99300A619285471F2F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedED33B01F453A4A99300A619285471F2F.report
Scheduling successful
submit!!!
Job submission for day 144 finished!
145
jobs = 96
day = 145 run = 15145009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145009/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:37:36 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.05 15:37:36 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:37:36 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:37:36 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:37:36 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process 6C5D836B9FF833EA7BC2ED2AC027114F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6C5D836B9FF833EA7BC2ED2AC027114F_1... done.
Writting process 6C5D836B9FF833EA7BC2ED2AC027114F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6C5D836B9FF833EA7BC2ED2AC027114F.report
Scheduling successful
submit!!!
jobs = 94
day = 145 run = 15145010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145010/*.root.log: No such file or directory
143
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:38:47 PDT] Dataset size is 143 files
Removing files not on site LBL
[2017.09.05 15:38:47 PDT] Dataset size is 143 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:38:47 PDT] Dataset size is 143 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:38:47 PDT] Started with 143 files, current size is 143files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:38:47 PDT] Dataset size is 143 files
----------------------------------------------------
validating dataset ....passed
Writting process 9149BDDD4B1D0C62DEFA38582A2CA4F4_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9149BDDD4B1D0C62DEFA38582A2CA4F4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9149BDDD4B1D0C62DEFA38582A2CA4F4.report
Scheduling successful
submit!!!
jobs = 94
day = 145 run = 15145013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145013/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:39:58 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 15:39:58 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:39:58 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:39:58 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:39:58 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 9671BCE033B491401E8E3FDCEE6F07F2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9671BCE033B491401E8E3FDCEE6F07F2_1... done.
Writting process 9671BCE033B491401E8E3FDCEE6F07F2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9671BCE033B491401E8E3FDCEE6F07F2.report
Scheduling successful
submit!!!
jobs = 94
day = 145 run = 15145014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145014/*.root.log: No such file or directory
139
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:41:29 PDT] Dataset size is 139 files
Removing files not on site LBL
[2017.09.05 15:41:29 PDT] Dataset size is 139 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:41:29 PDT] Dataset size is 139 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:41:29 PDT] Started with 139 files, current size is 139files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:41:29 PDT] Dataset size is 139 files
----------------------------------------------------
validating dataset ....passed
Writting process 37CCFA8D91F29CC271A2BEC6387AC8E1_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 37CCFA8D91F29CC271A2BEC6387AC8E1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched37CCFA8D91F29CC271A2BEC6387AC8E1.report
Scheduling successful
submit!!!
jobs = 92
day = 145 run = 15145015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145015/*.root.log: No such file or directory
43
43 43
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:42:36 PDT] Dataset size is 43 files
Removing files not on site LBL
[2017.09.05 15:42:37 PDT] Dataset size is 43 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:42:37 PDT] Dataset size is 43 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:42:37 PDT] Started with 43 files, current size is 43files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=43 ,maxSize=43 )
[2017.09.05 15:42:37 PDT] Dataset size is 43 files
----------------------------------------------------
validating dataset ....passed
Writting process BB04F2827AFE549BE518B795521EDCE7_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBB04F2827AFE549BE518B795521EDCE7.report
Scheduling successful
submit!!!
jobs = 90
day = 145 run = 15145016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145016/*.root.log: No such file or directory
72
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:43:45 PDT] Dataset size is 72 files
Removing files not on site LBL
[2017.09.05 15:43:45 PDT] Dataset size is 72 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:43:45 PDT] Dataset size is 72 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:43:45 PDT] Started with 72 files, current size is 72files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:43:45 PDT] Dataset size is 72 files
----------------------------------------------------
validating dataset ....passed
Writting process 506E17F8979955850D86E9597A51B897_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched506E17F8979955850D86E9597A51B897.report
Scheduling successful
submit!!!
jobs = 88
day = 145 run = 15145017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145017/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:45:01 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 15:45:01 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:45:01 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:45:01 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:45:01 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process EA8028272EB99C3A48913360E4BB803F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EA8028272EB99C3A48913360E4BB803F_1... done.
Writting process EA8028272EB99C3A48913360E4BB803F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEA8028272EB99C3A48913360E4BB803F.report
Scheduling successful
submit!!!
jobs = 91
day = 145 run = 15145018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145018/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:46:13 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 15:46:13 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:46:13 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:46:13 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:46:13 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 16F1C34C378A537727AF351A8B585F74_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 16F1C34C378A537727AF351A8B585F74_1... done.
Writting process 16F1C34C378A537727AF351A8B585F74_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched16F1C34C378A537727AF351A8B585F74.report
Scheduling successful
submit!!!
jobs = 91
day = 145 run = 15145019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145019/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:47:25 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 15:47:25 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:47:25 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:47:25 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:47:25 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 767C8CAE5B990C6089FD8AE9CA18BD09_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 767C8CAE5B990C6089FD8AE9CA18BD09_1... done.
Writting process 767C8CAE5B990C6089FD8AE9CA18BD09_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched767C8CAE5B990C6089FD8AE9CA18BD09.report
Scheduling successful
submit!!!
jobs = 91
day = 145 run = 15145020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145020/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:48:37 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 15:48:37 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:48:37 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:48:37 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:48:37 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process 67A1D957F407F3BD9D1AD8B7FEDEC646_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 67A1D957F407F3BD9D1AD8B7FEDEC646_1... done.
Writting process 67A1D957F407F3BD9D1AD8B7FEDEC646_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched67A1D957F407F3BD9D1AD8B7FEDEC646.report
Scheduling successful
submit!!!
jobs = 89
day = 145 run = 15145021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145021/*.root.log: No such file or directory
9
9 9
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:49:43 PDT] Dataset size is 9 files
Removing files not on site LBL
[2017.09.05 15:49:43 PDT] Dataset size is 9 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:49:43 PDT] Dataset size is 9 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:49:43 PDT] Started with 9 files, current size is 9files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=9 ,maxSize=9 )
[2017.09.05 15:49:43 PDT] Dataset size is 9 files
----------------------------------------------------
validating dataset ....passed
Writting process 173BA4AD925A035E30F1CF9E1110F0DA_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched173BA4AD925A035E30F1CF9E1110F0DA.report
Scheduling successful
submit!!!
jobs = 89
day = 145 run = 15145022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145022/*.root.log: No such file or directory
235
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:50:56 PDT] Dataset size is 235 files
Removing files not on site LBL
[2017.09.05 15:50:56 PDT] Dataset size is 235 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:50:56 PDT] Dataset size is 235 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:50:56 PDT] Started with 235 files, current size is 235files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:50:56 PDT] Dataset size is 235 files
----------------------------------------------------
validating dataset ....passed
Writting process 71CBAC0063CAC84EA81C0C0418934FE8_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 71CBAC0063CAC84EA81C0C0418934FE8_2... done.
Writting process 71CBAC0063CAC84EA81C0C0418934FE8_1... done.
Writting process 71CBAC0063CAC84EA81C0C0418934FE8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched71CBAC0063CAC84EA81C0C0418934FE8.report
Scheduling successful
submit!!!
jobs = 83
day = 145 run = 15145023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145023/*.root.log: No such file or directory
218
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:52:09 PDT] Dataset size is 218 files
Removing files not on site LBL
[2017.09.05 15:52:09 PDT] Dataset size is 218 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:52:09 PDT] Dataset size is 218 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:52:09 PDT] Started with 218 files, current size is 218files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:52:09 PDT] Dataset size is 218 files
----------------------------------------------------
validating dataset ....passed
Writting process BB72C4215276E87B24AE982A5428BB9B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BB72C4215276E87B24AE982A5428BB9B_2... done.
Writting process BB72C4215276E87B24AE982A5428BB9B_1... done.
Writting process BB72C4215276E87B24AE982A5428BB9B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBB72C4215276E87B24AE982A5428BB9B.report
Scheduling successful
submit!!!
jobs = 82
day = 145 run = 15145024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145024/*.root.log: No such file or directory
228
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:53:23 PDT] Dataset size is 228 files
Removing files not on site LBL
[2017.09.05 15:53:26 PDT] Dataset size is 228 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:53:27 PDT] Dataset size is 228 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:53:27 PDT] Started with 228 files, current size is 228files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:53:27 PDT] Dataset size is 228 files
----------------------------------------------------
validating dataset ....passed
Writting process 91457AFCF44A19EE507A924DA0E4F476_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 91457AFCF44A19EE507A924DA0E4F476_2... done.
Writting process 91457AFCF44A19EE507A924DA0E4F476_1... done.
Writting process 91457AFCF44A19EE507A924DA0E4F476_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched91457AFCF44A19EE507A924DA0E4F476.report
Scheduling successful
submit!!!
jobs = 83
day = 145 run = 15145037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145037/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:54:38 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 15:54:38 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:54:38 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:54:39 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:54:39 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process B4B74F8A18DDF2B70BAB745E9AE38354_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B4B74F8A18DDF2B70BAB745E9AE38354_1... done.
Writting process B4B74F8A18DDF2B70BAB745E9AE38354_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB4B74F8A18DDF2B70BAB745E9AE38354.report
Scheduling successful
submit!!!
jobs = 83
day = 145 run = 15145038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15145038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15145038/*.root.log: No such file or directory
128
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:55:48 PDT] Dataset size is 128 files
Removing files not on site LBL
[2017.09.05 15:55:48 PDT] Dataset size is 128 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:55:48 PDT] Dataset size is 128 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:55:49 PDT] Started with 128 files, current size is 128files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:55:49 PDT] Dataset size is 128 files
----------------------------------------------------
validating dataset ....passed
Writting process 4A16618C6F9C19DC3D4DF3C377876625_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4A16618C6F9C19DC3D4DF3C377876625_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4A16618C6F9C19DC3D4DF3C377876625.report
Scheduling successful
submit!!!
Job submission for day 145 finished!
146
jobs = 81
day = 146 run = 15146001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146001/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:56:59 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 15:57:00 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:57:00 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:57:00 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:57:00 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process 44CFB40C51355A0E8FD7789566DF21DF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 44CFB40C51355A0E8FD7789566DF21DF_1... done.
Writting process 44CFB40C51355A0E8FD7789566DF21DF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched44CFB40C51355A0E8FD7789566DF21DF.report
Scheduling successful
submit!!!
jobs = 81
day = 146 run = 15146002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146002/*.root.log: No such file or directory
161
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:58:11 PDT] Dataset size is 161 files
Removing files not on site LBL
[2017.09.05 15:58:11 PDT] Dataset size is 161 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:58:11 PDT] Dataset size is 161 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:58:11 PDT] Started with 161 files, current size is 161files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 15:58:11 PDT] Dataset size is 161 files
----------------------------------------------------
validating dataset ....passed
Writting process 968ECD5E3D9F2B87D9DB80E9DD4F6DC9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 968ECD5E3D9F2B87D9DB80E9DD4F6DC9_1... done.
Writting process 968ECD5E3D9F2B87D9DB80E9DD4F6DC9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched968ECD5E3D9F2B87D9DB80E9DD4F6DC9.report
Scheduling successful
submit!!!
jobs = 79
day = 146 run = 15146003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146003/*.root.log: No such file or directory
21
21 21
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 15:59:17 PDT] Dataset size is 21 files
Removing files not on site LBL
[2017.09.05 15:59:17 PDT] Dataset size is 21 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 15:59:17 PDT] Dataset size is 21 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 15:59:18 PDT] Started with 21 files, current size is 21files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=21 ,maxSize=21 )
[2017.09.05 15:59:18 PDT] Dataset size is 21 files
----------------------------------------------------
validating dataset ....passed
Writting process ACC24EF661EF8AFDE7F7CD96B9367BB4_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedACC24EF661EF8AFDE7F7CD96B9367BB4.report
Scheduling successful
submit!!!
jobs = 80
day = 146 run = 15146004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146004/*.root.log: No such file or directory
82
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:00:27 PDT] Dataset size is 82 files
Removing files not on site LBL
[2017.09.05 16:00:27 PDT] Dataset size is 82 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:00:27 PDT] Dataset size is 82 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:00:27 PDT] Started with 82 files, current size is 82files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:00:27 PDT] Dataset size is 82 files
----------------------------------------------------
validating dataset ....passed
Writting process 37A9AC6F6E83D00208007996EEB499DF_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched37A9AC6F6E83D00208007996EEB499DF.report
Scheduling successful
submit!!!
jobs = 79
day = 146 run = 15146006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146006/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:01:39 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 16:01:39 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:01:39 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:01:39 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:01:39 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process F195A168588B61D63EF57DB8CE429378_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F195A168588B61D63EF57DB8CE429378_1... done.
Writting process F195A168588B61D63EF57DB8CE429378_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF195A168588B61D63EF57DB8CE429378.report
Scheduling successful
submit!!!
jobs = 79
day = 146 run = 15146008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146008/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:02:50 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 16:02:50 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:02:50 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:02:50 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:02:51 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 679B46179FA49C9104A2699088B7B4BF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 679B46179FA49C9104A2699088B7B4BF_1... done.
Writting process 679B46179FA49C9104A2699088B7B4BF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched679B46179FA49C9104A2699088B7B4BF.report
Scheduling successful
submit!!!
jobs = 80
day = 146 run = 15146009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146009/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:04:02 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 16:04:02 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:04:02 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:04:02 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:04:02 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process 62D9F20D3951877DCD79F52B830AC39A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 62D9F20D3951877DCD79F52B830AC39A_1... done.
Writting process 62D9F20D3951877DCD79F52B830AC39A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched62D9F20D3951877DCD79F52B830AC39A.report
Scheduling successful
submit!!!
jobs = 79
day = 146 run = 15146010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146010/*.root.log: No such file or directory
53
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:05:09 PDT] Dataset size is 53 files
Removing files not on site LBL
[2017.09.05 16:05:09 PDT] Dataset size is 53 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:05:10 PDT] Dataset size is 53 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:05:10 PDT] Started with 53 files, current size is 53files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:05:10 PDT] Dataset size is 53 files
----------------------------------------------------
validating dataset ....passed
Writting process 82D6B2A4C7E6718C064BF6F29010B184_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched82D6B2A4C7E6718C064BF6F29010B184.report
Scheduling successful
submit!!!
jobs = 78
day = 146 run = 15146013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146013/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:06:21 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 16:06:21 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:06:21 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:06:22 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:06:22 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 15526CA953048E1C45835F337D9B8CF9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 15526CA953048E1C45835F337D9B8CF9_1... done.
Writting process 15526CA953048E1C45835F337D9B8CF9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched15526CA953048E1C45835F337D9B8CF9.report
Scheduling successful
submit!!!
jobs = 80
day = 146 run = 15146017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146017/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:07:37 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 16:07:37 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:07:37 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:07:38 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:07:38 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process 71EEA1BD7DC5F07DED1F7A8ECDF4ADC7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 71EEA1BD7DC5F07DED1F7A8ECDF4ADC7_1... done.
Writting process 71EEA1BD7DC5F07DED1F7A8ECDF4ADC7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched71EEA1BD7DC5F07DED1F7A8ECDF4ADC7.report
Scheduling successful
submit!!!
jobs = 82
day = 146 run = 15146020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146020/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:09:01 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 16:09:03 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:09:05 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:09:08 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:09:08 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process 81AA7B5FDC7462C7AF175BC7E0BD2847_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 81AA7B5FDC7462C7AF175BC7E0BD2847_1... done.
Writting process 81AA7B5FDC7462C7AF175BC7E0BD2847_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched81AA7B5FDC7462C7AF175BC7E0BD2847.report
Scheduling successful
submit!!!
jobs = 84
day = 146 run = 15146023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146023/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:10:32 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 16:10:33 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:10:33 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:10:34 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:10:35 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process 3188379F95EEB98CF564CDD781AE4085_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3188379F95EEB98CF564CDD781AE4085_1... done.
Writting process 3188379F95EEB98CF564CDD781AE4085_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3188379F95EEB98CF564CDD781AE4085.report
Scheduling successful
submit!!!
jobs = 85
day = 146 run = 15146025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146025/*.root.log: No such file or directory
197
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:11:56 PDT] Dataset size is 197 files
Removing files not on site LBL
[2017.09.05 16:11:57 PDT] Dataset size is 197 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:11:57 PDT] Dataset size is 197 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:12:00 PDT] Started with 197 files, current size is 197files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:12:00 PDT] Dataset size is 197 files
----------------------------------------------------
validating dataset ....passed
Writting process F66DEB6F3D7CD778DB69E3A89E5CF79E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F66DEB6F3D7CD778DB69E3A89E5CF79E_1... done.
Writting process F66DEB6F3D7CD778DB69E3A89E5CF79E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF66DEB6F3D7CD778DB69E3A89E5CF79E.report
Scheduling successful
submit!!!
jobs = 81
day = 146 run = 15146026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146026/*.root.log: No such file or directory
32
32 32
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:13:11 PDT] Dataset size is 32 files
Removing files not on site LBL
[2017.09.05 16:13:12 PDT] Dataset size is 32 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:13:13 PDT] Dataset size is 32 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:13:15 PDT] Started with 32 files, current size is 32files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=32 ,maxSize=32 )
[2017.09.05 16:13:16 PDT] Dataset size is 32 files
----------------------------------------------------
validating dataset ....passed
Writting process 17787397AF6777B948B06A29AB3B9027_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched17787397AF6777B948B06A29AB3B9027.report
Scheduling successful
submit!!!
jobs = 74
day = 146 run = 15146049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146049/*.root.log: No such file or directory
98
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:14:30 PDT] Dataset size is 98 files
Removing files not on site LBL
[2017.09.05 16:14:31 PDT] Dataset size is 98 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:14:31 PDT] Dataset size is 98 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:14:32 PDT] Started with 98 files, current size is 98files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:14:32 PDT] Dataset size is 98 files
----------------------------------------------------
validating dataset ....passed
Writting process C0ED618FD7547CA93A263DF55AB4A75C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC0ED618FD7547CA93A263DF55AB4A75C.report
Scheduling successful
submit!!!
jobs = 74
day = 146 run = 15146050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146050/*.root.log: No such file or directory
134
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:15:45 PDT] Dataset size is 134 files
Removing files not on site LBL
[2017.09.05 16:15:46 PDT] Dataset size is 134 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:15:47 PDT] Dataset size is 134 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:15:49 PDT] Started with 134 files, current size is 134files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:15:50 PDT] Dataset size is 134 files
----------------------------------------------------
validating dataset ....passed
Writting process 7BA756F15EA4B7DDA12B9FAF13A8BC9F_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7BA756F15EA4B7DDA12B9FAF13A8BC9F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7BA756F15EA4B7DDA12B9FAF13A8BC9F.report
Scheduling successful
submit!!!
jobs = 72
day = 146 run = 15146051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146051/*.root.log: No such file or directory
141
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:17:08 PDT] Dataset size is 141 files
Removing files not on site LBL
[2017.09.05 16:17:08 PDT] Dataset size is 141 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:17:08 PDT] Dataset size is 141 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:17:11 PDT] Started with 141 files, current size is 141files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:17:14 PDT] Dataset size is 141 files
----------------------------------------------------
validating dataset ....passed
Writting process AF7AD58A8FED73C52210A6A59D1ED95F_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AF7AD58A8FED73C52210A6A59D1ED95F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAF7AD58A8FED73C52210A6A59D1ED95F.report
Scheduling successful
submit!!!
jobs = 72
day = 146 run = 15146052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146052/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:18:30 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 16:18:31 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:18:31 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:18:32 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:18:32 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 0A3CC4830062C1F17309D67814F19E28_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0A3CC4830062C1F17309D67814F19E28_1... done.
Writting process 0A3CC4830062C1F17309D67814F19E28_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0A3CC4830062C1F17309D67814F19E28.report
Scheduling successful
submit!!!
jobs = 71
day = 146 run = 15146054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146054/*.root.log: No such file or directory
63
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:19:41 PDT] Dataset size is 63 files
Removing files not on site LBL
[2017.09.05 16:19:41 PDT] Dataset size is 63 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:19:41 PDT] Dataset size is 63 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:19:41 PDT] Started with 63 files, current size is 63files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:19:41 PDT] Dataset size is 63 files
----------------------------------------------------
validating dataset ....passed
Writting process 7056BA55CC4322B83BAA84DD3680F322_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7056BA55CC4322B83BAA84DD3680F322.report
Scheduling successful
submit!!!
jobs = 71
day = 146 run = 15146055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146055/*.root.log: No such file or directory
231
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:20:56 PDT] Dataset size is 231 files
Removing files not on site LBL
[2017.09.05 16:20:56 PDT] Dataset size is 231 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:20:56 PDT] Dataset size is 231 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:20:56 PDT] Started with 231 files, current size is 231files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:20:56 PDT] Dataset size is 231 files
----------------------------------------------------
validating dataset ....passed
Writting process 7663C815EEB7A10CC13E3E4C3D686BA1_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7663C815EEB7A10CC13E3E4C3D686BA1_2... done.
Writting process 7663C815EEB7A10CC13E3E4C3D686BA1_1... done.
Writting process 7663C815EEB7A10CC13E3E4C3D686BA1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7663C815EEB7A10CC13E3E4C3D686BA1.report
Scheduling successful
submit!!!
jobs = 73
day = 146 run = 15146057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146057/*.root.log: No such file or directory
223
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:22:10 PDT] Dataset size is 223 files
Removing files not on site LBL
[2017.09.05 16:22:11 PDT] Dataset size is 223 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:22:12 PDT] Dataset size is 223 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:22:12 PDT] Started with 223 files, current size is 223files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:22:12 PDT] Dataset size is 223 files
----------------------------------------------------
validating dataset ....passed
Writting process B61238F2C706200D2278381354E501CB_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B61238F2C706200D2278381354E501CB_2... done.
Writting process B61238F2C706200D2278381354E501CB_1... done.
Writting process B61238F2C706200D2278381354E501CB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB61238F2C706200D2278381354E501CB.report
Scheduling successful
submit!!!
jobs = 75
day = 146 run = 15146058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146058/*.root.log: No such file or directory
115
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:23:22 PDT] Dataset size is 115 files
Removing files not on site LBL
[2017.09.05 16:23:23 PDT] Dataset size is 115 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:23:23 PDT] Dataset size is 115 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:23:23 PDT] Started with 115 files, current size is 115files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:23:23 PDT] Dataset size is 115 files
----------------------------------------------------
validating dataset ....passed
Writting process 657F6C2762A32C7A3180C21578106B67_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 657F6C2762A32C7A3180C21578106B67_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched657F6C2762A32C7A3180C21578106B67.report
Scheduling successful
submit!!!
jobs = 77
day = 146 run = 15146059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146059/*.root.log: No such file or directory
223
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:24:36 PDT] Dataset size is 223 files
Removing files not on site LBL
[2017.09.05 16:24:36 PDT] Dataset size is 223 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:24:36 PDT] Dataset size is 223 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:24:46 PDT] Started with 223 files, current size is 223files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:24:49 PDT] Dataset size is 223 files
----------------------------------------------------
validating dataset ....passed
Writting process DF415120F26B9E1E9D1B299BD65D47AD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DF415120F26B9E1E9D1B299BD65D47AD_2... done.
Writting process DF415120F26B9E1E9D1B299BD65D47AD_1... done.
Writting process DF415120F26B9E1E9D1B299BD65D47AD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDF415120F26B9E1E9D1B299BD65D47AD.report
Scheduling successful
submit!!!
jobs = 80
day = 146 run = 15146060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146060/*.root.log: No such file or directory
245
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:26:08 PDT] Dataset size is 245 files
Removing files not on site LBL
[2017.09.05 16:26:09 PDT] Dataset size is 245 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:26:09 PDT] Dataset size is 245 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:26:09 PDT] Started with 245 files, current size is 245files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:26:09 PDT] Dataset size is 245 files
----------------------------------------------------
validating dataset ....passed
Writting process 01C66438762846B50E38DE00EF7941C6_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 01C66438762846B50E38DE00EF7941C6_2... done.
Writting process 01C66438762846B50E38DE00EF7941C6_1... done.
Writting process 01C66438762846B50E38DE00EF7941C6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched01C66438762846B50E38DE00EF7941C6.report
Scheduling successful
submit!!!
jobs = 79
day = 146 run = 15146061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146061/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:27:21 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 16:27:21 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:27:21 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:27:21 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:27:21 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process 66BD0946C509313DFB379466D7F65FEC_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 66BD0946C509313DFB379466D7F65FEC_1... done.
Writting process 66BD0946C509313DFB379466D7F65FEC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched66BD0946C509313DFB379466D7F65FEC.report
Scheduling successful
submit!!!
jobs = 80
day = 146 run = 15146062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15146062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15146062/*.root.log: No such file or directory
20
20 20
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:28:29 PDT] Dataset size is 20 files
Removing files not on site LBL
[2017.09.05 16:28:29 PDT] Dataset size is 20 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:28:29 PDT] Dataset size is 20 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:28:29 PDT] Started with 20 files, current size is 20files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=20 ,maxSize=20 )
[2017.09.05 16:28:29 PDT] Dataset size is 20 files
----------------------------------------------------
validating dataset ....passed
Writting process 1DEDE206700C1BF7A45FFCA58BAF8972_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1DEDE206700C1BF7A45FFCA58BAF8972.report
Scheduling successful
submit!!!
Job submission for day 146 finished!
147
jobs = 74
day = 147 run = 15147001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147001/*.root.log: No such file or directory
153
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:29:40 PDT] Dataset size is 153 files
Removing files not on site LBL
[2017.09.05 16:29:40 PDT] Dataset size is 153 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:29:40 PDT] Dataset size is 153 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:29:40 PDT] Started with 153 files, current size is 153files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:29:40 PDT] Dataset size is 153 files
----------------------------------------------------
validating dataset ....passed
Writting process FEFDF283DDAD9556386257703CD26C67_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FEFDF283DDAD9556386257703CD26C67_1... done.
Writting process FEFDF283DDAD9556386257703CD26C67_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFEFDF283DDAD9556386257703CD26C67.report
Scheduling successful
submit!!!
jobs = 75
day = 147 run = 15147002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147002/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:30:53 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 16:30:53 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:30:53 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:30:53 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:30:53 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 59B5850E7353A860D7B6DD188EEC6973_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 59B5850E7353A860D7B6DD188EEC6973_1... done.
Writting process 59B5850E7353A860D7B6DD188EEC6973_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched59B5850E7353A860D7B6DD188EEC6973.report
Scheduling successful
submit!!!
jobs = 76
day = 147 run = 15147003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147003/*.root.log: No such file or directory
217
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:32:07 PDT] Dataset size is 217 files
Removing files not on site LBL
[2017.09.05 16:32:07 PDT] Dataset size is 217 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:32:07 PDT] Dataset size is 217 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:32:07 PDT] Started with 217 files, current size is 217files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:32:07 PDT] Dataset size is 217 files
----------------------------------------------------
validating dataset ....passed
Writting process F5CE0F8411025E9B09D2C0A529E1C143_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F5CE0F8411025E9B09D2C0A529E1C143_2... done.
Writting process F5CE0F8411025E9B09D2C0A529E1C143_1... done.
Writting process F5CE0F8411025E9B09D2C0A529E1C143_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF5CE0F8411025E9B09D2C0A529E1C143.report
Scheduling successful
submit!!!
jobs = 79
day = 147 run = 15147004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147004/*.root.log: No such file or directory
80
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:33:16 PDT] Dataset size is 80 files
Removing files not on site LBL
[2017.09.05 16:33:16 PDT] Dataset size is 80 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:33:16 PDT] Dataset size is 80 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:33:16 PDT] Started with 80 files, current size is 80files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:33:16 PDT] Dataset size is 80 files
----------------------------------------------------
validating dataset ....passed
Writting process 04D5FFC71E65EF4646B8C6A581399E23_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched04D5FFC71E65EF4646B8C6A581399E23.report
Scheduling successful
submit!!!
jobs = 75
day = 147 run = 15147005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147005/*.root.log: No such file or directory
70
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:34:25 PDT] Dataset size is 70 files
Removing files not on site LBL
[2017.09.05 16:34:25 PDT] Dataset size is 70 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:34:25 PDT] Dataset size is 70 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:34:25 PDT] Started with 70 files, current size is 70files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:34:25 PDT] Dataset size is 70 files
----------------------------------------------------
validating dataset ....passed
Writting process 48475CC5B8C0C30CC3D46DCF25B446BA_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched48475CC5B8C0C30CC3D46DCF25B446BA.report
Scheduling successful
submit!!!
jobs = 74
day = 147 run = 15147006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147006/*.root.log: No such file or directory
221
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:35:37 PDT] Dataset size is 221 files
Removing files not on site LBL
[2017.09.05 16:35:37 PDT] Dataset size is 221 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:35:38 PDT] Dataset size is 221 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:35:38 PDT] Started with 221 files, current size is 221files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:35:38 PDT] Dataset size is 221 files
----------------------------------------------------
validating dataset ....passed
Writting process 77F58CD99EC64009AC084C4147BD8479_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 77F58CD99EC64009AC084C4147BD8479_2... done.
Writting process 77F58CD99EC64009AC084C4147BD8479_1... done.
Writting process 77F58CD99EC64009AC084C4147BD8479_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched77F58CD99EC64009AC084C4147BD8479.report
Scheduling successful
submit!!!
jobs = 75
day = 147 run = 15147007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147007/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:36:51 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 16:36:51 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:36:51 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:36:51 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:36:51 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process 89E738476060F7374A013CA25D7C5804_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 89E738476060F7374A013CA25D7C5804_1... done.
Writting process 89E738476060F7374A013CA25D7C5804_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched89E738476060F7374A013CA25D7C5804.report
Scheduling successful
submit!!!
jobs = 77
day = 147 run = 15147008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147008/*.root.log: No such file or directory
242
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:38:05 PDT] Dataset size is 242 files
Removing files not on site LBL
[2017.09.05 16:38:05 PDT] Dataset size is 242 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:38:05 PDT] Dataset size is 242 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:38:05 PDT] Started with 242 files, current size is 242files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:38:05 PDT] Dataset size is 242 files
----------------------------------------------------
validating dataset ....passed
Writting process 4698BBB67168B9E135B8EA14987CC770_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4698BBB67168B9E135B8EA14987CC770_2... done.
Writting process 4698BBB67168B9E135B8EA14987CC770_1... done.
Writting process 4698BBB67168B9E135B8EA14987CC770_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4698BBB67168B9E135B8EA14987CC770.report
Scheduling successful
submit!!!
jobs = 79
day = 147 run = 15147009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147009/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:39:17 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 16:39:17 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:39:17 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:39:17 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:39:17 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 1F3CC57F00A046DB876D77F6D71FD10E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1F3CC57F00A046DB876D77F6D71FD10E_1... done.
Writting process 1F3CC57F00A046DB876D77F6D71FD10E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1F3CC57F00A046DB876D77F6D71FD10E.report
Scheduling successful
submit!!!
jobs = 81
day = 147 run = 15147010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147010/*.root.log: No such file or directory
144
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:40:28 PDT] Dataset size is 144 files
Removing files not on site LBL
[2017.09.05 16:40:28 PDT] Dataset size is 144 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:40:28 PDT] Dataset size is 144 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:40:28 PDT] Started with 144 files, current size is 144files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:40:28 PDT] Dataset size is 144 files
----------------------------------------------------
validating dataset ....passed
Writting process DD61D04F59EF90F15F177B5FACFE1A80_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DD61D04F59EF90F15F177B5FACFE1A80_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDD61D04F59EF90F15F177B5FACFE1A80.report
Scheduling successful
submit!!!
jobs = 78
day = 147 run = 15147011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147011/*.root.log: No such file or directory
158
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:41:40 PDT] Dataset size is 158 files
Removing files not on site LBL
[2017.09.05 16:41:40 PDT] Dataset size is 158 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:41:40 PDT] Dataset size is 158 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:41:40 PDT] Started with 158 files, current size is 158files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:41:40 PDT] Dataset size is 158 files
----------------------------------------------------
validating dataset ....passed
Writting process 10BA32DC327B8ADF205C5FADD48B1AE7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 10BA32DC327B8ADF205C5FADD48B1AE7_1... done.
Writting process 10BA32DC327B8ADF205C5FADD48B1AE7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched10BA32DC327B8ADF205C5FADD48B1AE7.report
Scheduling successful
submit!!!
jobs = 81
day = 147 run = 15147012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147012/*.root.log: No such file or directory
164
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:42:51 PDT] Dataset size is 164 files
Removing files not on site LBL
[2017.09.05 16:42:51 PDT] Dataset size is 164 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:42:51 PDT] Dataset size is 164 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:42:51 PDT] Started with 164 files, current size is 164files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:42:51 PDT] Dataset size is 164 files
----------------------------------------------------
validating dataset ....passed
Writting process 307BDCF9BA48B629E6D5E067AF6F4024_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 307BDCF9BA48B629E6D5E067AF6F4024_1... done.
Writting process 307BDCF9BA48B629E6D5E067AF6F4024_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched307BDCF9BA48B629E6D5E067AF6F4024.report
Scheduling successful
submit!!!
jobs = 84
day = 147 run = 15147013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147013/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:44:02 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 16:44:03 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:44:03 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:44:03 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:44:03 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 114856E97357E049A13FCFDC41E3A4F1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 114856E97357E049A13FCFDC41E3A4F1_1... done.
Writting process 114856E97357E049A13FCFDC41E3A4F1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched114856E97357E049A13FCFDC41E3A4F1.report
Scheduling successful
submit!!!
jobs = 84
day = 147 run = 15147014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147014/*.root.log: No such file or directory
103
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:45:12 PDT] Dataset size is 103 files
Removing files not on site LBL
[2017.09.05 16:45:12 PDT] Dataset size is 103 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:45:12 PDT] Dataset size is 103 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:45:12 PDT] Started with 103 files, current size is 103files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:45:12 PDT] Dataset size is 103 files
----------------------------------------------------
validating dataset ....passed
Writting process 0B196D00CD9F6B78B131A69B313A25A8_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0B196D00CD9F6B78B131A69B313A25A8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0B196D00CD9F6B78B131A69B313A25A8.report
Scheduling successful
submit!!!
jobs = 84
day = 147 run = 15147015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147015/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:46:24 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 16:46:24 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:46:24 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:46:24 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:46:24 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process B55F5B00A5279C1F118ABCA3156F4AE3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B55F5B00A5279C1F118ABCA3156F4AE3_1... done.
Writting process B55F5B00A5279C1F118ABCA3156F4AE3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB55F5B00A5279C1F118ABCA3156F4AE3.report
Scheduling successful
submit!!!
jobs = 85
day = 147 run = 15147027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147027/*.root.log: No such file or directory
142
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:47:34 PDT] Dataset size is 142 files
Removing files not on site LBL
[2017.09.05 16:47:34 PDT] Dataset size is 142 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:47:34 PDT] Dataset size is 142 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:47:34 PDT] Started with 142 files, current size is 142files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:47:34 PDT] Dataset size is 142 files
----------------------------------------------------
validating dataset ....passed
Writting process 389CBA2510E128CC9F0657349230BBF2_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 389CBA2510E128CC9F0657349230BBF2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched389CBA2510E128CC9F0657349230BBF2.report
Scheduling successful
submit!!!
jobs = 85
day = 147 run = 15147028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147028/*.root.log: No such file or directory
150
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:48:45 PDT] Dataset size is 150 files
Removing files not on site LBL
[2017.09.05 16:48:45 PDT] Dataset size is 150 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:48:45 PDT] Dataset size is 150 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:48:45 PDT] Started with 150 files, current size is 150files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:48:45 PDT] Dataset size is 150 files
----------------------------------------------------
validating dataset ....passed
Writting process 2FEB28A55D3A2AB8E035E26A5463DD6B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2FEB28A55D3A2AB8E035E26A5463DD6B_1... done.
Writting process 2FEB28A55D3A2AB8E035E26A5463DD6B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2FEB28A55D3A2AB8E035E26A5463DD6B.report
Scheduling successful
submit!!!
jobs = 86
day = 147 run = 15147029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147029/*.root.log: No such file or directory
162
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:49:56 PDT] Dataset size is 162 files
Removing files not on site LBL
[2017.09.05 16:49:56 PDT] Dataset size is 162 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:49:56 PDT] Dataset size is 162 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:49:56 PDT] Started with 162 files, current size is 162files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:49:56 PDT] Dataset size is 162 files
----------------------------------------------------
validating dataset ....passed
Writting process E6BBCB92A2619E3D9286A43B2A7A63A0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E6BBCB92A2619E3D9286A43B2A7A63A0_1... done.
Writting process E6BBCB92A2619E3D9286A43B2A7A63A0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE6BBCB92A2619E3D9286A43B2A7A63A0.report
Scheduling successful
submit!!!
jobs = 88
day = 147 run = 15147030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147030/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:51:07 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 16:51:07 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:51:07 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:51:08 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:51:08 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process 46FE7DB63A47DBDFE4CF87EF424E2849_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 46FE7DB63A47DBDFE4CF87EF424E2849_1... done.
Writting process 46FE7DB63A47DBDFE4CF87EF424E2849_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched46FE7DB63A47DBDFE4CF87EF424E2849.report
Scheduling successful
submit!!!
jobs = 89
day = 147 run = 15147031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147031/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:52:19 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 16:52:19 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:52:19 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:52:19 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:52:19 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process C676357A92FF5E4CFD0CB1BC056585D5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C676357A92FF5E4CFD0CB1BC056585D5_1... done.
Writting process C676357A92FF5E4CFD0CB1BC056585D5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC676357A92FF5E4CFD0CB1BC056585D5.report
Scheduling successful
submit!!!
jobs = 91
day = 147 run = 15147032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147032/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:53:31 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 16:53:31 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:53:32 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:53:32 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:53:32 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process 13DF0DECBCCD2D5B26FC5540EB9F377E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 13DF0DECBCCD2D5B26FC5540EB9F377E_1... done.
Writting process 13DF0DECBCCD2D5B26FC5540EB9F377E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched13DF0DECBCCD2D5B26FC5540EB9F377E.report
Scheduling successful
submit!!!
jobs = 93
day = 147 run = 15147033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147033/*.root.log: No such file or directory
60
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:54:39 PDT] Dataset size is 60 files
Removing files not on site LBL
[2017.09.05 16:54:39 PDT] Dataset size is 60 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:54:39 PDT] Dataset size is 60 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:54:40 PDT] Started with 60 files, current size is 60files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:54:40 PDT] Dataset size is 60 files
----------------------------------------------------
validating dataset ....passed
Writting process CA44CA14A3C27202BF43595C99E711FF_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCA44CA14A3C27202BF43595C99E711FF.report
Scheduling successful
submit!!!
jobs = 92
day = 147 run = 15147041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147041/*.root.log: No such file or directory
135
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:55:50 PDT] Dataset size is 135 files
Removing files not on site LBL
[2017.09.05 16:55:50 PDT] Dataset size is 135 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:55:50 PDT] Dataset size is 135 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:55:50 PDT] Started with 135 files, current size is 135files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:55:50 PDT] Dataset size is 135 files
----------------------------------------------------
validating dataset ....passed
Writting process E3F4F8E8E154254359C5EF3001FC74D4_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E3F4F8E8E154254359C5EF3001FC74D4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE3F4F8E8E154254359C5EF3001FC74D4.report
Scheduling successful
submit!!!
jobs = 91
day = 147 run = 15147042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15147042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15147042/*.root.log: No such file or directory
32
32 32
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:56:57 PDT] Dataset size is 32 files
Removing files not on site LBL
[2017.09.05 16:56:57 PDT] Dataset size is 32 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:56:57 PDT] Dataset size is 32 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:56:57 PDT] Started with 32 files, current size is 32files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=32 ,maxSize=32 )
[2017.09.05 16:56:57 PDT] Dataset size is 32 files
----------------------------------------------------
validating dataset ....passed
Writting process D46566C0610EBCEA568340F9DBE0B054_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD46566C0610EBCEA568340F9DBE0B054.report
Scheduling successful
submit!!!
Job submission for day 147 finished!
148
jobs = 89
day = 148 run = 15148003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148003/*.root.log: No such file or directory
154
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:58:07 PDT] Dataset size is 154 files
Removing files not on site LBL
[2017.09.05 16:58:07 PDT] Dataset size is 154 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:58:07 PDT] Dataset size is 154 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:58:07 PDT] Started with 154 files, current size is 154files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:58:07 PDT] Dataset size is 154 files
----------------------------------------------------
validating dataset ....passed
Writting process 866DE56B1AAA7719553C4A4EF8AC5766_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 866DE56B1AAA7719553C4A4EF8AC5766_1... done.
Writting process 866DE56B1AAA7719553C4A4EF8AC5766_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched866DE56B1AAA7719553C4A4EF8AC5766.report
Scheduling successful
submit!!!
jobs = 90
day = 148 run = 15148004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148004/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 16:59:19 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 16:59:19 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 16:59:19 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 16:59:19 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 16:59:19 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 0B72497C0532F6410C24729CAB7D9E74_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0B72497C0532F6410C24729CAB7D9E74_1... done.
Writting process 0B72497C0532F6410C24729CAB7D9E74_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0B72497C0532F6410C24729CAB7D9E74.report
Scheduling successful
submit!!!
jobs = 92
day = 148 run = 15148005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148005/*.root.log: No such file or directory
129
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:00:30 PDT] Dataset size is 129 files
Removing files not on site LBL
[2017.09.05 17:00:30 PDT] Dataset size is 129 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:00:30 PDT] Dataset size is 129 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:00:30 PDT] Started with 129 files, current size is 129files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:00:30 PDT] Dataset size is 129 files
----------------------------------------------------
validating dataset ....passed
Writting process 2AD4628A06402D74BAD0AD05DDA8D11E_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2AD4628A06402D74BAD0AD05DDA8D11E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2AD4628A06402D74BAD0AD05DDA8D11E.report
Scheduling successful
submit!!!
jobs = 94
day = 148 run = 15148006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148006/*.root.log: No such file or directory
152
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:01:41 PDT] Dataset size is 152 files
Removing files not on site LBL
[2017.09.05 17:01:41 PDT] Dataset size is 152 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:01:41 PDT] Dataset size is 152 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:01:41 PDT] Started with 152 files, current size is 152files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:01:41 PDT] Dataset size is 152 files
----------------------------------------------------
validating dataset ....passed
Writting process F161D80F6CEED8DB5C458664BB4A5F1C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F161D80F6CEED8DB5C458664BB4A5F1C_1... done.
Writting process F161D80F6CEED8DB5C458664BB4A5F1C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF161D80F6CEED8DB5C458664BB4A5F1C.report
Scheduling successful
submit!!!
jobs = 96
day = 148 run = 15148007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148007/*.root.log: No such file or directory
143
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:02:52 PDT] Dataset size is 143 files
Removing files not on site LBL
[2017.09.05 17:02:52 PDT] Dataset size is 143 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:02:52 PDT] Dataset size is 143 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:02:52 PDT] Started with 143 files, current size is 143files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:02:52 PDT] Dataset size is 143 files
----------------------------------------------------
validating dataset ....passed
Writting process A49C040FE227EFAEC102B88C554E4F60_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A49C040FE227EFAEC102B88C554E4F60_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA49C040FE227EFAEC102B88C554E4F60.report
Scheduling successful
submit!!!
jobs = 98
day = 148 run = 15148008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148008/*.root.log: No such file or directory
143
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:04:02 PDT] Dataset size is 143 files
Removing files not on site LBL
[2017.09.05 17:04:02 PDT] Dataset size is 143 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:04:02 PDT] Dataset size is 143 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:04:02 PDT] Started with 143 files, current size is 143files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:04:02 PDT] Dataset size is 143 files
----------------------------------------------------
validating dataset ....passed
Writting process C5CD72B0C96B0ED68AA703CC9BCD8B41_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C5CD72B0C96B0ED68AA703CC9BCD8B41_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC5CD72B0C96B0ED68AA703CC9BCD8B41.report
Scheduling successful
submit!!!
jobs = 98
day = 148 run = 15148009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148009/*.root.log: No such file or directory
44
44 44
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:05:10 PDT] Dataset size is 44 files
Removing files not on site LBL
[2017.09.05 17:05:10 PDT] Dataset size is 44 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:05:10 PDT] Dataset size is 44 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:05:10 PDT] Started with 44 files, current size is 44files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=44 ,maxSize=44 )
[2017.09.05 17:05:10 PDT] Dataset size is 44 files
----------------------------------------------------
validating dataset ....passed
Writting process 24B7B8E65326903D06829DA5AA671136_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched24B7B8E65326903D06829DA5AA671136.report
Scheduling successful
submit!!!
jobs = 98
day = 148 run = 15148010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148010/*.root.log: No such file or directory
131
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:06:19 PDT] Dataset size is 131 files
Removing files not on site LBL
[2017.09.05 17:06:20 PDT] Dataset size is 131 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:06:20 PDT] Dataset size is 131 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:06:20 PDT] Started with 131 files, current size is 131files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:06:20 PDT] Dataset size is 131 files
----------------------------------------------------
validating dataset ....passed
Writting process D9D3610ADB185B0362F8D4A4BD231D99_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D9D3610ADB185B0362F8D4A4BD231D99_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD9D3610ADB185B0362F8D4A4BD231D99.report
Scheduling successful
submit!!!
jobs = 99
day = 148 run = 15148011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15148011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15148011/*.root.log: No such file or directory
91
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:07:29 PDT] Dataset size is 91 files
Removing files not on site LBL
[2017.09.05 17:07:29 PDT] Dataset size is 91 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:07:29 PDT] Dataset size is 91 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:07:29 PDT] Started with 91 files, current size is 91files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:07:29 PDT] Dataset size is 91 files
----------------------------------------------------
validating dataset ....passed
Writting process D8F2C46EAECFBC290FFF25B5D81B126F_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD8F2C46EAECFBC290FFF25B5D81B126F.report
Scheduling successful
submit!!!
Job submission for day 148 finished!
149
jobs = 99
day = 149 run = 15149012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149012/*.root.log: No such file or directory
197
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:08:41 PDT] Dataset size is 197 files
Removing files not on site LBL
[2017.09.05 17:08:41 PDT] Dataset size is 197 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:08:41 PDT] Dataset size is 197 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:08:41 PDT] Started with 197 files, current size is 197files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:08:41 PDT] Dataset size is 197 files
----------------------------------------------------
validating dataset ....passed
Writting process 0E9146767FC8A0FCEA37DDD3142493E8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0E9146767FC8A0FCEA37DDD3142493E8_1... done.
Writting process 0E9146767FC8A0FCEA37DDD3142493E8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0E9146767FC8A0FCEA37DDD3142493E8.report
Scheduling successful
submit!!!
jobs = 101
day = 149 run = 15149013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149013/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:09:53 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 17:09:53 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:09:53 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:09:53 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:09:53 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 571031FE497D97BED7B2AA51FA0B0034_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 571031FE497D97BED7B2AA51FA0B0034_1... done.
Writting process 571031FE497D97BED7B2AA51FA0B0034_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched571031FE497D97BED7B2AA51FA0B0034.report
Scheduling successful
submit!!!
jobs = 100
day = 149 run = 15149015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149015/*.root.log: No such file or directory
93
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:11:02 PDT] Dataset size is 93 files
Removing files not on site LBL
[2017.09.05 17:11:02 PDT] Dataset size is 93 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:11:02 PDT] Dataset size is 93 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:11:02 PDT] Started with 93 files, current size is 93files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:11:02 PDT] Dataset size is 93 files
----------------------------------------------------
validating dataset ....passed
Writting process 8AAA6A50A6FC4CBB02A102D2613267CE_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8AAA6A50A6FC4CBB02A102D2613267CE.report
Scheduling successful
submit!!!
jobs = 96
day = 149 run = 15149016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149016/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:12:14 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 17:12:14 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:12:14 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:12:14 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:12:14 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process E79869AEA2BB177A8DBE808057B8AB14_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E79869AEA2BB177A8DBE808057B8AB14_1... done.
Writting process E79869AEA2BB177A8DBE808057B8AB14_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE79869AEA2BB177A8DBE808057B8AB14.report
Scheduling successful
submit!!!
jobs = 95
day = 149 run = 15149017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149017/*.root.log: No such file or directory
139
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:13:24 PDT] Dataset size is 139 files
Removing files not on site LBL
[2017.09.05 17:13:24 PDT] Dataset size is 139 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:13:24 PDT] Dataset size is 139 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:13:25 PDT] Started with 139 files, current size is 139files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:13:25 PDT] Dataset size is 139 files
----------------------------------------------------
validating dataset ....passed
Writting process 4CE4EA1BD0A1CB224E24C0CBE983D72B_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4CE4EA1BD0A1CB224E24C0CBE983D72B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4CE4EA1BD0A1CB224E24C0CBE983D72B.report
Scheduling successful
submit!!!
jobs = 91
day = 149 run = 15149069
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149069/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149069/*.root.log: No such file or directory
34
34 34
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:14:31 PDT] Dataset size is 34 files
Removing files not on site LBL
[2017.09.05 17:14:32 PDT] Dataset size is 34 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:14:32 PDT] Dataset size is 34 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:14:32 PDT] Started with 34 files, current size is 34files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=34 ,maxSize=34 )
[2017.09.05 17:14:32 PDT] Dataset size is 34 files
----------------------------------------------------
validating dataset ....passed
Writting process 9C5B8A34549F056E7853BC285C7EFA64_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9C5B8A34549F056E7853BC285C7EFA64.report
Scheduling successful
submit!!!
jobs = 91
day = 149 run = 15149070
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149070/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149070/*.root.log: No such file or directory
93
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:15:40 PDT] Dataset size is 93 files
Removing files not on site LBL
[2017.09.05 17:15:40 PDT] Dataset size is 93 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:15:40 PDT] Dataset size is 93 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:15:40 PDT] Started with 93 files, current size is 93files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:15:40 PDT] Dataset size is 93 files
----------------------------------------------------
validating dataset ....passed
Writting process 47C373B9B84E52105368C44F0E70BA88_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched47C373B9B84E52105368C44F0E70BA88.report
Scheduling successful
submit!!!
jobs = 91
day = 149 run = 15149071
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149071/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149071/*.root.log: No such file or directory
157
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:16:51 PDT] Dataset size is 157 files
Removing files not on site LBL
[2017.09.05 17:16:51 PDT] Dataset size is 157 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:16:51 PDT] Dataset size is 157 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:16:51 PDT] Started with 157 files, current size is 157files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:16:51 PDT] Dataset size is 157 files
----------------------------------------------------
validating dataset ....passed
Writting process C4AAAB9ECE1FC7C4ED73FF61FFA3022B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C4AAAB9ECE1FC7C4ED73FF61FFA3022B_1... done.
Writting process C4AAAB9ECE1FC7C4ED73FF61FFA3022B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC4AAAB9ECE1FC7C4ED73FF61FFA3022B.report
Scheduling successful
submit!!!
jobs = 92
day = 149 run = 15149072
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149072/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149072/*.root.log: No such file or directory
51
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:17:59 PDT] Dataset size is 51 files
Removing files not on site LBL
[2017.09.05 17:17:59 PDT] Dataset size is 51 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:17:59 PDT] Dataset size is 51 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:17:59 PDT] Started with 51 files, current size is 51files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:17:59 PDT] Dataset size is 51 files
----------------------------------------------------
validating dataset ....passed
Writting process BE6757983A9B2C395367B1C1374A5E19_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBE6757983A9B2C395367B1C1374A5E19.report
Scheduling successful
submit!!!
jobs = 92
day = 149 run = 15149073
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149073/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149073/*.root.log: No such file or directory
26
26 26
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:19:05 PDT] Dataset size is 26 files
Removing files not on site LBL
[2017.09.05 17:19:05 PDT] Dataset size is 26 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:19:05 PDT] Dataset size is 26 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:19:05 PDT] Started with 26 files, current size is 26files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=26 ,maxSize=26 )
[2017.09.05 17:19:06 PDT] Dataset size is 26 files
----------------------------------------------------
validating dataset ....passed
Writting process EEDDC6CA0959C285E6B40B724E2E1ED9_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEEDDC6CA0959C285E6B40B724E2E1ED9.report
Scheduling successful
submit!!!
jobs = 89
day = 149 run = 15149074
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149074/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149074/*.root.log: No such file or directory
89
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:20:14 PDT] Dataset size is 89 files
Removing files not on site LBL
[2017.09.05 17:20:14 PDT] Dataset size is 89 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:20:14 PDT] Dataset size is 89 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:20:14 PDT] Started with 89 files, current size is 89files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:20:14 PDT] Dataset size is 89 files
----------------------------------------------------
validating dataset ....passed
Writting process E8A957FB692D2A48685686E980C5B4E3_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE8A957FB692D2A48685686E980C5B4E3.report
Scheduling successful
submit!!!
jobs = 87
day = 149 run = 15149075
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149075/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149075/*.root.log: No such file or directory
147
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:21:25 PDT] Dataset size is 147 files
Removing files not on site LBL
[2017.09.05 17:21:25 PDT] Dataset size is 147 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:21:25 PDT] Dataset size is 147 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:21:25 PDT] Started with 147 files, current size is 147files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:21:25 PDT] Dataset size is 147 files
----------------------------------------------------
validating dataset ....passed
Writting process 2A6E8176E17E59D9BA25BBD7C51E8E21_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2A6E8176E17E59D9BA25BBD7C51E8E21_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2A6E8176E17E59D9BA25BBD7C51E8E21.report
Scheduling successful
submit!!!
jobs = 86
day = 149 run = 15149076
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15149076/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15149076/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:22:36 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 17:22:36 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:22:36 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:22:37 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:22:37 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process B5B19B061FEB16131F2839DEE4DC7C38_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B5B19B061FEB16131F2839DEE4DC7C38_1... done.
Writting process B5B19B061FEB16131F2839DEE4DC7C38_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB5B19B061FEB16131F2839DEE4DC7C38.report
Scheduling successful
submit!!!
Job submission for day 149 finished!
150
jobs = 85
day = 150 run = 15150001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150001/*.root.log: No such file or directory
212
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:23:49 PDT] Dataset size is 212 files
Removing files not on site LBL
[2017.09.05 17:23:49 PDT] Dataset size is 212 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:23:49 PDT] Dataset size is 212 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:23:49 PDT] Started with 212 files, current size is 212files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:23:49 PDT] Dataset size is 212 files
----------------------------------------------------
validating dataset ....passed
Writting process 158CDE8A46DE2CF961887ABC76E82614_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 158CDE8A46DE2CF961887ABC76E82614_2... done.
Writting process 158CDE8A46DE2CF961887ABC76E82614_1... done.
Writting process 158CDE8A46DE2CF961887ABC76E82614_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched158CDE8A46DE2CF961887ABC76E82614.report
Scheduling successful
submit!!!
jobs = 87
day = 150 run = 15150004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150004/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:25:01 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 17:25:01 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:25:01 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:25:02 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:25:02 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process 770EDC3F99538ADB5A9662F5BE81AA71_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 770EDC3F99538ADB5A9662F5BE81AA71_1... done.
Writting process 770EDC3F99538ADB5A9662F5BE81AA71_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched770EDC3F99538ADB5A9662F5BE81AA71.report
Scheduling successful
submit!!!
jobs = 87
day = 150 run = 15150005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150005/*.root.log: No such file or directory
33
33 33
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:26:09 PDT] Dataset size is 33 files
Removing files not on site LBL
[2017.09.05 17:26:09 PDT] Dataset size is 33 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:26:09 PDT] Dataset size is 33 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:26:09 PDT] Started with 33 files, current size is 33files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=33 ,maxSize=33 )
[2017.09.05 17:26:09 PDT] Dataset size is 33 files
----------------------------------------------------
validating dataset ....passed
Writting process 2FE7761DA647F546B3AD0F84E2AF3B2E_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2FE7761DA647F546B3AD0F84E2AF3B2E.report
Scheduling successful
submit!!!
jobs = 86
day = 150 run = 15150014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150014/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:27:21 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 17:27:21 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:27:21 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:27:21 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:27:21 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process DA9F635A2391E3726244F5D11417604B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DA9F635A2391E3726244F5D11417604B_1... done.
Writting process DA9F635A2391E3726244F5D11417604B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDA9F635A2391E3726244F5D11417604B.report
Scheduling successful
submit!!!
jobs = 86
day = 150 run = 15150015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150015/*.root.log: No such file or directory
115
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:28:31 PDT] Dataset size is 115 files
Removing files not on site LBL
[2017.09.05 17:28:31 PDT] Dataset size is 115 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:28:31 PDT] Dataset size is 115 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:28:31 PDT] Started with 115 files, current size is 115files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:28:31 PDT] Dataset size is 115 files
----------------------------------------------------
validating dataset ....passed
Writting process 39C439E8B07C874BAB977EEFF21E0FB8_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 39C439E8B07C874BAB977EEFF21E0FB8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched39C439E8B07C874BAB977EEFF21E0FB8.report
Scheduling successful
submit!!!
jobs = 80
day = 150 run = 15150027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150027/*.root.log: No such file or directory
137
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:29:41 PDT] Dataset size is 137 files
Removing files not on site LBL
[2017.09.05 17:29:41 PDT] Dataset size is 137 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:29:41 PDT] Dataset size is 137 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:29:41 PDT] Started with 137 files, current size is 137files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:29:41 PDT] Dataset size is 137 files
----------------------------------------------------
validating dataset ....passed
Writting process 7161874BD6C822AD6B94E1A83B1E588A_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7161874BD6C822AD6B94E1A83B1E588A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7161874BD6C822AD6B94E1A83B1E588A.report
Scheduling successful
submit!!!
jobs = 81
day = 150 run = 15150030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150030/*.root.log: No such file or directory
80
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:30:50 PDT] Dataset size is 80 files
Removing files not on site LBL
[2017.09.05 17:30:50 PDT] Dataset size is 80 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:30:50 PDT] Dataset size is 80 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:30:50 PDT] Started with 80 files, current size is 80files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:30:50 PDT] Dataset size is 80 files
----------------------------------------------------
validating dataset ....passed
Writting process 9E7047665BFFCF4D6ABD65F9E7746D78_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9E7047665BFFCF4D6ABD65F9E7746D78.report
Scheduling successful
submit!!!
jobs = 76
day = 150 run = 15150031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150031/*.root.log: No such file or directory
2
2 2
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:31:56 PDT] Dataset size is 2 files
Removing files not on site LBL
[2017.09.05 17:31:56 PDT] Dataset size is 2 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:31:56 PDT] Dataset size is 2 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:31:56 PDT] Started with 2 files, current size is 2files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=2 ,maxSize=2 )
[2017.09.05 17:31:56 PDT] Dataset size is 2 files
----------------------------------------------------
validating dataset ....passed
Writting process EAB7350CF54798730B4B998F67D70970_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEAB7350CF54798730B4B998F67D70970.report
Scheduling successful
submit!!!
jobs = 73
day = 150 run = 15150048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150048/*.root.log: No such file or directory
198
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:33:08 PDT] Dataset size is 198 files
Removing files not on site LBL
[2017.09.05 17:33:08 PDT] Dataset size is 198 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:33:08 PDT] Dataset size is 198 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:33:08 PDT] Started with 198 files, current size is 198files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:33:08 PDT] Dataset size is 198 files
----------------------------------------------------
validating dataset ....passed
Writting process D14901A4F832E4AB5921519A75214FCB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D14901A4F832E4AB5921519A75214FCB_1... done.
Writting process D14901A4F832E4AB5921519A75214FCB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD14901A4F832E4AB5921519A75214FCB.report
Scheduling successful
submit!!!
jobs = 73
day = 150 run = 15150049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150049/*.root.log: No such file or directory
64
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:34:16 PDT] Dataset size is 64 files
Removing files not on site LBL
[2017.09.05 17:34:16 PDT] Dataset size is 64 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:34:16 PDT] Dataset size is 64 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:34:16 PDT] Started with 64 files, current size is 64files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:34:16 PDT] Dataset size is 64 files
----------------------------------------------------
validating dataset ....passed
Writting process 18F7E945E37CCE685347FF3F426CF3A1_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched18F7E945E37CCE685347FF3F426CF3A1.report
Scheduling successful
submit!!!
jobs = 73
day = 150 run = 15150054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150054/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:35:28 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 17:35:28 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:35:28 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:35:28 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:35:28 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process 8F68EAE789540C88D546BC83D9BD5501_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8F68EAE789540C88D546BC83D9BD5501_1... done.
Writting process 8F68EAE789540C88D546BC83D9BD5501_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8F68EAE789540C88D546BC83D9BD5501.report
Scheduling successful
submit!!!
jobs = 73
day = 150 run = 15150055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150055/*.root.log: No such file or directory
84
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:36:37 PDT] Dataset size is 84 files
Removing files not on site LBL
[2017.09.05 17:36:37 PDT] Dataset size is 84 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:36:37 PDT] Dataset size is 84 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:36:37 PDT] Started with 84 files, current size is 84files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:36:37 PDT] Dataset size is 84 files
----------------------------------------------------
validating dataset ....passed
Writting process B330B76D6A5F27F56C5E88EC9BA5CEDD_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB330B76D6A5F27F56C5E88EC9BA5CEDD.report
Scheduling successful
submit!!!
jobs = 71
day = 150 run = 15150056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150056/*.root.log: No such file or directory
41
41 41
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:37:44 PDT] Dataset size is 41 files
Removing files not on site LBL
[2017.09.05 17:37:44 PDT] Dataset size is 41 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:37:44 PDT] Dataset size is 41 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:37:44 PDT] Started with 41 files, current size is 41files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=41 ,maxSize=41 )
[2017.09.05 17:37:44 PDT] Dataset size is 41 files
----------------------------------------------------
validating dataset ....passed
Writting process 577F2685E27638671A25BB44F073AC62_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched577F2685E27638671A25BB44F073AC62.report
Scheduling successful
submit!!!
jobs = 71
day = 150 run = 15150058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150058/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:38:55 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 17:38:55 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:38:55 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:38:55 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:38:55 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process CDC2A6CE2F0B9A03C735D8A084D432A8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CDC2A6CE2F0B9A03C735D8A084D432A8_1... done.
Writting process CDC2A6CE2F0B9A03C735D8A084D432A8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCDC2A6CE2F0B9A03C735D8A084D432A8.report
Scheduling successful
submit!!!
jobs = 70
day = 150 run = 15150059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150059/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:40:07 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 17:40:07 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:40:07 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:40:07 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:40:07 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 3AE38B1484CD77ABFCF7A886B04CF5FF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3AE38B1484CD77ABFCF7A886B04CF5FF_1... done.
Writting process 3AE38B1484CD77ABFCF7A886B04CF5FF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3AE38B1484CD77ABFCF7A886B04CF5FF.report
Scheduling successful
submit!!!
jobs = 69
day = 150 run = 15150060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150060/*.root.log: No such file or directory
192
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:41:19 PDT] Dataset size is 192 files
Removing files not on site LBL
[2017.09.05 17:41:19 PDT] Dataset size is 192 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:41:19 PDT] Dataset size is 192 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:41:19 PDT] Started with 192 files, current size is 192files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:41:19 PDT] Dataset size is 192 files
----------------------------------------------------
validating dataset ....passed
Writting process E4D482F531A89F36157CBEC32DD09003_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E4D482F531A89F36157CBEC32DD09003_1... done.
Writting process E4D482F531A89F36157CBEC32DD09003_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE4D482F531A89F36157CBEC32DD09003.report
Scheduling successful
submit!!!
jobs = 71
day = 150 run = 15150061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150061/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:42:31 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 17:42:31 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:42:31 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:42:31 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:42:31 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process FE0F76D7D00272972F59B2C588BA5695_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FE0F76D7D00272972F59B2C588BA5695_1... done.
Writting process FE0F76D7D00272972F59B2C588BA5695_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFE0F76D7D00272972F59B2C588BA5695.report
Scheduling successful
submit!!!
jobs = 72
day = 150 run = 15150062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150062/*.root.log: No such file or directory
76
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:43:40 PDT] Dataset size is 76 files
Removing files not on site LBL
[2017.09.05 17:43:40 PDT] Dataset size is 76 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:43:40 PDT] Dataset size is 76 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:43:40 PDT] Started with 76 files, current size is 76files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:43:40 PDT] Dataset size is 76 files
----------------------------------------------------
validating dataset ....passed
Writting process 5B21E1B60F68CFF2643B8172518833FA_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5B21E1B60F68CFF2643B8172518833FA.report
Scheduling successful
submit!!!
jobs = 71
day = 150 run = 15150063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150063/*.root.log: No such file or directory
62
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:44:48 PDT] Dataset size is 62 files
Removing files not on site LBL
[2017.09.05 17:44:48 PDT] Dataset size is 62 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:44:48 PDT] Dataset size is 62 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:44:48 PDT] Started with 62 files, current size is 62files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:44:48 PDT] Dataset size is 62 files
----------------------------------------------------
validating dataset ....passed
Writting process D031F2D0131E5D521B2F5CC01E8EF5A4_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD031F2D0131E5D521B2F5CC01E8EF5A4.report
Scheduling successful
submit!!!
jobs = 71
day = 150 run = 15150064
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15150064/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15150064/*.root.log: No such file or directory
121
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:45:58 PDT] Dataset size is 121 files
Removing files not on site LBL
[2017.09.05 17:45:58 PDT] Dataset size is 121 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:45:58 PDT] Dataset size is 121 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:45:58 PDT] Started with 121 files, current size is 121files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:45:58 PDT] Dataset size is 121 files
----------------------------------------------------
validating dataset ....passed
Writting process 03C7203A0D4646292A6636AF96F846B5_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 03C7203A0D4646292A6636AF96F846B5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched03C7203A0D4646292A6636AF96F846B5.report
Scheduling successful
submit!!!
Job submission for day 150 finished!
151
jobs = 70
day = 151 run = 15151006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151006/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:47:09 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 17:47:09 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:47:09 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:47:09 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:47:09 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process B781CD3E940A7F737389D99E13C5914B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B781CD3E940A7F737389D99E13C5914B_1... done.
Writting process B781CD3E940A7F737389D99E13C5914B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB781CD3E940A7F737389D99E13C5914B.report
Scheduling successful
submit!!!
jobs = 71
day = 151 run = 15151007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151007/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:48:20 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.05 17:48:20 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:48:20 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:48:20 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:48:20 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process 393EEA2FB2838225655A70F18893FBC6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 393EEA2FB2838225655A70F18893FBC6_1... done.
Writting process 393EEA2FB2838225655A70F18893FBC6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched393EEA2FB2838225655A70F18893FBC6.report
Scheduling successful
submit!!!
jobs = 73
day = 151 run = 15151008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151008/*.root.log: No such file or directory
93
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:49:29 PDT] Dataset size is 93 files
Removing files not on site LBL
[2017.09.05 17:49:29 PDT] Dataset size is 93 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:49:29 PDT] Dataset size is 93 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:49:29 PDT] Started with 93 files, current size is 93files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:49:29 PDT] Dataset size is 93 files
----------------------------------------------------
validating dataset ....passed
Writting process CABA8D6974231B5425917791D0FC93D9_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCABA8D6974231B5425917791D0FC93D9.report
Scheduling successful
submit!!!
jobs = 74
day = 151 run = 15151009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151009/*.root.log: No such file or directory
92
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:50:38 PDT] Dataset size is 92 files
Removing files not on site LBL
[2017.09.05 17:50:38 PDT] Dataset size is 92 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:50:38 PDT] Dataset size is 92 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:50:38 PDT] Started with 92 files, current size is 92files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:50:38 PDT] Dataset size is 92 files
----------------------------------------------------
validating dataset ....passed
Writting process 20FEF8D76C278FC248617239978CFE5D_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched20FEF8D76C278FC248617239978CFE5D.report
Scheduling successful
submit!!!
jobs = 73
day = 151 run = 15151010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151010/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:51:49 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 17:51:49 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:51:49 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:51:49 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:51:49 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process EA763AA6A612249ED879485BA0B6D0C1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EA763AA6A612249ED879485BA0B6D0C1_1... done.
Writting process EA763AA6A612249ED879485BA0B6D0C1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEA763AA6A612249ED879485BA0B6D0C1.report
Scheduling successful
submit!!!
jobs = 74
day = 151 run = 15151011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151011/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:53:00 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 17:53:00 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:53:00 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:53:00 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:53:00 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process 6B74B17F42DD79069C48733763037831_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6B74B17F42DD79069C48733763037831_1... done.
Writting process 6B74B17F42DD79069C48733763037831_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6B74B17F42DD79069C48733763037831.report
Scheduling successful
submit!!!
jobs = 75
day = 151 run = 15151012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151012/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:54:12 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 17:54:12 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:54:12 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:54:12 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:54:12 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 88C449537C0CDDF2596027927F83E0F5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 88C449537C0CDDF2596027927F83E0F5_1... done.
Writting process 88C449537C0CDDF2596027927F83E0F5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched88C449537C0CDDF2596027927F83E0F5.report
Scheduling successful
submit!!!
jobs = 77
day = 151 run = 15151013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151013/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:55:24 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 17:55:24 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:55:24 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:55:24 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:55:24 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process 78A2D1C2F05F6C9D63AF728496BD1E75_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 78A2D1C2F05F6C9D63AF728496BD1E75_1... done.
Writting process 78A2D1C2F05F6C9D63AF728496BD1E75_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched78A2D1C2F05F6C9D63AF728496BD1E75.report
Scheduling successful
submit!!!
jobs = 77
day = 151 run = 15151014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151014/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:56:35 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 17:56:35 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:56:35 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:56:36 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:56:36 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 4DFFA925B1B444C7AF985D604C1FF411_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4DFFA925B1B444C7AF985D604C1FF411_1... done.
Writting process 4DFFA925B1B444C7AF985D604C1FF411_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4DFFA925B1B444C7AF985D604C1FF411.report
Scheduling successful
submit!!!
jobs = 77
day = 151 run = 15151015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151015/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:57:47 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 17:57:47 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:57:47 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:57:47 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:57:47 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process A1539F13D5D3800E996349F563F91D70_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A1539F13D5D3800E996349F563F91D70_1... done.
Writting process A1539F13D5D3800E996349F563F91D70_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA1539F13D5D3800E996349F563F91D70.report
Scheduling successful
submit!!!
jobs = 78
day = 151 run = 15151017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151017/*.root.log: No such file or directory
192
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 17:58:59 PDT] Dataset size is 192 files
Removing files not on site LBL
[2017.09.05 17:58:59 PDT] Dataset size is 192 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 17:58:59 PDT] Dataset size is 192 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 17:58:59 PDT] Started with 192 files, current size is 192files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 17:58:59 PDT] Dataset size is 192 files
----------------------------------------------------
validating dataset ....passed
Writting process 71BA640A36D6650A4A3AE3DAE4EC6B20_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 71BA640A36D6650A4A3AE3DAE4EC6B20_1... done.
Writting process 71BA640A36D6650A4A3AE3DAE4EC6B20_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched71BA640A36D6650A4A3AE3DAE4EC6B20.report
Scheduling successful
submit!!!
jobs = 78
day = 151 run = 15151018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151018/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:00:12 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 18:00:12 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:00:12 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:00:12 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:00:12 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process D80773DC6705668397869C3E98573F5B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D80773DC6705668397869C3E98573F5B_1... done.
Writting process D80773DC6705668397869C3E98573F5B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD80773DC6705668397869C3E98573F5B.report
Scheduling successful
submit!!!
jobs = 78
day = 151 run = 15151019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151019/*.root.log: No such file or directory
226
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:01:25 PDT] Dataset size is 226 files
Removing files not on site LBL
[2017.09.05 18:01:25 PDT] Dataset size is 226 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:01:25 PDT] Dataset size is 226 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:01:25 PDT] Started with 226 files, current size is 226files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:01:25 PDT] Dataset size is 226 files
----------------------------------------------------
validating dataset ....passed
Writting process B2B68DD16996A75EE207BAE7DA2BA71C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B2B68DD16996A75EE207BAE7DA2BA71C_2... done.
Writting process B2B68DD16996A75EE207BAE7DA2BA71C_1... done.
Writting process B2B68DD16996A75EE207BAE7DA2BA71C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB2B68DD16996A75EE207BAE7DA2BA71C.report
Scheduling successful
submit!!!
jobs = 82
day = 151 run = 15151020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151020/*.root.log: No such file or directory
214
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:02:38 PDT] Dataset size is 214 files
Removing files not on site LBL
[2017.09.05 18:02:38 PDT] Dataset size is 214 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:02:38 PDT] Dataset size is 214 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:02:38 PDT] Started with 214 files, current size is 214files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:02:38 PDT] Dataset size is 214 files
----------------------------------------------------
validating dataset ....passed
Writting process 50C164B7AF216339798F2E896A509399_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 50C164B7AF216339798F2E896A509399_2... done.
Writting process 50C164B7AF216339798F2E896A509399_1... done.
Writting process 50C164B7AF216339798F2E896A509399_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched50C164B7AF216339798F2E896A509399.report
Scheduling successful
submit!!!
jobs = 83
day = 151 run = 15151021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151021/*.root.log: No such file or directory
104
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:03:47 PDT] Dataset size is 104 files
Removing files not on site LBL
[2017.09.05 18:03:47 PDT] Dataset size is 104 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:03:47 PDT] Dataset size is 104 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:03:47 PDT] Started with 104 files, current size is 104files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:03:47 PDT] Dataset size is 104 files
----------------------------------------------------
validating dataset ....passed
Writting process D5F2D81B57001C03E37F062B8ECF22C9_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D5F2D81B57001C03E37F062B8ECF22C9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD5F2D81B57001C03E37F062B8ECF22C9.report
Scheduling successful
submit!!!
jobs = 84
day = 151 run = 15151022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151022/*.root.log: No such file or directory
133
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:04:57 PDT] Dataset size is 133 files
Removing files not on site LBL
[2017.09.05 18:04:57 PDT] Dataset size is 133 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:04:57 PDT] Dataset size is 133 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:04:57 PDT] Started with 133 files, current size is 133files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:04:57 PDT] Dataset size is 133 files
----------------------------------------------------
validating dataset ....passed
Writting process AEB0D39B82E7D3B33DA972CE50536FD2_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AEB0D39B82E7D3B33DA972CE50536FD2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAEB0D39B82E7D3B33DA972CE50536FD2.report
Scheduling successful
submit!!!
jobs = 82
day = 151 run = 15151023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151023/*.root.log: No such file or directory
222
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:06:10 PDT] Dataset size is 222 files
Removing files not on site LBL
[2017.09.05 18:06:10 PDT] Dataset size is 222 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:06:10 PDT] Dataset size is 222 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:06:10 PDT] Started with 222 files, current size is 222files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:06:10 PDT] Dataset size is 222 files
----------------------------------------------------
validating dataset ....passed
Writting process D8C7B4169DA6CDE93B91B1E1403A1E56_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D8C7B4169DA6CDE93B91B1E1403A1E56_2... done.
Writting process D8C7B4169DA6CDE93B91B1E1403A1E56_1... done.
Writting process D8C7B4169DA6CDE93B91B1E1403A1E56_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD8C7B4169DA6CDE93B91B1E1403A1E56.report
Scheduling successful
submit!!!
jobs = 85
day = 151 run = 15151024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151024/*.root.log: No such file or directory
96
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:07:19 PDT] Dataset size is 96 files
Removing files not on site LBL
[2017.09.05 18:07:19 PDT] Dataset size is 96 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:07:19 PDT] Dataset size is 96 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:07:19 PDT] Started with 96 files, current size is 96files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:07:19 PDT] Dataset size is 96 files
----------------------------------------------------
validating dataset ....passed
Writting process 4D7AFB3D37019AB05C0FE148876E5A4C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4D7AFB3D37019AB05C0FE148876E5A4C.report
Scheduling successful
submit!!!
jobs = 85
day = 151 run = 15151038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151038/*.root.log: No such file or directory
159
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:08:30 PDT] Dataset size is 159 files
Removing files not on site LBL
[2017.09.05 18:08:30 PDT] Dataset size is 159 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:08:30 PDT] Dataset size is 159 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:08:30 PDT] Started with 159 files, current size is 159files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:08:30 PDT] Dataset size is 159 files
----------------------------------------------------
validating dataset ....passed
Writting process AABCF8A2E4343B1466A956592D2DCB2B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AABCF8A2E4343B1466A956592D2DCB2B_1... done.
Writting process AABCF8A2E4343B1466A956592D2DCB2B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAABCF8A2E4343B1466A956592D2DCB2B.report
Scheduling successful
submit!!!
jobs = 87
day = 151 run = 15151039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151039/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:09:41 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 18:09:41 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:09:41 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:09:41 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:09:41 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 800720572179BA6F0771281BEC3FEC06_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 800720572179BA6F0771281BEC3FEC06_1... done.
Writting process 800720572179BA6F0771281BEC3FEC06_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched800720572179BA6F0771281BEC3FEC06.report
Scheduling successful
submit!!!
jobs = 87
day = 151 run = 15151040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151040/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:10:52 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 18:10:52 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:10:53 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:10:53 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:10:53 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process 96F8A2849BC14EAF7A25AE870827C7D6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 96F8A2849BC14EAF7A25AE870827C7D6_1... done.
Writting process 96F8A2849BC14EAF7A25AE870827C7D6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched96F8A2849BC14EAF7A25AE870827C7D6.report
Scheduling successful
submit!!!
jobs = 90
day = 151 run = 15151041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151041/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:12:04 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 18:12:04 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:12:04 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:12:04 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:12:04 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process A912C20946A74F9914AE6749F1479F32_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A912C20946A74F9914AE6749F1479F32_1... done.
Writting process A912C20946A74F9914AE6749F1479F32_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA912C20946A74F9914AE6749F1479F32.report
Scheduling successful
submit!!!
jobs = 90
day = 151 run = 15151042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151042/*.root.log: No such file or directory
40
40 40
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:13:11 PDT] Dataset size is 40 files
Removing files not on site LBL
[2017.09.05 18:13:11 PDT] Dataset size is 40 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:13:11 PDT] Dataset size is 40 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:13:12 PDT] Started with 40 files, current size is 40files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=40 ,maxSize=40 )
[2017.09.05 18:13:12 PDT] Dataset size is 40 files
----------------------------------------------------
validating dataset ....passed
Writting process 307CEFA380E98E401938A734F2B74215_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched307CEFA380E98E401938A734F2B74215.report
Scheduling successful
submit!!!
jobs = 88
day = 151 run = 15151044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151044/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:14:23 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 18:14:23 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:14:23 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:14:23 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:14:23 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 8DC99E8350428E74C5181E21DBF36ED7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8DC99E8350428E74C5181E21DBF36ED7_1... done.
Writting process 8DC99E8350428E74C5181E21DBF36ED7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8DC99E8350428E74C5181E21DBF36ED7.report
Scheduling successful
submit!!!
jobs = 88
day = 151 run = 15151045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151045/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:15:34 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 18:15:34 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:15:34 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:15:35 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:15:35 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process 3F5F8E0809DC968C96A9AC7E034BCE5C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3F5F8E0809DC968C96A9AC7E034BCE5C_1... done.
Writting process 3F5F8E0809DC968C96A9AC7E034BCE5C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3F5F8E0809DC968C96A9AC7E034BCE5C.report
Scheduling successful
submit!!!
jobs = 88
day = 151 run = 15151046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151046/*.root.log: No such file or directory
155
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:16:45 PDT] Dataset size is 155 files
Removing files not on site LBL
[2017.09.05 18:16:45 PDT] Dataset size is 155 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:16:45 PDT] Dataset size is 155 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:16:45 PDT] Started with 155 files, current size is 155files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:16:45 PDT] Dataset size is 155 files
----------------------------------------------------
validating dataset ....passed
Writting process 37A08D91B52D5A7BD776F70F00AB2BD2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 37A08D91B52D5A7BD776F70F00AB2BD2_1... done.
Writting process 37A08D91B52D5A7BD776F70F00AB2BD2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched37A08D91B52D5A7BD776F70F00AB2BD2.report
Scheduling successful
submit!!!
jobs = 90
day = 151 run = 15151048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151048/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:17:57 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 18:17:57 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:17:57 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:17:57 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:17:57 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 06980509F25748EA9D861E3823DACCC7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 06980509F25748EA9D861E3823DACCC7_1... done.
Writting process 06980509F25748EA9D861E3823DACCC7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched06980509F25748EA9D861E3823DACCC7.report
Scheduling successful
submit!!!
jobs = 92
day = 151 run = 15151049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151049/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:19:08 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 18:19:08 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:19:08 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:19:08 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:19:08 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process E9340CDEE7ECE3CB1B2173ED42855658_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E9340CDEE7ECE3CB1B2173ED42855658_1... done.
Writting process E9340CDEE7ECE3CB1B2173ED42855658_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE9340CDEE7ECE3CB1B2173ED42855658.report
Scheduling successful
submit!!!
jobs = 94
day = 151 run = 15151050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151050/*.root.log: No such file or directory
50
50 50
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:20:16 PDT] Dataset size is 50 files
Removing files not on site LBL
[2017.09.05 18:20:16 PDT] Dataset size is 50 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:20:16 PDT] Dataset size is 50 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:20:16 PDT] Started with 50 files, current size is 50files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=50 )
[2017.09.05 18:20:16 PDT] Dataset size is 50 files
----------------------------------------------------
validating dataset ....passed
Writting process BC951412B22E19C3F3C099BB682E2932_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBC951412B22E19C3F3C099BB682E2932.report
Scheduling successful
submit!!!
jobs = 91
day = 151 run = 15151051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151051/*.root.log: No such file or directory
46
46 46
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:21:23 PDT] Dataset size is 46 files
Removing files not on site LBL
[2017.09.05 18:21:23 PDT] Dataset size is 46 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:21:23 PDT] Dataset size is 46 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:21:23 PDT] Started with 46 files, current size is 46files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=46 ,maxSize=46 )
[2017.09.05 18:21:23 PDT] Dataset size is 46 files
----------------------------------------------------
validating dataset ....passed
Writting process C83D1B45E980FE94C1F5E109C278BEC5_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC83D1B45E980FE94C1F5E109C278BEC5.report
Scheduling successful
submit!!!
jobs = 90
day = 151 run = 15151052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151052/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:22:36 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.05 18:22:36 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:22:36 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:22:36 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:22:36 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 9777FEB03B7317068B28A3A955FD9D99_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9777FEB03B7317068B28A3A955FD9D99_2... done.
Writting process 9777FEB03B7317068B28A3A955FD9D99_1... done.
Writting process 9777FEB03B7317068B28A3A955FD9D99_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9777FEB03B7317068B28A3A955FD9D99.report
Scheduling successful
submit!!!
jobs = 91
day = 151 run = 15151053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151053/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:23:48 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 18:23:48 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:23:48 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:23:48 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:23:48 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process E139D1E9853304B19F89454F4F929D22_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E139D1E9853304B19F89454F4F929D22_1... done.
Writting process E139D1E9853304B19F89454F4F929D22_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE139D1E9853304B19F89454F4F929D22.report
Scheduling successful
submit!!!
jobs = 93
day = 151 run = 15151054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151054/*.root.log: No such file or directory
200
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:25:00 PDT] Dataset size is 200 files
Removing files not on site LBL
[2017.09.05 18:25:00 PDT] Dataset size is 200 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:25:00 PDT] Dataset size is 200 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:25:00 PDT] Started with 200 files, current size is 200files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:25:00 PDT] Dataset size is 200 files
----------------------------------------------------
validating dataset ....passed
Writting process 190A40BC4E11ECCF9F1336A7A53EC3CC_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 190A40BC4E11ECCF9F1336A7A53EC3CC_2... done.
Writting process 190A40BC4E11ECCF9F1336A7A53EC3CC_1... done.
Writting process 190A40BC4E11ECCF9F1336A7A53EC3CC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched190A40BC4E11ECCF9F1336A7A53EC3CC.report
Scheduling successful
submit!!!
jobs = 94
day = 151 run = 15151055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151055/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:26:11 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 18:26:11 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:26:12 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:26:12 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:26:12 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 4FB5048E4D0ECA0825EE11D7DAC740A8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4FB5048E4D0ECA0825EE11D7DAC740A8_1... done.
Writting process 4FB5048E4D0ECA0825EE11D7DAC740A8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4FB5048E4D0ECA0825EE11D7DAC740A8.report
Scheduling successful
submit!!!
jobs = 94
day = 151 run = 15151056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15151056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15151056/*.root.log: No such file or directory
214
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:27:24 PDT] Dataset size is 214 files
Removing files not on site LBL
[2017.09.05 18:27:24 PDT] Dataset size is 214 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:27:24 PDT] Dataset size is 214 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:27:24 PDT] Started with 214 files, current size is 214files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:27:24 PDT] Dataset size is 214 files
----------------------------------------------------
validating dataset ....passed
Writting process 129CDE85E338DBCAC297E53CD8BB59FD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 129CDE85E338DBCAC297E53CD8BB59FD_2... done.
Writting process 129CDE85E338DBCAC297E53CD8BB59FD_1... done.
Writting process 129CDE85E338DBCAC297E53CD8BB59FD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched129CDE85E338DBCAC297E53CD8BB59FD.report
Scheduling successful
submit!!!
Job submission for day 151 finished!
152
jobs = 92
day = 152 run = 15152003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152003/*.root.log: No such file or directory
61
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:28:32 PDT] Dataset size is 61 files
Removing files not on site LBL
[2017.09.05 18:28:32 PDT] Dataset size is 61 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:28:32 PDT] Dataset size is 61 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:28:32 PDT] Started with 61 files, current size is 61files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:28:33 PDT] Dataset size is 61 files
----------------------------------------------------
validating dataset ....passed
Writting process 05DB212A50EE0735D8088E2C8C78CF4E_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched05DB212A50EE0735D8088E2C8C78CF4E.report
Scheduling successful
submit!!!
jobs = 89
day = 152 run = 15152004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152004/*.root.log: No such file or directory
27
27 27
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:29:39 PDT] Dataset size is 27 files
Removing files not on site LBL
[2017.09.05 18:29:39 PDT] Dataset size is 27 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:29:39 PDT] Dataset size is 27 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:29:39 PDT] Started with 27 files, current size is 27files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=27 ,maxSize=27 )
[2017.09.05 18:29:39 PDT] Dataset size is 27 files
----------------------------------------------------
validating dataset ....passed
Writting process 0C20CB5780E7D3992BA254573B8185E6_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0C20CB5780E7D3992BA254573B8185E6.report
Scheduling successful
submit!!!
jobs = 87
day = 152 run = 15152005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152005/*.root.log: No such file or directory
242
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:30:52 PDT] Dataset size is 242 files
Removing files not on site LBL
[2017.09.05 18:30:53 PDT] Dataset size is 242 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:30:53 PDT] Dataset size is 242 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:30:53 PDT] Started with 242 files, current size is 242files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:30:53 PDT] Dataset size is 242 files
----------------------------------------------------
validating dataset ....passed
Writting process 07A565A53DC4F909EC4380BC3F1050D3_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 07A565A53DC4F909EC4380BC3F1050D3_2... done.
Writting process 07A565A53DC4F909EC4380BC3F1050D3_1... done.
Writting process 07A565A53DC4F909EC4380BC3F1050D3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched07A565A53DC4F909EC4380BC3F1050D3.report
Scheduling successful
submit!!!
jobs = 88
day = 152 run = 15152006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152006/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:32:04 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 18:32:04 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:32:04 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:32:04 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:32:04 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process DE27CE84D473BC9C27D52459C70BCB3D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DE27CE84D473BC9C27D52459C70BCB3D_1... done.
Writting process DE27CE84D473BC9C27D52459C70BCB3D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDE27CE84D473BC9C27D52459C70BCB3D.report
Scheduling successful
submit!!!
jobs = 90
day = 152 run = 15152007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152007/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:33:15 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.05 18:33:15 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:33:15 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:33:15 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:33:15 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 08E62FD59EC6E53524903AEDFD24A068_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 08E62FD59EC6E53524903AEDFD24A068_1... done.
Writting process 08E62FD59EC6E53524903AEDFD24A068_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched08E62FD59EC6E53524903AEDFD24A068.report
Scheduling successful
submit!!!
jobs = 92
day = 152 run = 15152008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152008/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:34:26 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 18:34:26 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:34:27 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:34:27 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:34:27 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process 9822BC0386B761CE3F23B183CE6EEB2D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9822BC0386B761CE3F23B183CE6EEB2D_1... done.
Writting process 9822BC0386B761CE3F23B183CE6EEB2D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9822BC0386B761CE3F23B183CE6EEB2D.report
Scheduling successful
submit!!!
jobs = 93
day = 152 run = 15152009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152009/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:35:38 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 18:35:38 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:35:38 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:35:38 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:35:38 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process FDD138D58CE25108F54D2EE2B0591E2A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FDD138D58CE25108F54D2EE2B0591E2A_1... done.
Writting process FDD138D58CE25108F54D2EE2B0591E2A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFDD138D58CE25108F54D2EE2B0591E2A.report
Scheduling successful
submit!!!
jobs = 93
day = 152 run = 15152010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152010/*.root.log: No such file or directory
192
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:36:50 PDT] Dataset size is 192 files
Removing files not on site LBL
[2017.09.05 18:36:50 PDT] Dataset size is 192 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:36:50 PDT] Dataset size is 192 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:36:50 PDT] Started with 192 files, current size is 192files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:36:50 PDT] Dataset size is 192 files
----------------------------------------------------
validating dataset ....passed
Writting process E5D34F3DE06E975920BCEB306EF8FAC0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E5D34F3DE06E975920BCEB306EF8FAC0_1... done.
Writting process E5D34F3DE06E975920BCEB306EF8FAC0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE5D34F3DE06E975920BCEB306EF8FAC0.report
Scheduling successful
submit!!!
jobs = 93
day = 152 run = 15152011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152011/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:38:01 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.05 18:38:01 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:38:01 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:38:01 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:38:01 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process 527D43C44655C66B6061BCCC8A23E284_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 527D43C44655C66B6061BCCC8A23E284_1... done.
Writting process 527D43C44655C66B6061BCCC8A23E284_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched527D43C44655C66B6061BCCC8A23E284.report
Scheduling successful
submit!!!
jobs = 89
day = 152 run = 15152012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152012/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:39:12 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 18:39:12 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:39:12 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:39:13 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:39:13 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process F7BC6235483950BAAC5EB1F39ADC59A2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F7BC6235483950BAAC5EB1F39ADC59A2_1... done.
Writting process F7BC6235483950BAAC5EB1F39ADC59A2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF7BC6235483950BAAC5EB1F39ADC59A2.report
Scheduling successful
submit!!!
jobs = 85
day = 152 run = 15152013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152013/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:40:24 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 18:40:24 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:40:24 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:40:24 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:40:24 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 56751DBDFC49BF3F655750B4C1BDFB52_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 56751DBDFC49BF3F655750B4C1BDFB52_1... done.
Writting process 56751DBDFC49BF3F655750B4C1BDFB52_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched56751DBDFC49BF3F655750B4C1BDFB52.report
Scheduling successful
submit!!!
jobs = 84
day = 152 run = 15152014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152014/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:41:36 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 18:41:36 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:41:36 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:41:36 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:41:36 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 0B261DEF6E76DAF3DF7EED158446D7C6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0B261DEF6E76DAF3DF7EED158446D7C6_1... done.
Writting process 0B261DEF6E76DAF3DF7EED158446D7C6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0B261DEF6E76DAF3DF7EED158446D7C6.report
Scheduling successful
submit!!!
jobs = 85
day = 152 run = 15152015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152015/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:42:48 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.05 18:42:48 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:42:48 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:42:48 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:42:48 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process 1260FAA4A838608B82B76224F6FEC1FD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1260FAA4A838608B82B76224F6FEC1FD_2... done.
Writting process 1260FAA4A838608B82B76224F6FEC1FD_1... done.
Writting process 1260FAA4A838608B82B76224F6FEC1FD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1260FAA4A838608B82B76224F6FEC1FD.report
Scheduling successful
submit!!!
jobs = 87
day = 152 run = 15152016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152016/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:44:00 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 18:44:00 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:44:00 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:44:00 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:44:00 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process 3002B41BB61FD472805EAB465D5397AF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3002B41BB61FD472805EAB465D5397AF_1... done.
Writting process 3002B41BB61FD472805EAB465D5397AF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3002B41BB61FD472805EAB465D5397AF.report
Scheduling successful
submit!!!
jobs = 86
day = 152 run = 15152017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152017/*.root.log: No such file or directory
196
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:45:12 PDT] Dataset size is 196 files
Removing files not on site LBL
[2017.09.05 18:45:12 PDT] Dataset size is 196 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:45:12 PDT] Dataset size is 196 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:45:12 PDT] Started with 196 files, current size is 196files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:45:12 PDT] Dataset size is 196 files
----------------------------------------------------
validating dataset ....passed
Writting process 9AC0C5897F4998EA4D1D629510E507A0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9AC0C5897F4998EA4D1D629510E507A0_1... done.
Writting process 9AC0C5897F4998EA4D1D629510E507A0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9AC0C5897F4998EA4D1D629510E507A0.report
Scheduling successful
submit!!!
jobs = 84
day = 152 run = 15152018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152018/*.root.log: No such file or directory
147
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:46:23 PDT] Dataset size is 147 files
Removing files not on site LBL
[2017.09.05 18:46:23 PDT] Dataset size is 147 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:46:23 PDT] Dataset size is 147 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:46:23 PDT] Started with 147 files, current size is 147files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:46:23 PDT] Dataset size is 147 files
----------------------------------------------------
validating dataset ....passed
Writting process 449D5A3EDFAD4AA6DBA5152F74AA4262_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 449D5A3EDFAD4AA6DBA5152F74AA4262_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched449D5A3EDFAD4AA6DBA5152F74AA4262.report
Scheduling successful
submit!!!
jobs = 85
day = 152 run = 15152020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152020/*.root.log: No such file or directory
140
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:47:33 PDT] Dataset size is 140 files
Removing files not on site LBL
[2017.09.05 18:47:33 PDT] Dataset size is 140 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:47:33 PDT] Dataset size is 140 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:47:33 PDT] Started with 140 files, current size is 140files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:47:33 PDT] Dataset size is 140 files
----------------------------------------------------
validating dataset ....passed
Writting process 7089C52B8B80FE06AAE200B4CDCD5F29_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7089C52B8B80FE06AAE200B4CDCD5F29_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7089C52B8B80FE06AAE200B4CDCD5F29.report
Scheduling successful
submit!!!
jobs = 84
day = 152 run = 15152038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152038/*.root.log: No such file or directory
169
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:48:44 PDT] Dataset size is 169 files
Removing files not on site LBL
[2017.09.05 18:48:44 PDT] Dataset size is 169 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:48:44 PDT] Dataset size is 169 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:48:45 PDT] Started with 169 files, current size is 169files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:48:45 PDT] Dataset size is 169 files
----------------------------------------------------
validating dataset ....passed
Writting process AD10951231D7A8113727C16782B6FF88_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AD10951231D7A8113727C16782B6FF88_1... done.
Writting process AD10951231D7A8113727C16782B6FF88_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD10951231D7A8113727C16782B6FF88.report
Scheduling successful
submit!!!
jobs = 85
day = 152 run = 15152039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152039/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:49:56 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 18:49:56 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:49:56 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:49:56 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:49:56 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process 2DB40C45BB3CC904FAC096264BF6D327_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2DB40C45BB3CC904FAC096264BF6D327_1... done.
Writting process 2DB40C45BB3CC904FAC096264BF6D327_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2DB40C45BB3CC904FAC096264BF6D327.report
Scheduling successful
submit!!!
jobs = 86
day = 152 run = 15152040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152040/*.root.log: No such file or directory
113
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:51:05 PDT] Dataset size is 113 files
Removing files not on site LBL
[2017.09.05 18:51:05 PDT] Dataset size is 113 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:51:05 PDT] Dataset size is 113 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:51:05 PDT] Started with 113 files, current size is 113files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:51:05 PDT] Dataset size is 113 files
----------------------------------------------------
validating dataset ....passed
Writting process D4D54F5AA89CE72E9427911777DB75AF_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D4D54F5AA89CE72E9427911777DB75AF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD4D54F5AA89CE72E9427911777DB75AF.report
Scheduling successful
submit!!!
jobs = 84
day = 152 run = 15152041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152041/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:52:17 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 18:52:17 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:52:17 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:52:17 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:52:17 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 064F555E798EB96B4E87CF8C52A76C67_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 064F555E798EB96B4E87CF8C52A76C67_1... done.
Writting process 064F555E798EB96B4E87CF8C52A76C67_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched064F555E798EB96B4E87CF8C52A76C67.report
Scheduling successful
submit!!!
jobs = 86
day = 152 run = 15152042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152042/*.root.log: No such file or directory
159
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:53:27 PDT] Dataset size is 159 files
Removing files not on site LBL
[2017.09.05 18:53:28 PDT] Dataset size is 159 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:53:28 PDT] Dataset size is 159 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:53:28 PDT] Started with 159 files, current size is 159files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:53:28 PDT] Dataset size is 159 files
----------------------------------------------------
validating dataset ....passed
Writting process 3F7037A8A602E752B9B8F512B24E9B15_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3F7037A8A602E752B9B8F512B24E9B15_1... done.
Writting process 3F7037A8A602E752B9B8F512B24E9B15_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3F7037A8A602E752B9B8F512B24E9B15.report
Scheduling successful
submit!!!
jobs = 89
day = 152 run = 15152043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152043/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:54:39 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 18:54:39 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:54:39 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:54:39 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:54:40 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process B3B5F123F3402A334718DA57E4D7B0CA_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B3B5F123F3402A334718DA57E4D7B0CA_1... done.
Writting process B3B5F123F3402A334718DA57E4D7B0CA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB3B5F123F3402A334718DA57E4D7B0CA.report
Scheduling successful
submit!!!
jobs = 88
day = 152 run = 15152044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152044/*.root.log: No such file or directory
169
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:55:50 PDT] Dataset size is 169 files
Removing files not on site LBL
[2017.09.05 18:55:51 PDT] Dataset size is 169 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:55:51 PDT] Dataset size is 169 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:55:51 PDT] Started with 169 files, current size is 169files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:55:51 PDT] Dataset size is 169 files
----------------------------------------------------
validating dataset ....passed
Writting process BC638051C6B09700E416AE9B9A1B0D98_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BC638051C6B09700E416AE9B9A1B0D98_1... done.
Writting process BC638051C6B09700E416AE9B9A1B0D98_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBC638051C6B09700E416AE9B9A1B0D98.report
Scheduling successful
submit!!!
jobs = 90
day = 152 run = 15152046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152046/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:57:03 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 18:57:03 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:57:03 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:57:03 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:57:03 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 1963301A8D90FF09DA63FD6AFC6C6774_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1963301A8D90FF09DA63FD6AFC6C6774_1... done.
Writting process 1963301A8D90FF09DA63FD6AFC6C6774_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1963301A8D90FF09DA63FD6AFC6C6774.report
Scheduling successful
submit!!!
jobs = 90
day = 152 run = 15152047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152047/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:58:14 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 18:58:14 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:58:14 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:58:14 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:58:14 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process 68A09D463777679A80E58EED76F19697_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 68A09D463777679A80E58EED76F19697_1... done.
Writting process 68A09D463777679A80E58EED76F19697_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched68A09D463777679A80E58EED76F19697.report
Scheduling successful
submit!!!
jobs = 87
day = 152 run = 15152048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152048/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 18:59:26 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 18:59:26 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 18:59:26 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 18:59:26 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 18:59:26 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process 76C9BD83DACC49200F70190F27BDC504_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 76C9BD83DACC49200F70190F27BDC504_1... done.
Writting process 76C9BD83DACC49200F70190F27BDC504_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched76C9BD83DACC49200F70190F27BDC504.report
Scheduling successful
submit!!!
jobs = 89
day = 152 run = 15152049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152049/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:00:39 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 19:00:39 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:00:39 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:00:39 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:00:39 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process BDC70819B1ACCA1F8BDCCDF46028187D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BDC70819B1ACCA1F8BDCCDF46028187D_1... done.
Writting process BDC70819B1ACCA1F8BDCCDF46028187D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBDC70819B1ACCA1F8BDCCDF46028187D.report
Scheduling successful
submit!!!
jobs = 89
day = 152 run = 15152050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152050/*.root.log: No such file or directory
217
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:01:52 PDT] Dataset size is 217 files
Removing files not on site LBL
[2017.09.05 19:01:52 PDT] Dataset size is 217 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:01:52 PDT] Dataset size is 217 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:01:52 PDT] Started with 217 files, current size is 217files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:01:52 PDT] Dataset size is 217 files
----------------------------------------------------
validating dataset ....passed
Writting process 04DBE552B717626ACF6E6B4CEFDF3C95_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 04DBE552B717626ACF6E6B4CEFDF3C95_2... done.
Writting process 04DBE552B717626ACF6E6B4CEFDF3C95_1... done.
Writting process 04DBE552B717626ACF6E6B4CEFDF3C95_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched04DBE552B717626ACF6E6B4CEFDF3C95.report
Scheduling successful
submit!!!
jobs = 88
day = 152 run = 15152051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152051/*.root.log: No such file or directory
94
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:03:00 PDT] Dataset size is 94 files
Removing files not on site LBL
[2017.09.05 19:03:00 PDT] Dataset size is 94 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:03:00 PDT] Dataset size is 94 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:03:01 PDT] Started with 94 files, current size is 94files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:03:01 PDT] Dataset size is 94 files
----------------------------------------------------
validating dataset ....passed
Writting process FFAA8C896B9774468BE4FF99B5DD78D2_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFFAA8C896B9774468BE4FF99B5DD78D2.report
Scheduling successful
submit!!!
jobs = 88
day = 152 run = 15152052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152052/*.root.log: No such file or directory
222
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:04:13 PDT] Dataset size is 222 files
Removing files not on site LBL
[2017.09.05 19:04:13 PDT] Dataset size is 222 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:04:13 PDT] Dataset size is 222 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:04:13 PDT] Started with 222 files, current size is 222files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:04:13 PDT] Dataset size is 222 files
----------------------------------------------------
validating dataset ....passed
Writting process 509E6FEDC7679D1C41BF3ABF175CE8E2_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 509E6FEDC7679D1C41BF3ABF175CE8E2_2... done.
Writting process 509E6FEDC7679D1C41BF3ABF175CE8E2_1... done.
Writting process 509E6FEDC7679D1C41BF3ABF175CE8E2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched509E6FEDC7679D1C41BF3ABF175CE8E2.report
Scheduling successful
submit!!!
jobs = 90
day = 152 run = 15152053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152053/*.root.log: No such file or directory
200
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:05:24 PDT] Dataset size is 200 files
Removing files not on site LBL
[2017.09.05 19:05:24 PDT] Dataset size is 200 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:05:24 PDT] Dataset size is 200 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:05:25 PDT] Started with 200 files, current size is 200files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:05:25 PDT] Dataset size is 200 files
----------------------------------------------------
validating dataset ....passed
Writting process EE3D9032C151FF3FF2F16116F5D7088C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EE3D9032C151FF3FF2F16116F5D7088C_2... done.
Writting process EE3D9032C151FF3FF2F16116F5D7088C_1... done.
Writting process EE3D9032C151FF3FF2F16116F5D7088C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEE3D9032C151FF3FF2F16116F5D7088C.report
Scheduling successful
submit!!!
jobs = 92
day = 152 run = 15152054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15152054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15152054/*.root.log: No such file or directory
272
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:06:38 PDT] Dataset size is 272 files
Removing files not on site LBL
[2017.09.05 19:06:38 PDT] Dataset size is 272 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:06:38 PDT] Dataset size is 272 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:06:38 PDT] Started with 272 files, current size is 272files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:06:39 PDT] Dataset size is 272 files
----------------------------------------------------
validating dataset ....passed
Writting process C7FA9AB4370CB2EEDA5CFCBBB6644BCB_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C7FA9AB4370CB2EEDA5CFCBBB6644BCB_3... done.
Writting process C7FA9AB4370CB2EEDA5CFCBBB6644BCB_2... done.
Writting process C7FA9AB4370CB2EEDA5CFCBBB6644BCB_1... done.
Writting process C7FA9AB4370CB2EEDA5CFCBBB6644BCB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC7FA9AB4370CB2EEDA5CFCBBB6644BCB.report
Scheduling successful
submit!!!
Job submission for day 152 finished!
153
jobs = 94
day = 153 run = 15153003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153003/*.root.log: No such file or directory
161
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:07:50 PDT] Dataset size is 161 files
Removing files not on site LBL
[2017.09.05 19:07:50 PDT] Dataset size is 161 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:07:50 PDT] Dataset size is 161 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:07:50 PDT] Started with 161 files, current size is 161files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:07:50 PDT] Dataset size is 161 files
----------------------------------------------------
validating dataset ....passed
Writting process 7ED5288146C2A6B6882949D85816EAF7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7ED5288146C2A6B6882949D85816EAF7_1... done.
Writting process 7ED5288146C2A6B6882949D85816EAF7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7ED5288146C2A6B6882949D85816EAF7.report
Scheduling successful
submit!!!
jobs = 94
day = 153 run = 15153004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153004/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:09:01 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 19:09:01 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:09:01 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:09:01 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:09:01 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process BAEC158C00866586BAEAFFE43C7BE604_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BAEC158C00866586BAEAFFE43C7BE604_1... done.
Writting process BAEC158C00866586BAEAFFE43C7BE604_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBAEC158C00866586BAEAFFE43C7BE604.report
Scheduling successful
submit!!!
jobs = 94
day = 153 run = 15153006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153006/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:10:12 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.05 19:10:12 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:10:12 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:10:12 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:10:12 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process 96B8FC1D31F6B051DE664B5A84111687_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 96B8FC1D31F6B051DE664B5A84111687_1... done.
Writting process 96B8FC1D31F6B051DE664B5A84111687_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched96B8FC1D31F6B051DE664B5A84111687.report
Scheduling successful
submit!!!
jobs = 97
day = 153 run = 15153007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153007/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:11:23 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 19:11:23 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:11:23 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:11:23 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:11:23 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process D261A13ACFAC648388FD5436F3C60795_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D261A13ACFAC648388FD5436F3C60795_1... done.
Writting process D261A13ACFAC648388FD5436F3C60795_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD261A13ACFAC648388FD5436F3C60795.report
Scheduling successful
submit!!!
jobs = 100
day = 153 run = 15153008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153008/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:12:34 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 19:12:34 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:12:34 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:12:34 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:12:34 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process F5125E03ECBDE8BEDF398E29E4538E34_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F5125E03ECBDE8BEDF398E29E4538E34_1... done.
Writting process F5125E03ECBDE8BEDF398E29E4538E34_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF5125E03ECBDE8BEDF398E29E4538E34.report
Scheduling successful
submit!!!
jobs = 100
day = 153 run = 15153009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153009/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:13:45 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 19:13:45 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:13:45 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:13:46 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:13:46 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 0118B2BEB68ECA5AE490EEAFA6FC707E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0118B2BEB68ECA5AE490EEAFA6FC707E_1... done.
Writting process 0118B2BEB68ECA5AE490EEAFA6FC707E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0118B2BEB68ECA5AE490EEAFA6FC707E.report
Scheduling successful
submit!!!
jobs = 98
day = 153 run = 15153010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153010/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:14:57 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 19:14:57 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:14:57 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:14:57 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:14:57 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process A76210441276483FD5784081723B8CD2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A76210441276483FD5784081723B8CD2_1... done.
Writting process A76210441276483FD5784081723B8CD2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA76210441276483FD5784081723B8CD2.report
Scheduling successful
submit!!!
jobs = 100
day = 153 run = 15153011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153011/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:16:08 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 19:16:08 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:16:08 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:16:08 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:16:08 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process 9E553A205D00FFBAE4E577225357F009_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9E553A205D00FFBAE4E577225357F009_1... done.
Writting process 9E553A205D00FFBAE4E577225357F009_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9E553A205D00FFBAE4E577225357F009.report
Scheduling successful
submit!!!
jobs = 102
day = 153 run = 15153012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153012/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:17:20 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 19:17:20 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:17:20 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:17:20 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:17:20 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 7AB6E14574E479EF74587A7E67AEBC8E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7AB6E14574E479EF74587A7E67AEBC8E_1... done.
Writting process 7AB6E14574E479EF74587A7E67AEBC8E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7AB6E14574E479EF74587A7E67AEBC8E.report
Scheduling successful
submit!!!
jobs = 97
day = 153 run = 15153013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153013/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:18:32 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 19:18:32 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:18:32 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:18:32 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:18:32 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 625E4F957B7E3BA95854D8B3932CAE2B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 625E4F957B7E3BA95854D8B3932CAE2B_1... done.
Writting process 625E4F957B7E3BA95854D8B3932CAE2B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched625E4F957B7E3BA95854D8B3932CAE2B.report
Scheduling successful
submit!!!
jobs = 97
day = 153 run = 15153014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153014/*.root.log: No such file or directory
208
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:19:44 PDT] Dataset size is 208 files
Removing files not on site LBL
[2017.09.05 19:19:44 PDT] Dataset size is 208 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:19:44 PDT] Dataset size is 208 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:19:44 PDT] Started with 208 files, current size is 208files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:19:44 PDT] Dataset size is 208 files
----------------------------------------------------
validating dataset ....passed
Writting process E39414042D1D1EC4765D92BD2E6C6D34_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E39414042D1D1EC4765D92BD2E6C6D34_2... done.
Writting process E39414042D1D1EC4765D92BD2E6C6D34_1... done.
Writting process E39414042D1D1EC4765D92BD2E6C6D34_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE39414042D1D1EC4765D92BD2E6C6D34.report
Scheduling successful
submit!!!
jobs = 99
day = 153 run = 15153015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153015/*.root.log: No such file or directory
215
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:20:56 PDT] Dataset size is 215 files
Removing files not on site LBL
[2017.09.05 19:20:56 PDT] Dataset size is 215 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:20:56 PDT] Dataset size is 215 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:20:56 PDT] Started with 215 files, current size is 215files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:20:57 PDT] Dataset size is 215 files
----------------------------------------------------
validating dataset ....passed
Writting process 4662915F16F29A7911979D9D5AF1F7C1_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4662915F16F29A7911979D9D5AF1F7C1_2... done.
Writting process 4662915F16F29A7911979D9D5AF1F7C1_1... done.
Writting process 4662915F16F29A7911979D9D5AF1F7C1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4662915F16F29A7911979D9D5AF1F7C1.report
Scheduling successful
submit!!!
jobs = 102
day = 153 run = 15153017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153017/*.root.log: No such file or directory
194
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:22:08 PDT] Dataset size is 194 files
Removing files not on site LBL
[2017.09.05 19:22:08 PDT] Dataset size is 194 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:22:08 PDT] Dataset size is 194 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:22:08 PDT] Started with 194 files, current size is 194files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:22:08 PDT] Dataset size is 194 files
----------------------------------------------------
validating dataset ....passed
Writting process EA505F76425BD2EF80C42AD3781CE251_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EA505F76425BD2EF80C42AD3781CE251_1... done.
Writting process EA505F76425BD2EF80C42AD3781CE251_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEA505F76425BD2EF80C42AD3781CE251.report
Scheduling successful
submit!!!
jobs = 103
day = 153 run = 15153018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153018/*.root.log: No such file or directory
211
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:23:20 PDT] Dataset size is 211 files
Removing files not on site LBL
[2017.09.05 19:23:20 PDT] Dataset size is 211 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:23:20 PDT] Dataset size is 211 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:23:20 PDT] Started with 211 files, current size is 211files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:23:20 PDT] Dataset size is 211 files
----------------------------------------------------
validating dataset ....passed
Writting process AD30E86F3CDD06C9D437572038D1D90C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AD30E86F3CDD06C9D437572038D1D90C_2... done.
Writting process AD30E86F3CDD06C9D437572038D1D90C_1... done.
Writting process AD30E86F3CDD06C9D437572038D1D90C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAD30E86F3CDD06C9D437572038D1D90C.report
Scheduling successful
submit!!!
jobs = 104
day = 153 run = 15153019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153019/*.root.log: No such file or directory
162
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:24:31 PDT] Dataset size is 162 files
Removing files not on site LBL
[2017.09.05 19:24:31 PDT] Dataset size is 162 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:24:31 PDT] Dataset size is 162 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:24:31 PDT] Started with 162 files, current size is 162files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:24:31 PDT] Dataset size is 162 files
----------------------------------------------------
validating dataset ....passed
Writting process 351B088F6797E5BEB9783D95E3D5F243_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 351B088F6797E5BEB9783D95E3D5F243_1... done.
Writting process 351B088F6797E5BEB9783D95E3D5F243_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched351B088F6797E5BEB9783D95E3D5F243.report
Scheduling successful
submit!!!
jobs = 106
day = 153 run = 15153022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153022/*.root.log: No such file or directory
99
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:25:40 PDT] Dataset size is 99 files
Removing files not on site LBL
[2017.09.05 19:25:40 PDT] Dataset size is 99 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:25:40 PDT] Dataset size is 99 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:25:40 PDT] Started with 99 files, current size is 99files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:25:40 PDT] Dataset size is 99 files
----------------------------------------------------
validating dataset ....passed
Writting process E9AB40FE65C31E054755D388410D606C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE9AB40FE65C31E054755D388410D606C.report
Scheduling successful
submit!!!
jobs = 104
day = 153 run = 15153040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153040/*.root.log: No such file or directory
97
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:26:49 PDT] Dataset size is 97 files
Removing files not on site LBL
[2017.09.05 19:26:49 PDT] Dataset size is 97 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:26:49 PDT] Dataset size is 97 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:26:49 PDT] Started with 97 files, current size is 97files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:26:49 PDT] Dataset size is 97 files
----------------------------------------------------
validating dataset ....passed
Writting process 71A53E397EDEE34B555D226605D3E12E_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched71A53E397EDEE34B555D226605D3E12E.report
Scheduling successful
submit!!!
jobs = 101
day = 153 run = 15153041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153041/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:28:00 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 19:28:00 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:28:00 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:28:00 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:28:00 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 4A4FA95B574A15FAB812F7FD8629A379_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4A4FA95B574A15FAB812F7FD8629A379_1... done.
Writting process 4A4FA95B574A15FAB812F7FD8629A379_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4A4FA95B574A15FAB812F7FD8629A379.report
Scheduling successful
submit!!!
jobs = 97
day = 153 run = 15153042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153042/*.root.log: No such file or directory
169
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:29:11 PDT] Dataset size is 169 files
Removing files not on site LBL
[2017.09.05 19:29:11 PDT] Dataset size is 169 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:29:11 PDT] Dataset size is 169 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:29:11 PDT] Started with 169 files, current size is 169files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:29:11 PDT] Dataset size is 169 files
----------------------------------------------------
validating dataset ....passed
Writting process C205B5704C8D56FF4E7D98263A9845F2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C205B5704C8D56FF4E7D98263A9845F2_1... done.
Writting process C205B5704C8D56FF4E7D98263A9845F2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC205B5704C8D56FF4E7D98263A9845F2.report
Scheduling successful
submit!!!
jobs = 95
day = 153 run = 15153043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153043/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:30:22 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 19:30:22 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:30:22 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:30:23 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:30:23 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process 338E450744B4DADF35B6CB2B78D3C88D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 338E450744B4DADF35B6CB2B78D3C88D_1... done.
Writting process 338E450744B4DADF35B6CB2B78D3C88D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched338E450744B4DADF35B6CB2B78D3C88D.report
Scheduling successful
submit!!!
jobs = 95
day = 153 run = 15153044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153044/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:31:34 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 19:31:34 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:31:34 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:31:34 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:31:34 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process DF428C35B072EAB5756716332D91A75E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DF428C35B072EAB5756716332D91A75E_1... done.
Writting process DF428C35B072EAB5756716332D91A75E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDF428C35B072EAB5756716332D91A75E.report
Scheduling successful
submit!!!
jobs = 95
day = 153 run = 15153045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153045/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:32:45 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 19:32:45 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:32:45 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:32:45 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:32:45 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process 0997BFC935A096C025530191C7590EE2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0997BFC935A096C025530191C7590EE2_1... done.
Writting process 0997BFC935A096C025530191C7590EE2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0997BFC935A096C025530191C7590EE2.report
Scheduling successful
submit!!!
jobs = 96
day = 153 run = 15153046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153046/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:33:57 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 19:33:57 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:33:57 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:33:57 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:33:57 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process C8EC85A768E3D072830B90F5CAFDFB74_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C8EC85A768E3D072830B90F5CAFDFB74_1... done.
Writting process C8EC85A768E3D072830B90F5CAFDFB74_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC8EC85A768E3D072830B90F5CAFDFB74.report
Scheduling successful
submit!!!
jobs = 96
day = 153 run = 15153047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153047/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:35:09 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 19:35:09 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:35:09 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:35:10 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:35:10 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process 583994387DC78FF8D65AE2339E5BA553_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 583994387DC78FF8D65AE2339E5BA553_1... done.
Writting process 583994387DC78FF8D65AE2339E5BA553_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched583994387DC78FF8D65AE2339E5BA553.report
Scheduling successful
submit!!!
jobs = 98
day = 153 run = 15153048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153048/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:36:21 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 19:36:21 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:36:21 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:36:21 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:36:21 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process DFB17B097A7246B7E7C4C6DCFA22C5C7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DFB17B097A7246B7E7C4C6DCFA22C5C7_1... done.
Writting process DFB17B097A7246B7E7C4C6DCFA22C5C7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDFB17B097A7246B7E7C4C6DCFA22C5C7.report
Scheduling successful
submit!!!
jobs = 100
day = 153 run = 15153049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153049/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:37:32 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 19:37:32 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:37:32 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:37:32 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:37:33 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 0EB7053E693208285A887CD800800C9E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0EB7053E693208285A887CD800800C9E_1... done.
Writting process 0EB7053E693208285A887CD800800C9E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0EB7053E693208285A887CD800800C9E.report
Scheduling successful
submit!!!
jobs = 100
day = 153 run = 15153050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153050/*.root.log: No such file or directory
53
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:38:40 PDT] Dataset size is 53 files
Removing files not on site LBL
[2017.09.05 19:38:40 PDT] Dataset size is 53 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:38:40 PDT] Dataset size is 53 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:38:40 PDT] Started with 53 files, current size is 53files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:38:40 PDT] Dataset size is 53 files
----------------------------------------------------
validating dataset ....passed
Writting process A7D91EB77DC5C59BE6BD0D75D73377A5_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA7D91EB77DC5C59BE6BD0D75D73377A5.report
Scheduling successful
submit!!!
jobs = 99
day = 153 run = 15153052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153052/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:39:51 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 19:39:51 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:39:51 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:39:51 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:39:51 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process F127E7CCF952B7014D259D3F7884A64E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F127E7CCF952B7014D259D3F7884A64E_1... done.
Writting process F127E7CCF952B7014D259D3F7884A64E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF127E7CCF952B7014D259D3F7884A64E.report
Scheduling successful
submit!!!
jobs = 99
day = 153 run = 15153053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153053/*.root.log: No such file or directory
210
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:41:03 PDT] Dataset size is 210 files
Removing files not on site LBL
[2017.09.05 19:41:03 PDT] Dataset size is 210 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:41:03 PDT] Dataset size is 210 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:41:03 PDT] Started with 210 files, current size is 210files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:41:03 PDT] Dataset size is 210 files
----------------------------------------------------
validating dataset ....passed
Writting process 37BA6A3A1CD25746374A48570B99A81E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 37BA6A3A1CD25746374A48570B99A81E_2... done.
Writting process 37BA6A3A1CD25746374A48570B99A81E_1... done.
Writting process 37BA6A3A1CD25746374A48570B99A81E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched37BA6A3A1CD25746374A48570B99A81E.report
Scheduling successful
submit!!!
jobs = 98
day = 153 run = 15153054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153054/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:42:15 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 19:42:15 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:42:15 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:42:15 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:42:15 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 352DCDFB97A41F923AA4577DD0228579_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 352DCDFB97A41F923AA4577DD0228579_1... done.
Writting process 352DCDFB97A41F923AA4577DD0228579_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched352DCDFB97A41F923AA4577DD0228579.report
Scheduling successful
submit!!!
jobs = 95
day = 153 run = 15153055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153055/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:43:26 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 19:43:26 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:43:26 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:43:26 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:43:26 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process E248E47E05EB203143B23FC8A5EB6F2B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E248E47E05EB203143B23FC8A5EB6F2B_1... done.
Writting process E248E47E05EB203143B23FC8A5EB6F2B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE248E47E05EB203143B23FC8A5EB6F2B.report
Scheduling successful
submit!!!
jobs = 94
day = 153 run = 15153056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153056/*.root.log: No such file or directory
202
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:44:39 PDT] Dataset size is 202 files
Removing files not on site LBL
[2017.09.05 19:44:39 PDT] Dataset size is 202 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:44:39 PDT] Dataset size is 202 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:44:39 PDT] Started with 202 files, current size is 202files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:44:39 PDT] Dataset size is 202 files
----------------------------------------------------
validating dataset ....passed
Writting process B82714DD0E7F15E6CD72132CDC6AA85C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B82714DD0E7F15E6CD72132CDC6AA85C_2... done.
Writting process B82714DD0E7F15E6CD72132CDC6AA85C_1... done.
Writting process B82714DD0E7F15E6CD72132CDC6AA85C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB82714DD0E7F15E6CD72132CDC6AA85C.report
Scheduling successful
submit!!!
jobs = 93
day = 153 run = 15153057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153057/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:45:51 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 19:45:51 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:45:51 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:45:51 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:45:51 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process 905A0C4DBE0EB8E3657BC1461939F54D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 905A0C4DBE0EB8E3657BC1461939F54D_1... done.
Writting process 905A0C4DBE0EB8E3657BC1461939F54D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched905A0C4DBE0EB8E3657BC1461939F54D.report
Scheduling successful
submit!!!
jobs = 93
day = 153 run = 15153058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15153058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15153058/*.root.log: No such file or directory
282
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:47:05 PDT] Dataset size is 282 files
Removing files not on site LBL
[2017.09.05 19:47:05 PDT] Dataset size is 282 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:47:05 PDT] Dataset size is 282 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:47:05 PDT] Started with 282 files, current size is 282files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:47:05 PDT] Dataset size is 282 files
----------------------------------------------------
validating dataset ....passed
Writting process 1892866885C0FBD40A6D6DD91D7C547D_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1892866885C0FBD40A6D6DD91D7C547D_3... done.
Writting process 1892866885C0FBD40A6D6DD91D7C547D_2... done.
Writting process 1892866885C0FBD40A6D6DD91D7C547D_1... done.
Writting process 1892866885C0FBD40A6D6DD91D7C547D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1892866885C0FBD40A6D6DD91D7C547D.report
Scheduling successful
submit!!!
Job submission for day 153 finished!
154
jobs = 96
day = 154 run = 15154001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154001/*.root.log: No such file or directory
211
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:48:17 PDT] Dataset size is 211 files
Removing files not on site LBL
[2017.09.05 19:48:17 PDT] Dataset size is 211 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:48:17 PDT] Dataset size is 211 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:48:17 PDT] Started with 211 files, current size is 211files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:48:17 PDT] Dataset size is 211 files
----------------------------------------------------
validating dataset ....passed
Writting process B3E0209591C0E5556AD24790D8391532_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B3E0209591C0E5556AD24790D8391532_2... done.
Writting process B3E0209591C0E5556AD24790D8391532_1... done.
Writting process B3E0209591C0E5556AD24790D8391532_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB3E0209591C0E5556AD24790D8391532.report
Scheduling successful
submit!!!
jobs = 99
day = 154 run = 15154002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154002/*.root.log: No such file or directory
129
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:49:27 PDT] Dataset size is 129 files
Removing files not on site LBL
[2017.09.05 19:49:27 PDT] Dataset size is 129 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:49:27 PDT] Dataset size is 129 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:49:27 PDT] Started with 129 files, current size is 129files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:49:27 PDT] Dataset size is 129 files
----------------------------------------------------
validating dataset ....passed
Writting process C064D186512A08D3065D55933E4D8A5D_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C064D186512A08D3065D55933E4D8A5D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC064D186512A08D3065D55933E4D8A5D.report
Scheduling successful
submit!!!
jobs = 99
day = 154 run = 15154003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154003/*.root.log: No such file or directory
138
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:50:38 PDT] Dataset size is 138 files
Removing files not on site LBL
[2017.09.05 19:50:38 PDT] Dataset size is 138 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:50:38 PDT] Dataset size is 138 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:50:38 PDT] Started with 138 files, current size is 138files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:50:38 PDT] Dataset size is 138 files
----------------------------------------------------
validating dataset ....passed
Writting process 76B57FBFFEBBDEA6CD7287AF1047D12A_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 76B57FBFFEBBDEA6CD7287AF1047D12A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched76B57FBFFEBBDEA6CD7287AF1047D12A.report
Scheduling successful
submit!!!
jobs = 101
day = 154 run = 15154012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154012/*.root.log: No such file or directory
234
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:51:51 PDT] Dataset size is 234 files
Removing files not on site LBL
[2017.09.05 19:51:51 PDT] Dataset size is 234 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:51:51 PDT] Dataset size is 234 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:51:51 PDT] Started with 234 files, current size is 234files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:51:51 PDT] Dataset size is 234 files
----------------------------------------------------
validating dataset ....passed
Writting process 932662B95913FF75C0F586B7E3E4DB05_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 932662B95913FF75C0F586B7E3E4DB05_2... done.
Writting process 932662B95913FF75C0F586B7E3E4DB05_1... done.
Writting process 932662B95913FF75C0F586B7E3E4DB05_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched932662B95913FF75C0F586B7E3E4DB05.report
Scheduling successful
submit!!!
jobs = 100
day = 154 run = 15154013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154013/*.root.log: No such file or directory
50
50 50
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:52:59 PDT] Dataset size is 50 files
Removing files not on site LBL
[2017.09.05 19:52:59 PDT] Dataset size is 50 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:52:59 PDT] Dataset size is 50 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:52:59 PDT] Started with 50 files, current size is 50files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=50 )
[2017.09.05 19:53:00 PDT] Dataset size is 50 files
----------------------------------------------------
validating dataset ....passed
Writting process D08D2B060A2D372EA16712BF9CD1315C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD08D2B060A2D372EA16712BF9CD1315C.report
Scheduling successful
submit!!!
jobs = 100
day = 154 run = 15154014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154014/*.root.log: No such file or directory
68
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:54:07 PDT] Dataset size is 68 files
Removing files not on site LBL
[2017.09.05 19:54:07 PDT] Dataset size is 68 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:54:07 PDT] Dataset size is 68 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:54:07 PDT] Started with 68 files, current size is 68files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:54:07 PDT] Dataset size is 68 files
----------------------------------------------------
validating dataset ....passed
Writting process 40F049F17E8E80A29B119EFF58571BEC_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched40F049F17E8E80A29B119EFF58571BEC.report
Scheduling successful
submit!!!
jobs = 99
day = 154 run = 15154015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154015/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:55:19 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.05 19:55:19 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:55:19 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:55:19 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:55:19 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process D82D1C0427888EFAE5FD8785869E552C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D82D1C0427888EFAE5FD8785869E552C_2... done.
Writting process D82D1C0427888EFAE5FD8785869E552C_1... done.
Writting process D82D1C0427888EFAE5FD8785869E552C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD82D1C0427888EFAE5FD8785869E552C.report
Scheduling successful
submit!!!
jobs = 98
day = 154 run = 15154016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154016/*.root.log: No such file or directory
237
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:56:32 PDT] Dataset size is 237 files
Removing files not on site LBL
[2017.09.05 19:56:32 PDT] Dataset size is 237 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:56:32 PDT] Dataset size is 237 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:56:32 PDT] Started with 237 files, current size is 237files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:56:32 PDT] Dataset size is 237 files
----------------------------------------------------
validating dataset ....passed
Writting process 3FFE3905252E66C98B7E5366A554FD47_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3FFE3905252E66C98B7E5366A554FD47_2... done.
Writting process 3FFE3905252E66C98B7E5366A554FD47_1... done.
Writting process 3FFE3905252E66C98B7E5366A554FD47_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3FFE3905252E66C98B7E5366A554FD47.report
Scheduling successful
submit!!!
jobs = 98
day = 154 run = 15154017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154017/*.root.log: No such file or directory
254
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:57:45 PDT] Dataset size is 254 files
Removing files not on site LBL
[2017.09.05 19:57:45 PDT] Dataset size is 254 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:57:45 PDT] Dataset size is 254 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:57:45 PDT] Started with 254 files, current size is 254files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:57:45 PDT] Dataset size is 254 files
----------------------------------------------------
validating dataset ....passed
Writting process 0ABE774845275ABED1D86FBA290B9944_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0ABE774845275ABED1D86FBA290B9944_3... done.
Writting process 0ABE774845275ABED1D86FBA290B9944_2... done.
Writting process 0ABE774845275ABED1D86FBA290B9944_1... done.
Writting process 0ABE774845275ABED1D86FBA290B9944_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0ABE774845275ABED1D86FBA290B9944.report
Scheduling successful
submit!!!
jobs = 102
day = 154 run = 15154018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154018/*.root.log: No such file or directory
254
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 19:58:58 PDT] Dataset size is 254 files
Removing files not on site LBL
[2017.09.05 19:58:58 PDT] Dataset size is 254 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 19:58:59 PDT] Dataset size is 254 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 19:58:59 PDT] Started with 254 files, current size is 254files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 19:58:59 PDT] Dataset size is 254 files
----------------------------------------------------
validating dataset ....passed
Writting process 0D683F2DD98B18E9C81D268DDB6A64B6_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0D683F2DD98B18E9C81D268DDB6A64B6_3... done.
Writting process 0D683F2DD98B18E9C81D268DDB6A64B6_2... done.
Writting process 0D683F2DD98B18E9C81D268DDB6A64B6_1... done.
Writting process 0D683F2DD98B18E9C81D268DDB6A64B6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0D683F2DD98B18E9C81D268DDB6A64B6.report
Scheduling successful
submit!!!
jobs = 106
day = 154 run = 15154021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154021/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:00:11 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 20:00:11 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:00:11 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:00:12 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:00:12 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 5009C9B0ECA375BE83CA44DB3E97FCF4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5009C9B0ECA375BE83CA44DB3E97FCF4_1... done.
Writting process 5009C9B0ECA375BE83CA44DB3E97FCF4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5009C9B0ECA375BE83CA44DB3E97FCF4.report
Scheduling successful
submit!!!
jobs = 105
day = 154 run = 15154022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154022/*.root.log: No such file or directory
203
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:01:24 PDT] Dataset size is 203 files
Removing files not on site LBL
[2017.09.05 20:01:24 PDT] Dataset size is 203 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:01:25 PDT] Dataset size is 203 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:01:25 PDT] Started with 203 files, current size is 203files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:01:25 PDT] Dataset size is 203 files
----------------------------------------------------
validating dataset ....passed
Writting process 2C14639630B22F8A57F369423129778B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2C14639630B22F8A57F369423129778B_2... done.
Writting process 2C14639630B22F8A57F369423129778B_1... done.
Writting process 2C14639630B22F8A57F369423129778B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2C14639630B22F8A57F369423129778B.report
Scheduling successful
submit!!!
jobs = 109
day = 154 run = 15154023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154023/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:02:36 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 20:02:36 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:02:36 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:02:36 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:02:36 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 7580F08A6CE08CB704AD7F93C4D73793_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7580F08A6CE08CB704AD7F93C4D73793_1... done.
Writting process 7580F08A6CE08CB704AD7F93C4D73793_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7580F08A6CE08CB704AD7F93C4D73793.report
Scheduling successful
submit!!!
jobs = 111
day = 154 run = 15154024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15154024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15154024/*.root.log: No such file or directory
122
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:03:45 PDT] Dataset size is 122 files
Removing files not on site LBL
[2017.09.05 20:03:46 PDT] Dataset size is 122 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:03:46 PDT] Dataset size is 122 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:03:46 PDT] Started with 122 files, current size is 122files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:03:46 PDT] Dataset size is 122 files
----------------------------------------------------
validating dataset ....passed
Writting process CBE92C175EF286C6F413F1FCFB72E477_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CBE92C175EF286C6F413F1FCFB72E477_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCBE92C175EF286C6F413F1FCFB72E477.report
Scheduling successful
submit!!!
Job submission for day 154 finished!
155
jobs = 110
day = 155 run = 15155010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15155010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15155010/*.root.log: No such file or directory
126
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:04:55 PDT] Dataset size is 126 files
Removing files not on site LBL
[2017.09.05 20:04:55 PDT] Dataset size is 126 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:04:55 PDT] Dataset size is 126 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:04:55 PDT] Started with 126 files, current size is 126files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:04:55 PDT] Dataset size is 126 files
----------------------------------------------------
validating dataset ....passed
Writting process 8507A78216CC82A7FC8EEC32CA37FB07_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8507A78216CC82A7FC8EEC32CA37FB07_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8507A78216CC82A7FC8EEC32CA37FB07.report
Scheduling successful
submit!!!
Job submission for day 155 finished!
156
jobs = 111
day = 156 run = 15156007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156007/*.root.log: No such file or directory
114
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:06:04 PDT] Dataset size is 114 files
Removing files not on site LBL
[2017.09.05 20:06:04 PDT] Dataset size is 114 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:06:04 PDT] Dataset size is 114 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:06:05 PDT] Started with 114 files, current size is 114files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:06:05 PDT] Dataset size is 114 files
----------------------------------------------------
validating dataset ....passed
Writting process 24BC7FA1F81A633C6B699DACAC2F8152_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 24BC7FA1F81A633C6B699DACAC2F8152_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched24BC7FA1F81A633C6B699DACAC2F8152.report
Scheduling successful
submit!!!
jobs = 111
day = 156 run = 15156008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156008/*.root.log: No such file or directory
2
2 2
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:07:11 PDT] Dataset size is 2 files
Removing files not on site LBL
[2017.09.05 20:07:12 PDT] Dataset size is 2 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:07:12 PDT] Dataset size is 2 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:07:12 PDT] Started with 2 files, current size is 2files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=2 ,maxSize=2 )
[2017.09.05 20:07:12 PDT] Dataset size is 2 files
----------------------------------------------------
validating dataset ....passed
Writting process 68AA47BD87E5F4E51D42B982AD3DB4CA_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched68AA47BD87E5F4E51D42B982AD3DB4CA.report
Scheduling successful
submit!!!
jobs = 107
day = 156 run = 15156015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156015/*.root.log: No such file or directory
236
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:08:37 PDT] Dataset size is 236 files
Removing files not on site LBL
[2017.09.05 20:08:40 PDT] Dataset size is 236 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:08:42 PDT] Dataset size is 236 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:08:43 PDT] Started with 236 files, current size is 236files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:08:43 PDT] Dataset size is 236 files
----------------------------------------------------
validating dataset ....passed
Writting process 1A7DE3CA62B76E7815ACDA33D69E2C51_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1A7DE3CA62B76E7815ACDA33D69E2C51_2... done.
Writting process 1A7DE3CA62B76E7815ACDA33D69E2C51_1... done.
Writting process 1A7DE3CA62B76E7815ACDA33D69E2C51_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1A7DE3CA62B76E7815ACDA33D69E2C51.report
Scheduling successful
submit!!!
jobs = 107
day = 156 run = 15156016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156016/*.root.log: No such file or directory
265
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:10:10 PDT] Dataset size is 265 files
Removing files not on site LBL
[2017.09.05 20:10:10 PDT] Dataset size is 265 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:10:10 PDT] Dataset size is 265 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:10:11 PDT] Started with 265 files, current size is 265files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:10:11 PDT] Dataset size is 265 files
----------------------------------------------------
validating dataset ....passed
Writting process E294791FA024BB99F9634E804BCF8F0F_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E294791FA024BB99F9634E804BCF8F0F_3... done.
Writting process E294791FA024BB99F9634E804BCF8F0F_2... done.
Writting process E294791FA024BB99F9634E804BCF8F0F_1... done.
Writting process E294791FA024BB99F9634E804BCF8F0F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE294791FA024BB99F9634E804BCF8F0F.report
Scheduling successful
submit!!!
jobs = 107
day = 156 run = 15156017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156017/*.root.log: No such file or directory
318
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:11:31 PDT] Dataset size is 318 files
Removing files not on site LBL
[2017.09.05 20:11:32 PDT] Dataset size is 318 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:11:33 PDT] Dataset size is 318 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:11:34 PDT] Started with 318 files, current size is 318files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:11:34 PDT] Dataset size is 318 files
----------------------------------------------------
validating dataset ....passed
Writting process 9D38586FBA58D485162F6724EB5029A0_5.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9D38586FBA58D485162F6724EB5029A0_4... done.
Writting process 9D38586FBA58D485162F6724EB5029A0_3... done.
Writting process 9D38586FBA58D485162F6724EB5029A0_2... done.
Writting process 9D38586FBA58D485162F6724EB5029A0_1... done.
Writting process 9D38586FBA58D485162F6724EB5029A0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9D38586FBA58D485162F6724EB5029A0.report
Scheduling successful
submit!!!
jobs = 113
day = 156 run = 15156019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156019/*.root.log: No such file or directory
209
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:12:50 PDT] Dataset size is 209 files
Removing files not on site LBL
[2017.09.05 20:12:50 PDT] Dataset size is 209 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:12:50 PDT] Dataset size is 209 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:12:51 PDT] Started with 209 files, current size is 209files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:12:51 PDT] Dataset size is 209 files
----------------------------------------------------
validating dataset ....passed
Writting process 4F7483B1508E98B34A14FADA6A0B01C9_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4F7483B1508E98B34A14FADA6A0B01C9_2... done.
Writting process 4F7483B1508E98B34A14FADA6A0B01C9_1... done.
Writting process 4F7483B1508E98B34A14FADA6A0B01C9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4F7483B1508E98B34A14FADA6A0B01C9.report
Scheduling successful
submit!!!
jobs = 115
day = 156 run = 15156020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156020/*.root.log: No such file or directory
210
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:14:03 PDT] Dataset size is 210 files
Removing files not on site LBL
[2017.09.05 20:14:03 PDT] Dataset size is 210 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:14:03 PDT] Dataset size is 210 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:14:03 PDT] Started with 210 files, current size is 210files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:14:03 PDT] Dataset size is 210 files
----------------------------------------------------
validating dataset ....passed
Writting process 501F4AABAEB2AAD7108E3CE333B31F97_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 501F4AABAEB2AAD7108E3CE333B31F97_2... done.
Writting process 501F4AABAEB2AAD7108E3CE333B31F97_1... done.
Writting process 501F4AABAEB2AAD7108E3CE333B31F97_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched501F4AABAEB2AAD7108E3CE333B31F97.report
Scheduling successful
submit!!!
jobs = 114
day = 156 run = 15156021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156021/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:15:17 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 20:15:17 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:15:18 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:15:20 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:15:20 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process 4C1D9161F204D21922B7970A337FCC49_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4C1D9161F204D21922B7970A337FCC49_1... done.
Writting process 4C1D9161F204D21922B7970A337FCC49_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4C1D9161F204D21922B7970A337FCC49.report
Scheduling successful
submit!!!
jobs = 114
day = 156 run = 15156022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156022/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:16:36 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 20:16:38 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:16:39 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:16:39 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:16:39 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process D4D1F7F93A815B9A135987F7F6304A24_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D4D1F7F93A815B9A135987F7F6304A24_1... done.
Writting process D4D1F7F93A815B9A135987F7F6304A24_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD4D1F7F93A815B9A135987F7F6304A24.report
Scheduling successful
submit!!!
jobs = 116
day = 156 run = 15156023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156023/*.root.log: No such file or directory
111
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:17:50 PDT] Dataset size is 111 files
Removing files not on site LBL
[2017.09.05 20:17:50 PDT] Dataset size is 111 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:17:50 PDT] Dataset size is 111 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:17:50 PDT] Started with 111 files, current size is 111files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:17:50 PDT] Dataset size is 111 files
----------------------------------------------------
validating dataset ....passed
Writting process 8B23B3934E6D040964E2F0C4595C11A2_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8B23B3934E6D040964E2F0C4595C11A2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8B23B3934E6D040964E2F0C4595C11A2.report
Scheduling successful
submit!!!
jobs = 117
day = 156 run = 15156024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15156024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15156024/*.root.log: No such file or directory
103
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:19:02 PDT] Dataset size is 103 files
Removing files not on site LBL
[2017.09.05 20:19:03 PDT] Dataset size is 103 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:19:04 PDT] Dataset size is 103 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:19:07 PDT] Started with 103 files, current size is 103files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:19:07 PDT] Dataset size is 103 files
----------------------------------------------------
validating dataset ....passed
Writting process 2CF7E747D1165F6E8D970CF18ECB4E56_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2CF7E747D1165F6E8D970CF18ECB4E56_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2CF7E747D1165F6E8D970CF18ECB4E56.report
Scheduling successful
submit!!!
Job submission for day 156 finished!
157
jobs = 118
day = 157 run = 15157011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157011/*.root.log: No such file or directory
275
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:20:22 PDT] Dataset size is 275 files
Removing files not on site LBL
[2017.09.05 20:20:22 PDT] Dataset size is 275 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:20:22 PDT] Dataset size is 275 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:20:23 PDT] Started with 275 files, current size is 275files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:20:23 PDT] Dataset size is 275 files
----------------------------------------------------
validating dataset ....passed
Writting process AA3AA90F252ECCB00A3FF0197BF69C00_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AA3AA90F252ECCB00A3FF0197BF69C00_3... done.
Writting process AA3AA90F252ECCB00A3FF0197BF69C00_2... done.
Writting process AA3AA90F252ECCB00A3FF0197BF69C00_1... done.
Writting process AA3AA90F252ECCB00A3FF0197BF69C00_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAA3AA90F252ECCB00A3FF0197BF69C00.report
Scheduling successful
submit!!!
jobs = 121
day = 157 run = 15157012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157012/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:21:38 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 20:21:38 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:21:39 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:21:40 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:21:40 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process 99489A71EE02275F27E6CAE5DA207B56_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 99489A71EE02275F27E6CAE5DA207B56_1... done.
Writting process 99489A71EE02275F27E6CAE5DA207B56_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched99489A71EE02275F27E6CAE5DA207B56.report
Scheduling successful
submit!!!
jobs = 120
day = 157 run = 15157013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157013/*.root.log: No such file or directory
210
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:22:54 PDT] Dataset size is 210 files
Removing files not on site LBL
[2017.09.05 20:22:54 PDT] Dataset size is 210 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:22:54 PDT] Dataset size is 210 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:22:54 PDT] Started with 210 files, current size is 210files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:22:54 PDT] Dataset size is 210 files
----------------------------------------------------
validating dataset ....passed
Writting process FB297928FE83DD4C8C9E5619BF632EB7_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FB297928FE83DD4C8C9E5619BF632EB7_2... done.
Writting process FB297928FE83DD4C8C9E5619BF632EB7_1... done.
Writting process FB297928FE83DD4C8C9E5619BF632EB7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFB297928FE83DD4C8C9E5619BF632EB7.report
Scheduling successful
submit!!!
jobs = 121
day = 157 run = 15157014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157014/*.root.log: No such file or directory
254
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:24:08 PDT] Dataset size is 254 files
Removing files not on site LBL
[2017.09.05 20:24:08 PDT] Dataset size is 254 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:24:08 PDT] Dataset size is 254 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:24:08 PDT] Started with 254 files, current size is 254files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:24:09 PDT] Dataset size is 254 files
----------------------------------------------------
validating dataset ....passed
Writting process 8DBA401B5495FA2F6799B57210C04A96_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8DBA401B5495FA2F6799B57210C04A96_3... done.
Writting process 8DBA401B5495FA2F6799B57210C04A96_2... done.
Writting process 8DBA401B5495FA2F6799B57210C04A96_1... done.
Writting process 8DBA401B5495FA2F6799B57210C04A96_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8DBA401B5495FA2F6799B57210C04A96.report
Scheduling successful
submit!!!
jobs = 125
day = 157 run = 15157015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157015/*.root.log: No such file or directory
232
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:25:23 PDT] Dataset size is 232 files
Removing files not on site LBL
[2017.09.05 20:25:24 PDT] Dataset size is 232 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:25:24 PDT] Dataset size is 232 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:25:26 PDT] Started with 232 files, current size is 232files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:25:26 PDT] Dataset size is 232 files
----------------------------------------------------
validating dataset ....passed
Writting process FC499B31059ADB4C9A4447F329ACE6D4_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FC499B31059ADB4C9A4447F329ACE6D4_2... done.
Writting process FC499B31059ADB4C9A4447F329ACE6D4_1... done.
Writting process FC499B31059ADB4C9A4447F329ACE6D4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFC499B31059ADB4C9A4447F329ACE6D4.report
Scheduling successful
submit!!!
jobs = 126
day = 157 run = 15157016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157016/*.root.log: No such file or directory
239
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:26:40 PDT] Dataset size is 239 files
Removing files not on site LBL
[2017.09.05 20:26:40 PDT] Dataset size is 239 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:26:40 PDT] Dataset size is 239 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:26:41 PDT] Started with 239 files, current size is 239files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:26:41 PDT] Dataset size is 239 files
----------------------------------------------------
validating dataset ....passed
Writting process 33589C6761DE6D11131CD97CA9154274_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 33589C6761DE6D11131CD97CA9154274_2... done.
Writting process 33589C6761DE6D11131CD97CA9154274_1... done.
Writting process 33589C6761DE6D11131CD97CA9154274_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched33589C6761DE6D11131CD97CA9154274.report
Scheduling successful
submit!!!
jobs = 129
day = 157 run = 15157017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157017/*.root.log: No such file or directory
48
48 48
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:27:48 PDT] Dataset size is 48 files
Removing files not on site LBL
[2017.09.05 20:27:48 PDT] Dataset size is 48 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:27:48 PDT] Dataset size is 48 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:27:48 PDT] Started with 48 files, current size is 48files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=48 ,maxSize=48 )
[2017.09.05 20:27:48 PDT] Dataset size is 48 files
----------------------------------------------------
validating dataset ....passed
Writting process 6284CA7369B0DFE0CCC3780D77FF8808_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6284CA7369B0DFE0CCC3780D77FF8808.report
Scheduling successful
submit!!!
jobs = 127
day = 157 run = 15157020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157020/*.root.log: No such file or directory
47
47 47
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:28:56 PDT] Dataset size is 47 files
Removing files not on site LBL
[2017.09.05 20:28:56 PDT] Dataset size is 47 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:28:56 PDT] Dataset size is 47 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:28:56 PDT] Started with 47 files, current size is 47files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=47 ,maxSize=47 )
[2017.09.05 20:28:56 PDT] Dataset size is 47 files
----------------------------------------------------
validating dataset ....passed
Writting process 9E934F66F4BF9857D6239D47A42C0BE7_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9E934F66F4BF9857D6239D47A42C0BE7.report
Scheduling successful
submit!!!
jobs = 127
day = 157 run = 15157022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157022/*.root.log: No such file or directory
67
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:30:04 PDT] Dataset size is 67 files
Removing files not on site LBL
[2017.09.05 20:30:04 PDT] Dataset size is 67 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:30:04 PDT] Dataset size is 67 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:30:04 PDT] Started with 67 files, current size is 67files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:30:04 PDT] Dataset size is 67 files
----------------------------------------------------
validating dataset ....passed
Writting process BC180753293EB35A1D403A0A93D23657_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBC180753293EB35A1D403A0A93D23657.report
Scheduling successful
submit!!!
jobs = 127
day = 157 run = 15157023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157023/*.root.log: No such file or directory
228
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:31:17 PDT] Dataset size is 228 files
Removing files not on site LBL
[2017.09.05 20:31:17 PDT] Dataset size is 228 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:31:17 PDT] Dataset size is 228 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:31:17 PDT] Started with 228 files, current size is 228files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:31:17 PDT] Dataset size is 228 files
----------------------------------------------------
validating dataset ....passed
Writting process 77F04BC8C17AC4BDCFC903342E6C6832_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 77F04BC8C17AC4BDCFC903342E6C6832_2... done.
Writting process 77F04BC8C17AC4BDCFC903342E6C6832_1... done.
Writting process 77F04BC8C17AC4BDCFC903342E6C6832_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched77F04BC8C17AC4BDCFC903342E6C6832.report
Scheduling successful
submit!!!
jobs = 128
day = 157 run = 15157024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157024/*.root.log: No such file or directory
229
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:32:30 PDT] Dataset size is 229 files
Removing files not on site LBL
[2017.09.05 20:32:30 PDT] Dataset size is 229 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:32:30 PDT] Dataset size is 229 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:32:30 PDT] Started with 229 files, current size is 229files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:32:30 PDT] Dataset size is 229 files
----------------------------------------------------
validating dataset ....passed
Writting process DF41D06C1104446EE455579B6C499218_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DF41D06C1104446EE455579B6C499218_2... done.
Writting process DF41D06C1104446EE455579B6C499218_1... done.
Writting process DF41D06C1104446EE455579B6C499218_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDF41D06C1104446EE455579B6C499218.report
Scheduling successful
submit!!!
jobs = 131
day = 157 run = 15157025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157025/*.root.log: No such file or directory
216
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:33:43 PDT] Dataset size is 216 files
Removing files not on site LBL
[2017.09.05 20:33:43 PDT] Dataset size is 216 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:33:43 PDT] Dataset size is 216 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:33:43 PDT] Started with 216 files, current size is 216files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:33:43 PDT] Dataset size is 216 files
----------------------------------------------------
validating dataset ....passed
Writting process 8DADE040844818B62EC0E95521E680EC_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8DADE040844818B62EC0E95521E680EC_2... done.
Writting process 8DADE040844818B62EC0E95521E680EC_1... done.
Writting process 8DADE040844818B62EC0E95521E680EC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8DADE040844818B62EC0E95521E680EC.report
Scheduling successful
submit!!!
jobs = 130
day = 157 run = 15157028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157028/*.root.log: No such file or directory
209
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:34:56 PDT] Dataset size is 209 files
Removing files not on site LBL
[2017.09.05 20:34:56 PDT] Dataset size is 209 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:34:56 PDT] Dataset size is 209 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:34:56 PDT] Started with 209 files, current size is 209files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:34:56 PDT] Dataset size is 209 files
----------------------------------------------------
validating dataset ....passed
Writting process 4A3CB46224EC0DEEE4772C4756B04666_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4A3CB46224EC0DEEE4772C4756B04666_2... done.
Writting process 4A3CB46224EC0DEEE4772C4756B04666_1... done.
Writting process 4A3CB46224EC0DEEE4772C4756B04666_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4A3CB46224EC0DEEE4772C4756B04666.report
Scheduling successful
submit!!!
jobs = 132
day = 157 run = 15157049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157049/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:36:08 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 20:36:08 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:36:08 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:36:08 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:36:08 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process E1EACFF0FC9A684DCFB7E53067C88590_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E1EACFF0FC9A684DCFB7E53067C88590_1... done.
Writting process E1EACFF0FC9A684DCFB7E53067C88590_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE1EACFF0FC9A684DCFB7E53067C88590.report
Scheduling successful
submit!!!
jobs = 134
day = 157 run = 15157050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157050/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:37:20 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 20:37:20 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:37:20 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:37:20 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:37:20 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 31CE384C625040A7F2311563229C1D1D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 31CE384C625040A7F2311563229C1D1D_1... done.
Writting process 31CE384C625040A7F2311563229C1D1D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched31CE384C625040A7F2311563229C1D1D.report
Scheduling successful
submit!!!
jobs = 134
day = 157 run = 15157051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157051/*.root.log: No such file or directory
181
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:38:32 PDT] Dataset size is 181 files
Removing files not on site LBL
[2017.09.05 20:38:32 PDT] Dataset size is 181 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:38:32 PDT] Dataset size is 181 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:38:32 PDT] Started with 181 files, current size is 181files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:38:32 PDT] Dataset size is 181 files
----------------------------------------------------
validating dataset ....passed
Writting process E71CE0A45A277AF42C13F26A7D3C613D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E71CE0A45A277AF42C13F26A7D3C613D_1... done.
Writting process E71CE0A45A277AF42C13F26A7D3C613D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE71CE0A45A277AF42C13F26A7D3C613D.report
Scheduling successful
submit!!!
jobs = 133
day = 157 run = 15157052
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157052/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157052/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:39:44 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 20:39:44 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:39:44 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:39:44 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:39:44 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process F1EEB6792052642E4B4F062E9D84E3EE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F1EEB6792052642E4B4F062E9D84E3EE_1... done.
Writting process F1EEB6792052642E4B4F062E9D84E3EE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF1EEB6792052642E4B4F062E9D84E3EE.report
Scheduling successful
submit!!!
jobs = 132
day = 157 run = 15157053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157053/*.root.log: No such file or directory
194
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:40:56 PDT] Dataset size is 194 files
Removing files not on site LBL
[2017.09.05 20:40:56 PDT] Dataset size is 194 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:40:56 PDT] Dataset size is 194 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:40:56 PDT] Started with 194 files, current size is 194files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:40:56 PDT] Dataset size is 194 files
----------------------------------------------------
validating dataset ....passed
Writting process 1708F7AD92DF23E969FADA3D3A16FD91_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1708F7AD92DF23E969FADA3D3A16FD91_1... done.
Writting process 1708F7AD92DF23E969FADA3D3A16FD91_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1708F7AD92DF23E969FADA3D3A16FD91.report
Scheduling successful
submit!!!
jobs = 130
day = 157 run = 15157054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157054/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:42:08 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.05 20:42:08 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:42:08 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:42:08 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:42:08 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 8E84AA9AC7B21D6FCD8E5D2B9C9D71A9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8E84AA9AC7B21D6FCD8E5D2B9C9D71A9_1... done.
Writting process 8E84AA9AC7B21D6FCD8E5D2B9C9D71A9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8E84AA9AC7B21D6FCD8E5D2B9C9D71A9.report
Scheduling successful
submit!!!
jobs = 126
day = 157 run = 15157055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157055/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:43:20 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.05 20:43:20 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:43:20 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:43:20 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:43:21 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 2846BC2BF1554D14572A8AF24388A6C4_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2846BC2BF1554D14572A8AF24388A6C4_2... done.
Writting process 2846BC2BF1554D14572A8AF24388A6C4_1... done.
Writting process 2846BC2BF1554D14572A8AF24388A6C4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2846BC2BF1554D14572A8AF24388A6C4.report
Scheduling successful
submit!!!
jobs = 127
day = 157 run = 15157056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157056/*.root.log: No such file or directory
259
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:44:34 PDT] Dataset size is 259 files
Removing files not on site LBL
[2017.09.05 20:44:34 PDT] Dataset size is 259 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:44:34 PDT] Dataset size is 259 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:44:35 PDT] Started with 259 files, current size is 259files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:44:35 PDT] Dataset size is 259 files
----------------------------------------------------
validating dataset ....passed
Writting process 284A2BF8E80139C1315C7423D928E963_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 284A2BF8E80139C1315C7423D928E963_3... done.
Writting process 284A2BF8E80139C1315C7423D928E963_2... done.
Writting process 284A2BF8E80139C1315C7423D928E963_1... done.
Writting process 284A2BF8E80139C1315C7423D928E963_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched284A2BF8E80139C1315C7423D928E963.report
Scheduling successful
submit!!!
jobs = 127
day = 157 run = 15157057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157057/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:45:47 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 20:45:47 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:45:47 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:45:47 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:45:47 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process C62D3A43129455243FFBCD2A5C8CCCFF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C62D3A43129455243FFBCD2A5C8CCCFF_1... done.
Writting process C62D3A43129455243FFBCD2A5C8CCCFF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC62D3A43129455243FFBCD2A5C8CCCFF.report
Scheduling successful
submit!!!
jobs = 126
day = 157 run = 15157058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157058/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:46:58 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 20:46:58 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:46:58 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:46:58 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:46:58 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 0C2C3B198CCCF6B0143C6419DC610243_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0C2C3B198CCCF6B0143C6419DC610243_1... done.
Writting process 0C2C3B198CCCF6B0143C6419DC610243_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0C2C3B198CCCF6B0143C6419DC610243.report
Scheduling successful
submit!!!
jobs = 128
day = 157 run = 15157059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157059/*.root.log: No such file or directory
200
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:48:11 PDT] Dataset size is 200 files
Removing files not on site LBL
[2017.09.05 20:48:11 PDT] Dataset size is 200 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:48:11 PDT] Dataset size is 200 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:48:11 PDT] Started with 200 files, current size is 200files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:48:11 PDT] Dataset size is 200 files
----------------------------------------------------
validating dataset ....passed
Writting process 5D12CD4181D2C67BEED721BB1CCB18A5_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5D12CD4181D2C67BEED721BB1CCB18A5_2... done.
Writting process 5D12CD4181D2C67BEED721BB1CCB18A5_1... done.
Writting process 5D12CD4181D2C67BEED721BB1CCB18A5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5D12CD4181D2C67BEED721BB1CCB18A5.report
Scheduling successful
submit!!!
jobs = 132
day = 157 run = 15157060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157060/*.root.log: No such file or directory
310
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:49:27 PDT] Dataset size is 310 files
Removing files not on site LBL
[2017.09.05 20:49:27 PDT] Dataset size is 310 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:49:27 PDT] Dataset size is 310 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:49:27 PDT] Started with 310 files, current size is 310files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:49:27 PDT] Dataset size is 310 files
----------------------------------------------------
validating dataset ....passed
Writting process FE242785FE8E804EE83037C2C9365CBD_5.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FE242785FE8E804EE83037C2C9365CBD_4... done.
Writting process FE242785FE8E804EE83037C2C9365CBD_3... done.
Writting process FE242785FE8E804EE83037C2C9365CBD_2... done.
Writting process FE242785FE8E804EE83037C2C9365CBD_1... done.
Writting process FE242785FE8E804EE83037C2C9365CBD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFE242785FE8E804EE83037C2C9365CBD.report
Scheduling successful
submit!!!
jobs = 136
day = 157 run = 15157061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15157061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15157061/*.root.log: No such file or directory
287
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:50:42 PDT] Dataset size is 287 files
Removing files not on site LBL
[2017.09.05 20:50:42 PDT] Dataset size is 287 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:50:42 PDT] Dataset size is 287 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:50:42 PDT] Started with 287 files, current size is 287files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:50:42 PDT] Dataset size is 287 files
----------------------------------------------------
validating dataset ....passed
Writting process BC3ECE878C3FFC5C1D2A0237A1E8F7F7_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BC3ECE878C3FFC5C1D2A0237A1E8F7F7_3... done.
Writting process BC3ECE878C3FFC5C1D2A0237A1E8F7F7_2... done.
Writting process BC3ECE878C3FFC5C1D2A0237A1E8F7F7_1... done.
Writting process BC3ECE878C3FFC5C1D2A0237A1E8F7F7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBC3ECE878C3FFC5C1D2A0237A1E8F7F7.report
Scheduling successful
submit!!!
Job submission for day 157 finished!
158
jobs = 137
day = 158 run = 15158001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158001/*.root.log: No such file or directory
102
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:51:52 PDT] Dataset size is 102 files
Removing files not on site LBL
[2017.09.05 20:51:52 PDT] Dataset size is 102 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:51:52 PDT] Dataset size is 102 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:51:52 PDT] Started with 102 files, current size is 102files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:51:52 PDT] Dataset size is 102 files
----------------------------------------------------
validating dataset ....passed
Writting process D4FAD8C0BC184ACEC4925ACBA65D8482_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D4FAD8C0BC184ACEC4925ACBA65D8482_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD4FAD8C0BC184ACEC4925ACBA65D8482.report
Scheduling successful
submit!!!
jobs = 136
day = 158 run = 15158028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158028/*.root.log: No such file or directory
222
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:53:04 PDT] Dataset size is 222 files
Removing files not on site LBL
[2017.09.05 20:53:05 PDT] Dataset size is 222 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:53:05 PDT] Dataset size is 222 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:53:05 PDT] Started with 222 files, current size is 222files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:53:05 PDT] Dataset size is 222 files
----------------------------------------------------
validating dataset ....passed
Writting process DBEBC76E815D8822D3B43D96AE64F0AA_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DBEBC76E815D8822D3B43D96AE64F0AA_2... done.
Writting process DBEBC76E815D8822D3B43D96AE64F0AA_1... done.
Writting process DBEBC76E815D8822D3B43D96AE64F0AA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDBEBC76E815D8822D3B43D96AE64F0AA.report
Scheduling successful
submit!!!
jobs = 138
day = 158 run = 15158029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158029/*.root.log: No such file or directory
269
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:54:19 PDT] Dataset size is 269 files
Removing files not on site LBL
[2017.09.05 20:54:19 PDT] Dataset size is 269 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:54:19 PDT] Dataset size is 269 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:54:19 PDT] Started with 269 files, current size is 269files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:54:19 PDT] Dataset size is 269 files
----------------------------------------------------
validating dataset ....passed
Writting process 116F1F1699D8148E69D948C54AC7A34E_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 116F1F1699D8148E69D948C54AC7A34E_3... done.
Writting process 116F1F1699D8148E69D948C54AC7A34E_2... done.
Writting process 116F1F1699D8148E69D948C54AC7A34E_1... done.
Writting process 116F1F1699D8148E69D948C54AC7A34E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched116F1F1699D8148E69D948C54AC7A34E.report
Scheduling successful
submit!!!
jobs = 138
day = 158 run = 15158031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158031/*.root.log: No such file or directory
59
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:55:27 PDT] Dataset size is 59 files
Removing files not on site LBL
[2017.09.05 20:55:27 PDT] Dataset size is 59 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:55:27 PDT] Dataset size is 59 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:55:27 PDT] Started with 59 files, current size is 59files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:55:27 PDT] Dataset size is 59 files
----------------------------------------------------
validating dataset ....passed
Writting process 9EDC4A4AAE33E0ACF89009EABE1EE3DD_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9EDC4A4AAE33E0ACF89009EABE1EE3DD.report
Scheduling successful
submit!!!
jobs = 136
day = 158 run = 15158032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158032/*.root.log: No such file or directory
80
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:56:35 PDT] Dataset size is 80 files
Removing files not on site LBL
[2017.09.05 20:56:35 PDT] Dataset size is 80 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:56:35 PDT] Dataset size is 80 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:56:36 PDT] Started with 80 files, current size is 80files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:56:36 PDT] Dataset size is 80 files
----------------------------------------------------
validating dataset ....passed
Writting process 6E1DA339D308B0FB47733BB6872EC609_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6E1DA339D308B0FB47733BB6872EC609.report
Scheduling successful
submit!!!
jobs = 134
day = 158 run = 15158033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158033/*.root.log: No such file or directory
313
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:57:51 PDT] Dataset size is 313 files
Removing files not on site LBL
[2017.09.05 20:57:51 PDT] Dataset size is 313 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:57:51 PDT] Dataset size is 313 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:57:51 PDT] Started with 313 files, current size is 313files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:57:51 PDT] Dataset size is 313 files
----------------------------------------------------
validating dataset ....passed
Writting process 8191C5954A1D2646428BC372BAF8F74E_5.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8191C5954A1D2646428BC372BAF8F74E_4... done.
Writting process 8191C5954A1D2646428BC372BAF8F74E_3... done.
Writting process 8191C5954A1D2646428BC372BAF8F74E_2... done.
Writting process 8191C5954A1D2646428BC372BAF8F74E_1... done.
Writting process 8191C5954A1D2646428BC372BAF8F74E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8191C5954A1D2646428BC372BAF8F74E.report
Scheduling successful
submit!!!
jobs = 138
day = 158 run = 15158034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158034/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 20:59:03 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 20:59:03 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 20:59:03 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 20:59:03 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 20:59:03 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process 7749A408F1A20FB1B9E0E1F5F53B66E6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7749A408F1A20FB1B9E0E1F5F53B66E6_1... done.
Writting process 7749A408F1A20FB1B9E0E1F5F53B66E6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7749A408F1A20FB1B9E0E1F5F53B66E6.report
Scheduling successful
submit!!!
jobs = 139
day = 158 run = 15158035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158035/*.root.log: No such file or directory
52
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:00:11 PDT] Dataset size is 52 files
Removing files not on site LBL
[2017.09.05 21:00:11 PDT] Dataset size is 52 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:00:11 PDT] Dataset size is 52 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:00:11 PDT] Started with 52 files, current size is 52files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:00:11 PDT] Dataset size is 52 files
----------------------------------------------------
validating dataset ....passed
Writting process 13090089A5066ADD4A2B3CCE8C564941_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched13090089A5066ADD4A2B3CCE8C564941.report
Scheduling successful
submit!!!
jobs = 139
day = 158 run = 15158036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158036/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:01:23 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 21:01:23 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:01:23 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:01:23 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:01:23 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 13B5E27CFCC9434A0B8E8A8EA5757D15_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 13B5E27CFCC9434A0B8E8A8EA5757D15_1... done.
Writting process 13B5E27CFCC9434A0B8E8A8EA5757D15_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched13B5E27CFCC9434A0B8E8A8EA5757D15.report
Scheduling successful
submit!!!
jobs = 140
day = 158 run = 15158037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158037/*.root.log: No such file or directory
191
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:02:35 PDT] Dataset size is 191 files
Removing files not on site LBL
[2017.09.05 21:02:35 PDT] Dataset size is 191 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:02:35 PDT] Dataset size is 191 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:02:35 PDT] Started with 191 files, current size is 191files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:02:35 PDT] Dataset size is 191 files
----------------------------------------------------
validating dataset ....passed
Writting process FD4C0E893CCC17479A489739CBED1B81_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FD4C0E893CCC17479A489739CBED1B81_1... done.
Writting process FD4C0E893CCC17479A489739CBED1B81_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFD4C0E893CCC17479A489739CBED1B81.report
Scheduling successful
submit!!!
jobs = 137
day = 158 run = 15158038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158038/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:03:47 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 21:03:47 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:03:47 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:03:47 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:03:47 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process 3B1D5370E2EE078285B2C10B64D7841C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3B1D5370E2EE078285B2C10B64D7841C_1... done.
Writting process 3B1D5370E2EE078285B2C10B64D7841C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3B1D5370E2EE078285B2C10B64D7841C.report
Scheduling successful
submit!!!
jobs = 135
day = 158 run = 15158039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158039/*.root.log: No such file or directory
231
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:05:00 PDT] Dataset size is 231 files
Removing files not on site LBL
[2017.09.05 21:05:00 PDT] Dataset size is 231 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:05:00 PDT] Dataset size is 231 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:05:00 PDT] Started with 231 files, current size is 231files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:05:00 PDT] Dataset size is 231 files
----------------------------------------------------
validating dataset ....passed
Writting process ADE34D705A11E9C7F212C1154AB46EEF_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ADE34D705A11E9C7F212C1154AB46EEF_2... done.
Writting process ADE34D705A11E9C7F212C1154AB46EEF_1... done.
Writting process ADE34D705A11E9C7F212C1154AB46EEF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedADE34D705A11E9C7F212C1154AB46EEF.report
Scheduling successful
submit!!!
jobs = 135
day = 158 run = 15158040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158040/*.root.log: No such file or directory
201
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:06:12 PDT] Dataset size is 201 files
Removing files not on site LBL
[2017.09.05 21:06:12 PDT] Dataset size is 201 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:06:12 PDT] Dataset size is 201 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:06:13 PDT] Started with 201 files, current size is 201files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:06:13 PDT] Dataset size is 201 files
----------------------------------------------------
validating dataset ....passed
Writting process 243FBB068AC5E6E35BA5582C30D27946_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 243FBB068AC5E6E35BA5582C30D27946_2... done.
Writting process 243FBB068AC5E6E35BA5582C30D27946_1... done.
Writting process 243FBB068AC5E6E35BA5582C30D27946_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched243FBB068AC5E6E35BA5582C30D27946.report
Scheduling successful
submit!!!
jobs = 137
day = 158 run = 15158062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158062/*.root.log: No such file or directory
158
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:07:23 PDT] Dataset size is 158 files
Removing files not on site LBL
[2017.09.05 21:07:24 PDT] Dataset size is 158 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:07:24 PDT] Dataset size is 158 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:07:24 PDT] Started with 158 files, current size is 158files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:07:24 PDT] Dataset size is 158 files
----------------------------------------------------
validating dataset ....passed
Writting process FBC7C628E8FD88490FDB14DF0598CB4F_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FBC7C628E8FD88490FDB14DF0598CB4F_1... done.
Writting process FBC7C628E8FD88490FDB14DF0598CB4F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFBC7C628E8FD88490FDB14DF0598CB4F.report
Scheduling successful
submit!!!
jobs = 138
day = 158 run = 15158063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158063/*.root.log: No such file or directory
162
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:08:35 PDT] Dataset size is 162 files
Removing files not on site LBL
[2017.09.05 21:08:35 PDT] Dataset size is 162 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:08:35 PDT] Dataset size is 162 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:08:35 PDT] Started with 162 files, current size is 162files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:08:35 PDT] Dataset size is 162 files
----------------------------------------------------
validating dataset ....passed
Writting process FF58044C3180D88AA9EFCD568A2F4CAB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FF58044C3180D88AA9EFCD568A2F4CAB_1... done.
Writting process FF58044C3180D88AA9EFCD568A2F4CAB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFF58044C3180D88AA9EFCD568A2F4CAB.report
Scheduling successful
submit!!!
jobs = 135
day = 158 run = 15158064
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158064/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158064/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:09:46 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.05 21:09:46 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:09:46 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:09:46 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:09:46 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process D71FE74D79B2159BBDA6104E314D2692_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D71FE74D79B2159BBDA6104E314D2692_1... done.
Writting process D71FE74D79B2159BBDA6104E314D2692_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD71FE74D79B2159BBDA6104E314D2692.report
Scheduling successful
submit!!!
jobs = 134
day = 158 run = 15158070
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15158070/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15158070/*.root.log: No such file or directory
220
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:10:59 PDT] Dataset size is 220 files
Removing files not on site LBL
[2017.09.05 21:10:59 PDT] Dataset size is 220 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:10:59 PDT] Dataset size is 220 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:10:59 PDT] Started with 220 files, current size is 220files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:10:59 PDT] Dataset size is 220 files
----------------------------------------------------
validating dataset ....passed
Writting process 57A488694CB24B113F1D0940853EAA9A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 57A488694CB24B113F1D0940853EAA9A_2... done.
Writting process 57A488694CB24B113F1D0940853EAA9A_1... done.
Writting process 57A488694CB24B113F1D0940853EAA9A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched57A488694CB24B113F1D0940853EAA9A.report
Scheduling successful
submit!!!
Job submission for day 158 finished!
159
jobs = 136
day = 159 run = 15159001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159001/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:12:11 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 21:12:11 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:12:11 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:12:11 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:12:11 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 43CE29F0322CC65E3233E95714CEAF1E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 43CE29F0322CC65E3233E95714CEAF1E_1... done.
Writting process 43CE29F0322CC65E3233E95714CEAF1E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched43CE29F0322CC65E3233E95714CEAF1E.report
Scheduling successful
submit!!!
jobs = 137
day = 159 run = 15159002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159002/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:13:23 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 21:13:23 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:13:23 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:13:23 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:13:23 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 37BF0580C7B77D56CC6FB27364189813_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 37BF0580C7B77D56CC6FB27364189813_1... done.
Writting process 37BF0580C7B77D56CC6FB27364189813_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched37BF0580C7B77D56CC6FB27364189813.report
Scheduling successful
submit!!!
jobs = 137
day = 159 run = 15159003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159003/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:14:34 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 21:14:34 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:14:34 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:14:34 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:14:34 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process 4D3AAF2132AE980CC9A82B50F4E29187_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4D3AAF2132AE980CC9A82B50F4E29187_1... done.
Writting process 4D3AAF2132AE980CC9A82B50F4E29187_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4D3AAF2132AE980CC9A82B50F4E29187.report
Scheduling successful
submit!!!
jobs = 132
day = 159 run = 15159004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159004/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:15:46 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 21:15:46 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:15:46 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:15:46 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:15:46 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process 4D9813B54CA4574EDE6C18E23A26091A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4D9813B54CA4574EDE6C18E23A26091A_1... done.
Writting process 4D9813B54CA4574EDE6C18E23A26091A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4D9813B54CA4574EDE6C18E23A26091A.report
Scheduling successful
submit!!!
jobs = 131
day = 159 run = 15159005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159005/*.root.log: No such file or directory
209
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:16:58 PDT] Dataset size is 209 files
Removing files not on site LBL
[2017.09.05 21:16:58 PDT] Dataset size is 209 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:16:58 PDT] Dataset size is 209 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:16:58 PDT] Started with 209 files, current size is 209files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:16:58 PDT] Dataset size is 209 files
----------------------------------------------------
validating dataset ....passed
Writting process 673202FEAED35937A93F6950F7E667D4_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 673202FEAED35937A93F6950F7E667D4_2... done.
Writting process 673202FEAED35937A93F6950F7E667D4_1... done.
Writting process 673202FEAED35937A93F6950F7E667D4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched673202FEAED35937A93F6950F7E667D4.report
Scheduling successful
submit!!!
jobs = 132
day = 159 run = 15159006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159006/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:18:11 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.05 21:18:11 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:18:11 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:18:11 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:18:11 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 35C51B0AB1EF6560432E364F36336390_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 35C51B0AB1EF6560432E364F36336390_2... done.
Writting process 35C51B0AB1EF6560432E364F36336390_1... done.
Writting process 35C51B0AB1EF6560432E364F36336390_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched35C51B0AB1EF6560432E364F36336390.report
Scheduling successful
submit!!!
jobs = 134
day = 159 run = 15159007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159007/*.root.log: No such file or directory
211
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:19:23 PDT] Dataset size is 211 files
Removing files not on site LBL
[2017.09.05 21:19:24 PDT] Dataset size is 211 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:19:24 PDT] Dataset size is 211 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:19:24 PDT] Started with 211 files, current size is 211files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:19:24 PDT] Dataset size is 211 files
----------------------------------------------------
validating dataset ....passed
Writting process 783F677E871CFC18116A215C722EF0A5_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 783F677E871CFC18116A215C722EF0A5_2... done.
Writting process 783F677E871CFC18116A215C722EF0A5_1... done.
Writting process 783F677E871CFC18116A215C722EF0A5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched783F677E871CFC18116A215C722EF0A5.report
Scheduling successful
submit!!!
jobs = 134
day = 159 run = 15159008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159008/*.root.log: No such file or directory
261
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:20:38 PDT] Dataset size is 261 files
Removing files not on site LBL
[2017.09.05 21:20:38 PDT] Dataset size is 261 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:20:38 PDT] Dataset size is 261 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:20:38 PDT] Started with 261 files, current size is 261files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:20:38 PDT] Dataset size is 261 files
----------------------------------------------------
validating dataset ....passed
Writting process B43F574B4BF90E1C1AE25B7751B2F08A_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B43F574B4BF90E1C1AE25B7751B2F08A_3... done.
Writting process B43F574B4BF90E1C1AE25B7751B2F08A_2... done.
Writting process B43F574B4BF90E1C1AE25B7751B2F08A_1... done.
Writting process B43F574B4BF90E1C1AE25B7751B2F08A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB43F574B4BF90E1C1AE25B7751B2F08A.report
Scheduling successful
submit!!!
jobs = 137
day = 159 run = 15159009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159009/*.root.log: No such file or directory
347
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:21:55 PDT] Dataset size is 347 files
Removing files not on site LBL
[2017.09.05 21:21:55 PDT] Dataset size is 347 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:21:55 PDT] Dataset size is 347 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:21:55 PDT] Started with 347 files, current size is 347files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:21:55 PDT] Dataset size is 347 files
----------------------------------------------------
validating dataset ....passed
Writting process 5715228DF0F446346D3299546D395E25_5.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5715228DF0F446346D3299546D395E25_4... done.
Writting process 5715228DF0F446346D3299546D395E25_3... done.
Writting process 5715228DF0F446346D3299546D395E25_2... done.
Writting process 5715228DF0F446346D3299546D395E25_1... done.
Writting process 5715228DF0F446346D3299546D395E25_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5715228DF0F446346D3299546D395E25.report
Scheduling successful
submit!!!
jobs = 142
day = 159 run = 15159021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159021/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:23:07 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 21:23:07 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:23:07 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:23:07 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:23:07 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process FEAEEC57603459136D2D9157980ED73D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FEAEEC57603459136D2D9157980ED73D_1... done.
Writting process FEAEEC57603459136D2D9157980ED73D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFEAEEC57603459136D2D9157980ED73D.report
Scheduling successful
submit!!!
jobs = 143
day = 159 run = 15159024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159024/*.root.log: No such file or directory
248
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:24:20 PDT] Dataset size is 248 files
Removing files not on site LBL
[2017.09.05 21:24:21 PDT] Dataset size is 248 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:24:21 PDT] Dataset size is 248 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:24:21 PDT] Started with 248 files, current size is 248files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:24:21 PDT] Dataset size is 248 files
----------------------------------------------------
validating dataset ....passed
Writting process 0887E61F90D7671647B8D996F26B325E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0887E61F90D7671647B8D996F26B325E_2... done.
Writting process 0887E61F90D7671647B8D996F26B325E_1... done.
Writting process 0887E61F90D7671647B8D996F26B325E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0887E61F90D7671647B8D996F26B325E.report
Scheduling successful
submit!!!
jobs = 142
day = 159 run = 15159025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159025/*.root.log: No such file or directory
224
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:25:33 PDT] Dataset size is 224 files
Removing files not on site LBL
[2017.09.05 21:25:33 PDT] Dataset size is 224 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:25:33 PDT] Dataset size is 224 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:25:34 PDT] Started with 224 files, current size is 224files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:25:34 PDT] Dataset size is 224 files
----------------------------------------------------
validating dataset ....passed
Writting process 7B3C1B71C833F78D79895112E813E5AA_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7B3C1B71C833F78D79895112E813E5AA_2... done.
Writting process 7B3C1B71C833F78D79895112E813E5AA_1... done.
Writting process 7B3C1B71C833F78D79895112E813E5AA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7B3C1B71C833F78D79895112E813E5AA.report
Scheduling successful
submit!!!
jobs = 143
day = 159 run = 15159026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159026/*.root.log: No such file or directory
259
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:26:48 PDT] Dataset size is 259 files
Removing files not on site LBL
[2017.09.05 21:26:48 PDT] Dataset size is 259 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:26:48 PDT] Dataset size is 259 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:26:48 PDT] Started with 259 files, current size is 259files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:26:48 PDT] Dataset size is 259 files
----------------------------------------------------
validating dataset ....passed
Writting process 53076F5FA5AA7650C8836BDEEE1974AE_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 53076F5FA5AA7650C8836BDEEE1974AE_3... done.
Writting process 53076F5FA5AA7650C8836BDEEE1974AE_2... done.
Writting process 53076F5FA5AA7650C8836BDEEE1974AE_1... done.
Writting process 53076F5FA5AA7650C8836BDEEE1974AE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched53076F5FA5AA7650C8836BDEEE1974AE.report
Scheduling successful
submit!!!
jobs = 141
day = 159 run = 15159027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159027/*.root.log: No such file or directory
255
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:28:02 PDT] Dataset size is 255 files
Removing files not on site LBL
[2017.09.05 21:28:02 PDT] Dataset size is 255 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:28:02 PDT] Dataset size is 255 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:28:02 PDT] Started with 255 files, current size is 255files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:28:02 PDT] Dataset size is 255 files
----------------------------------------------------
validating dataset ....passed
Writting process 277EFE714399CF16C9B593C2EE36D7A5_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 277EFE714399CF16C9B593C2EE36D7A5_3... done.
Writting process 277EFE714399CF16C9B593C2EE36D7A5_2... done.
Writting process 277EFE714399CF16C9B593C2EE36D7A5_1... done.
Writting process 277EFE714399CF16C9B593C2EE36D7A5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched277EFE714399CF16C9B593C2EE36D7A5.report
Scheduling successful
submit!!!
jobs = 145
day = 159 run = 15159028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159028/*.root.log: No such file or directory
218
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:29:15 PDT] Dataset size is 218 files
Removing files not on site LBL
[2017.09.05 21:29:15 PDT] Dataset size is 218 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:29:15 PDT] Dataset size is 218 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:29:15 PDT] Started with 218 files, current size is 218files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:29:15 PDT] Dataset size is 218 files
----------------------------------------------------
validating dataset ....passed
Writting process E612AAC1B5F602F2BC0ABB7370A6FDDD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E612AAC1B5F602F2BC0ABB7370A6FDDD_2... done.
Writting process E612AAC1B5F602F2BC0ABB7370A6FDDD_1... done.
Writting process E612AAC1B5F602F2BC0ABB7370A6FDDD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE612AAC1B5F602F2BC0ABB7370A6FDDD.report
Scheduling successful
submit!!!
jobs = 148
day = 159 run = 15159029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159029/*.root.log: No such file or directory
200
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:30:27 PDT] Dataset size is 200 files
Removing files not on site LBL
[2017.09.05 21:30:27 PDT] Dataset size is 200 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:30:27 PDT] Dataset size is 200 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:30:27 PDT] Started with 200 files, current size is 200files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:30:27 PDT] Dataset size is 200 files
----------------------------------------------------
validating dataset ....passed
Writting process 4A5464A855E0B7FD9F897F383D85562F_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4A5464A855E0B7FD9F897F383D85562F_2... done.
Writting process 4A5464A855E0B7FD9F897F383D85562F_1... done.
Writting process 4A5464A855E0B7FD9F897F383D85562F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4A5464A855E0B7FD9F897F383D85562F.report
Scheduling successful
submit!!!
jobs = 151
day = 159 run = 15159030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159030/*.root.log: No such file or directory
214
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:31:40 PDT] Dataset size is 214 files
Removing files not on site LBL
[2017.09.05 21:31:40 PDT] Dataset size is 214 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:31:40 PDT] Dataset size is 214 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:31:40 PDT] Started with 214 files, current size is 214files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:31:40 PDT] Dataset size is 214 files
----------------------------------------------------
validating dataset ....passed
Writting process 18E0375D7E8E10439C4728BB07B9D097_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 18E0375D7E8E10439C4728BB07B9D097_2... done.
Writting process 18E0375D7E8E10439C4728BB07B9D097_1... done.
Writting process 18E0375D7E8E10439C4728BB07B9D097_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched18E0375D7E8E10439C4728BB07B9D097.report
Scheduling successful
submit!!!
jobs = 155
day = 159 run = 15159031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159031/*.root.log: No such file or directory
217
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:32:53 PDT] Dataset size is 217 files
Removing files not on site LBL
[2017.09.05 21:32:53 PDT] Dataset size is 217 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:32:53 PDT] Dataset size is 217 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:32:53 PDT] Started with 217 files, current size is 217files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:32:53 PDT] Dataset size is 217 files
----------------------------------------------------
validating dataset ....passed
Writting process A7BA5701F375635780202942EE48E175_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A7BA5701F375635780202942EE48E175_2... done.
Writting process A7BA5701F375635780202942EE48E175_1... done.
Writting process A7BA5701F375635780202942EE48E175_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA7BA5701F375635780202942EE48E175.report
Scheduling successful
submit!!!
jobs = 154
day = 159 run = 15159032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159032/*.root.log: No such file or directory
224
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:34:06 PDT] Dataset size is 224 files
Removing files not on site LBL
[2017.09.05 21:34:06 PDT] Dataset size is 224 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:34:06 PDT] Dataset size is 224 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:34:06 PDT] Started with 224 files, current size is 224files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:34:06 PDT] Dataset size is 224 files
----------------------------------------------------
validating dataset ....passed
Writting process 35CE60364EF50D1C05693F6BA8A0A855_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 35CE60364EF50D1C05693F6BA8A0A855_2... done.
Writting process 35CE60364EF50D1C05693F6BA8A0A855_1... done.
Writting process 35CE60364EF50D1C05693F6BA8A0A855_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched35CE60364EF50D1C05693F6BA8A0A855.report
Scheduling successful
submit!!!
jobs = 155
day = 159 run = 15159033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159033/*.root.log: No such file or directory
201
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:35:18 PDT] Dataset size is 201 files
Removing files not on site LBL
[2017.09.05 21:35:18 PDT] Dataset size is 201 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:35:18 PDT] Dataset size is 201 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:35:18 PDT] Started with 201 files, current size is 201files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:35:18 PDT] Dataset size is 201 files
----------------------------------------------------
validating dataset ....passed
Writting process AA07B4CB622F216F4EC63F2EF82F295A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AA07B4CB622F216F4EC63F2EF82F295A_2... done.
Writting process AA07B4CB622F216F4EC63F2EF82F295A_1... done.
Writting process AA07B4CB622F216F4EC63F2EF82F295A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAA07B4CB622F216F4EC63F2EF82F295A.report
Scheduling successful
submit!!!
jobs = 156
day = 159 run = 15159034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159034/*.root.log: No such file or directory
222
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:36:31 PDT] Dataset size is 222 files
Removing files not on site LBL
[2017.09.05 21:36:31 PDT] Dataset size is 222 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:36:31 PDT] Dataset size is 222 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:36:31 PDT] Started with 222 files, current size is 222files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:36:31 PDT] Dataset size is 222 files
----------------------------------------------------
validating dataset ....passed
Writting process DC7C159F05B3C4086E8DB4F13F51A8B6_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DC7C159F05B3C4086E8DB4F13F51A8B6_2... done.
Writting process DC7C159F05B3C4086E8DB4F13F51A8B6_1... done.
Writting process DC7C159F05B3C4086E8DB4F13F51A8B6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDC7C159F05B3C4086E8DB4F13F51A8B6.report
Scheduling successful
submit!!!
jobs = 157
day = 159 run = 15159035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159035/*.root.log: No such file or directory
209
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:37:43 PDT] Dataset size is 209 files
Removing files not on site LBL
[2017.09.05 21:37:43 PDT] Dataset size is 209 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:37:43 PDT] Dataset size is 209 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:37:44 PDT] Started with 209 files, current size is 209files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:37:44 PDT] Dataset size is 209 files
----------------------------------------------------
validating dataset ....passed
Writting process 7E324B193687D01ADEA0C28664340F2F_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7E324B193687D01ADEA0C28664340F2F_2... done.
Writting process 7E324B193687D01ADEA0C28664340F2F_1... done.
Writting process 7E324B193687D01ADEA0C28664340F2F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7E324B193687D01ADEA0C28664340F2F.report
Scheduling successful
submit!!!
jobs = 156
day = 159 run = 15159036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159036/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:38:56 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.05 21:38:56 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:38:56 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:38:56 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:38:56 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process AAE30A022E314C54FAD5D1A507BC058B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AAE30A022E314C54FAD5D1A507BC058B_2... done.
Writting process AAE30A022E314C54FAD5D1A507BC058B_1... done.
Writting process AAE30A022E314C54FAD5D1A507BC058B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAAE30A022E314C54FAD5D1A507BC058B.report
Scheduling successful
submit!!!
jobs = 159
day = 159 run = 15159045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159045/*.root.log: No such file or directory
190
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:40:08 PDT] Dataset size is 190 files
Removing files not on site LBL
[2017.09.05 21:40:08 PDT] Dataset size is 190 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:40:08 PDT] Dataset size is 190 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:40:08 PDT] Started with 190 files, current size is 190files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:40:08 PDT] Dataset size is 190 files
----------------------------------------------------
validating dataset ....passed
Writting process 0ADF308C618CE572759F8E0E76650B84_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0ADF308C618CE572759F8E0E76650B84_1... done.
Writting process 0ADF308C618CE572759F8E0E76650B84_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0ADF308C618CE572759F8E0E76650B84.report
Scheduling successful
submit!!!
jobs = 152
day = 159 run = 15159046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159046/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:41:20 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 21:41:20 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:41:20 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:41:20 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:41:20 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process 6D6B0B90452374955BC99204CD5993B2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6D6B0B90452374955BC99204CD5993B2_1... done.
Writting process 6D6B0B90452374955BC99204CD5993B2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6D6B0B90452374955BC99204CD5993B2.report
Scheduling successful
submit!!!
jobs = 152
day = 159 run = 15159049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159049/*.root.log: No such file or directory
59
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:42:27 PDT] Dataset size is 59 files
Removing files not on site LBL
[2017.09.05 21:42:27 PDT] Dataset size is 59 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:42:28 PDT] Dataset size is 59 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:42:28 PDT] Started with 59 files, current size is 59files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:42:28 PDT] Dataset size is 59 files
----------------------------------------------------
validating dataset ....passed
Writting process F65431C2EBF0B099D9304ED2B71549A0_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF65431C2EBF0B099D9304ED2B71549A0.report
Scheduling successful
submit!!!
jobs = 150
day = 159 run = 15159051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159051/*.root.log: No such file or directory
41
41 41
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:43:35 PDT] Dataset size is 41 files
Removing files not on site LBL
[2017.09.05 21:43:35 PDT] Dataset size is 41 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:43:35 PDT] Dataset size is 41 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:43:35 PDT] Started with 41 files, current size is 41files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=41 ,maxSize=41 )
[2017.09.05 21:43:35 PDT] Dataset size is 41 files
----------------------------------------------------
validating dataset ....passed
Writting process 6D8B985E6CD2C51A174F6EEA84F33EBF_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6D8B985E6CD2C51A174F6EEA84F33EBF.report
Scheduling successful
submit!!!
jobs = 146
day = 159 run = 15159054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159054/*.root.log: No such file or directory
76
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:44:43 PDT] Dataset size is 76 files
Removing files not on site LBL
[2017.09.05 21:44:43 PDT] Dataset size is 76 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:44:43 PDT] Dataset size is 76 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:44:43 PDT] Started with 76 files, current size is 76files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:44:43 PDT] Dataset size is 76 files
----------------------------------------------------
validating dataset ....passed
Writting process 3371B7527C86A5F0C3C352A6D3E582BD_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3371B7527C86A5F0C3C352A6D3E582BD.report
Scheduling successful
submit!!!
jobs = 141
day = 159 run = 15159055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15159055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15159055/*.root.log: No such file or directory
260
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:45:57 PDT] Dataset size is 260 files
Removing files not on site LBL
[2017.09.05 21:45:57 PDT] Dataset size is 260 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:45:57 PDT] Dataset size is 260 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:45:57 PDT] Started with 260 files, current size is 260files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:45:57 PDT] Dataset size is 260 files
----------------------------------------------------
validating dataset ....passed
Writting process D60F09C93214F052D8B0A7231F85F207_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D60F09C93214F052D8B0A7231F85F207_3... done.
Writting process D60F09C93214F052D8B0A7231F85F207_2... done.
Writting process D60F09C93214F052D8B0A7231F85F207_1... done.
Writting process D60F09C93214F052D8B0A7231F85F207_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD60F09C93214F052D8B0A7231F85F207.report
Scheduling successful
submit!!!
Job submission for day 159 finished!
160
jobs = 142
day = 160 run = 15160001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160001/*.root.log: No such file or directory
316
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:47:13 PDT] Dataset size is 316 files
Removing files not on site LBL
[2017.09.05 21:47:13 PDT] Dataset size is 316 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:47:13 PDT] Dataset size is 316 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:47:14 PDT] Started with 316 files, current size is 316files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:47:14 PDT] Dataset size is 316 files
----------------------------------------------------
validating dataset ....passed
Writting process 851C31C51905A632345DCB99D5306BBF_5.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 851C31C51905A632345DCB99D5306BBF_4... done.
Writting process 851C31C51905A632345DCB99D5306BBF_3... done.
Writting process 851C31C51905A632345DCB99D5306BBF_2... done.
Writting process 851C31C51905A632345DCB99D5306BBF_1... done.
Writting process 851C31C51905A632345DCB99D5306BBF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched851C31C51905A632345DCB99D5306BBF.report
Scheduling successful
submit!!!
jobs = 139
day = 160 run = 15160002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160002/*.root.log: No such file or directory
211
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:48:26 PDT] Dataset size is 211 files
Removing files not on site LBL
[2017.09.05 21:48:26 PDT] Dataset size is 211 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:48:26 PDT] Dataset size is 211 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:48:26 PDT] Started with 211 files, current size is 211files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:48:26 PDT] Dataset size is 211 files
----------------------------------------------------
validating dataset ....passed
Writting process 7271E190F0AFF673EDBDC6283D09C412_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7271E190F0AFF673EDBDC6283D09C412_2... done.
Writting process 7271E190F0AFF673EDBDC6283D09C412_1... done.
Writting process 7271E190F0AFF673EDBDC6283D09C412_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7271E190F0AFF673EDBDC6283D09C412.report
Scheduling successful
submit!!!
jobs = 141
day = 160 run = 15160003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160003/*.root.log: No such file or directory
257
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:49:39 PDT] Dataset size is 257 files
Removing files not on site LBL
[2017.09.05 21:49:39 PDT] Dataset size is 257 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:49:40 PDT] Dataset size is 257 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:49:40 PDT] Started with 257 files, current size is 257files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:49:40 PDT] Dataset size is 257 files
----------------------------------------------------
validating dataset ....passed
Writting process AFE4D7FF62E09C8B89E058016CCDB206_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AFE4D7FF62E09C8B89E058016CCDB206_3... done.
Writting process AFE4D7FF62E09C8B89E058016CCDB206_2... done.
Writting process AFE4D7FF62E09C8B89E058016CCDB206_1... done.
Writting process AFE4D7FF62E09C8B89E058016CCDB206_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAFE4D7FF62E09C8B89E058016CCDB206.report
Scheduling successful
submit!!!
jobs = 145
day = 160 run = 15160004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160004/*.root.log: No such file or directory
310
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:50:55 PDT] Dataset size is 310 files
Removing files not on site LBL
[2017.09.05 21:50:55 PDT] Dataset size is 310 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:50:55 PDT] Dataset size is 310 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:50:55 PDT] Started with 310 files, current size is 310files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:50:56 PDT] Dataset size is 310 files
----------------------------------------------------
validating dataset ....passed
Writting process AC04B0EE77B032AEADFD1118BF24B467_5.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AC04B0EE77B032AEADFD1118BF24B467_4... done.
Writting process AC04B0EE77B032AEADFD1118BF24B467_3... done.
Writting process AC04B0EE77B032AEADFD1118BF24B467_2... done.
Writting process AC04B0EE77B032AEADFD1118BF24B467_1... done.
Writting process AC04B0EE77B032AEADFD1118BF24B467_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAC04B0EE77B032AEADFD1118BF24B467.report
Scheduling successful
submit!!!
jobs = 147
day = 160 run = 15160005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160005/*.root.log: No such file or directory
138
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:52:06 PDT] Dataset size is 138 files
Removing files not on site LBL
[2017.09.05 21:52:06 PDT] Dataset size is 138 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:52:06 PDT] Dataset size is 138 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:52:06 PDT] Started with 138 files, current size is 138files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:52:06 PDT] Dataset size is 138 files
----------------------------------------------------
validating dataset ....passed
Writting process 80CB8660CDFF6403B4267498C1FDE6EB_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 80CB8660CDFF6403B4267498C1FDE6EB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched80CB8660CDFF6403B4267498C1FDE6EB.report
Scheduling successful
submit!!!
jobs = 144
day = 160 run = 15160006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160006/*.root.log: No such file or directory
215
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:53:18 PDT] Dataset size is 215 files
Removing files not on site LBL
[2017.09.05 21:53:18 PDT] Dataset size is 215 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:53:19 PDT] Dataset size is 215 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:53:19 PDT] Started with 215 files, current size is 215files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:53:19 PDT] Dataset size is 215 files
----------------------------------------------------
validating dataset ....passed
Writting process 05F4E63DD718FF5D2432D75DAC21F2D6_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 05F4E63DD718FF5D2432D75DAC21F2D6_2... done.
Writting process 05F4E63DD718FF5D2432D75DAC21F2D6_1... done.
Writting process 05F4E63DD718FF5D2432D75DAC21F2D6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched05F4E63DD718FF5D2432D75DAC21F2D6.report
Scheduling successful
submit!!!
jobs = 146
day = 160 run = 15160007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160007/*.root.log: No such file or directory
233
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:54:32 PDT] Dataset size is 233 files
Removing files not on site LBL
[2017.09.05 21:54:32 PDT] Dataset size is 233 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:54:32 PDT] Dataset size is 233 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:54:32 PDT] Started with 233 files, current size is 233files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:54:32 PDT] Dataset size is 233 files
----------------------------------------------------
validating dataset ....passed
Writting process F932E3201F575E64DFF5701B5BF97E34_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F932E3201F575E64DFF5701B5BF97E34_2... done.
Writting process F932E3201F575E64DFF5701B5BF97E34_1... done.
Writting process F932E3201F575E64DFF5701B5BF97E34_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF932E3201F575E64DFF5701B5BF97E34.report
Scheduling successful
submit!!!
jobs = 146
day = 160 run = 15160033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160033/*.root.log: No such file or directory
231
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:55:45 PDT] Dataset size is 231 files
Removing files not on site LBL
[2017.09.05 21:55:45 PDT] Dataset size is 231 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:55:45 PDT] Dataset size is 231 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:55:45 PDT] Started with 231 files, current size is 231files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:55:45 PDT] Dataset size is 231 files
----------------------------------------------------
validating dataset ....passed
Writting process 3E98C99AC02DBD419122A693B1F40327_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3E98C99AC02DBD419122A693B1F40327_2... done.
Writting process 3E98C99AC02DBD419122A693B1F40327_1... done.
Writting process 3E98C99AC02DBD419122A693B1F40327_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3E98C99AC02DBD419122A693B1F40327.report
Scheduling successful
submit!!!
jobs = 144
day = 160 run = 15160034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160034/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:56:57 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 21:56:57 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:56:57 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:56:57 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:56:57 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process A06D1A56DDD34C89DC4D6A67853BB597_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A06D1A56DDD34C89DC4D6A67853BB597_1... done.
Writting process A06D1A56DDD34C89DC4D6A67853BB597_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA06D1A56DDD34C89DC4D6A67853BB597.report
Scheduling successful
submit!!!
jobs = 143
day = 160 run = 15160035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160035/*.root.log: No such file or directory
162
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:58:08 PDT] Dataset size is 162 files
Removing files not on site LBL
[2017.09.05 21:58:08 PDT] Dataset size is 162 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:58:08 PDT] Dataset size is 162 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:58:08 PDT] Started with 162 files, current size is 162files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:58:08 PDT] Dataset size is 162 files
----------------------------------------------------
validating dataset ....passed
Writting process 846FFBABB5DC4AE36C3902BBAC73C721_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 846FFBABB5DC4AE36C3902BBAC73C721_1... done.
Writting process 846FFBABB5DC4AE36C3902BBAC73C721_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched846FFBABB5DC4AE36C3902BBAC73C721.report
Scheduling successful
submit!!!
jobs = 141
day = 160 run = 15160036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160036/*.root.log: No such file or directory
168
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 21:59:20 PDT] Dataset size is 168 files
Removing files not on site LBL
[2017.09.05 21:59:20 PDT] Dataset size is 168 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 21:59:20 PDT] Dataset size is 168 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 21:59:20 PDT] Started with 168 files, current size is 168files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 21:59:20 PDT] Dataset size is 168 files
----------------------------------------------------
validating dataset ....passed
Writting process 142E80A37438DE4AED8750875FFCE8DA_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 142E80A37438DE4AED8750875FFCE8DA_1... done.
Writting process 142E80A37438DE4AED8750875FFCE8DA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched142E80A37438DE4AED8750875FFCE8DA.report
Scheduling successful
submit!!!
jobs = 140
day = 160 run = 15160037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160037/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:00:33 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.05 22:00:33 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:00:33 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:00:33 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:00:33 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 2DE0D077762FEEB1EC3D452CAA03BA32_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2DE0D077762FEEB1EC3D452CAA03BA32_1... done.
Writting process 2DE0D077762FEEB1EC3D452CAA03BA32_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2DE0D077762FEEB1EC3D452CAA03BA32.report
Scheduling successful
submit!!!
jobs = 141
day = 160 run = 15160038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160038/*.root.log: No such file or directory
156
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:01:44 PDT] Dataset size is 156 files
Removing files not on site LBL
[2017.09.05 22:01:44 PDT] Dataset size is 156 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:01:44 PDT] Dataset size is 156 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:01:44 PDT] Started with 156 files, current size is 156files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:01:44 PDT] Dataset size is 156 files
----------------------------------------------------
validating dataset ....passed
Writting process 7F25114CAB4945CD5F8C6389F37DA3BC_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7F25114CAB4945CD5F8C6389F37DA3BC_1... done.
Writting process 7F25114CAB4945CD5F8C6389F37DA3BC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7F25114CAB4945CD5F8C6389F37DA3BC.report
Scheduling successful
submit!!!
jobs = 143
day = 160 run = 15160039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160039/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:02:56 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 22:02:56 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:02:56 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:02:56 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:02:57 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process E6CE982965C8EB06918A5494DAF49F13_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E6CE982965C8EB06918A5494DAF49F13_1... done.
Writting process E6CE982965C8EB06918A5494DAF49F13_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE6CE982965C8EB06918A5494DAF49F13.report
Scheduling successful
submit!!!
jobs = 140
day = 160 run = 15160040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160040/*.root.log: No such file or directory
125
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:04:07 PDT] Dataset size is 125 files
Removing files not on site LBL
[2017.09.05 22:04:07 PDT] Dataset size is 125 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:04:07 PDT] Dataset size is 125 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:04:08 PDT] Started with 125 files, current size is 125files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:04:08 PDT] Dataset size is 125 files
----------------------------------------------------
validating dataset ....passed
Writting process 2B1B74583323F4178143EFD770CBA99F_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2B1B74583323F4178143EFD770CBA99F_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2B1B74583323F4178143EFD770CBA99F.report
Scheduling successful
submit!!!
jobs = 139
day = 160 run = 15160041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160041/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:05:20 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 22:05:20 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:05:20 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:05:21 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:05:21 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process D6C5DD8E535CE4C38DDA88FD33550BAD_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D6C5DD8E535CE4C38DDA88FD33550BAD_1... done.
Writting process D6C5DD8E535CE4C38DDA88FD33550BAD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD6C5DD8E535CE4C38DDA88FD33550BAD.report
Scheduling successful
submit!!!
jobs = 139
day = 160 run = 15160042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160042/*.root.log: No such file or directory
212
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:06:34 PDT] Dataset size is 212 files
Removing files not on site LBL
[2017.09.05 22:06:34 PDT] Dataset size is 212 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:06:34 PDT] Dataset size is 212 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:06:35 PDT] Started with 212 files, current size is 212files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:06:35 PDT] Dataset size is 212 files
----------------------------------------------------
validating dataset ....passed
Writting process A49F3DCEE2DF641A2741AC12532FB9AF_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A49F3DCEE2DF641A2741AC12532FB9AF_2... done.
Writting process A49F3DCEE2DF641A2741AC12532FB9AF_1... done.
Writting process A49F3DCEE2DF641A2741AC12532FB9AF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA49F3DCEE2DF641A2741AC12532FB9AF.report
Scheduling successful
submit!!!
jobs = 135
day = 160 run = 15160043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160043/*.root.log: No such file or directory
200
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:07:48 PDT] Dataset size is 200 files
Removing files not on site LBL
[2017.09.05 22:07:48 PDT] Dataset size is 200 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:07:48 PDT] Dataset size is 200 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:07:49 PDT] Started with 200 files, current size is 200files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:07:49 PDT] Dataset size is 200 files
----------------------------------------------------
validating dataset ....passed
Writting process F6F3534E3AEE79DAC1FA1780C7AF585A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F6F3534E3AEE79DAC1FA1780C7AF585A_2... done.
Writting process F6F3534E3AEE79DAC1FA1780C7AF585A_1... done.
Writting process F6F3534E3AEE79DAC1FA1780C7AF585A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF6F3534E3AEE79DAC1FA1780C7AF585A.report
Scheduling successful
submit!!!
jobs = 137
day = 160 run = 15160044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160044/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:09:02 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 22:09:02 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:09:02 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:09:03 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:09:03 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process 328DAD49DBDED5C87C300EBB6AD5173E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 328DAD49DBDED5C87C300EBB6AD5173E_1... done.
Writting process 328DAD49DBDED5C87C300EBB6AD5173E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched328DAD49DBDED5C87C300EBB6AD5173E.report
Scheduling successful
submit!!!
jobs = 137
day = 160 run = 15160045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160045/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:10:16 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.05 22:10:16 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:10:16 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:10:17 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:10:17 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process B9EE955A247321C8A31E9538C1565F93_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B9EE955A247321C8A31E9538C1565F93_2... done.
Writting process B9EE955A247321C8A31E9538C1565F93_1... done.
Writting process B9EE955A247321C8A31E9538C1565F93_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB9EE955A247321C8A31E9538C1565F93.report
Scheduling successful
submit!!!
jobs = 135
day = 160 run = 15160046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160046/*.root.log: No such file or directory
178
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:11:28 PDT] Dataset size is 178 files
Removing files not on site LBL
[2017.09.05 22:11:28 PDT] Dataset size is 178 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:11:29 PDT] Dataset size is 178 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:11:29 PDT] Started with 178 files, current size is 178files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:11:29 PDT] Dataset size is 178 files
----------------------------------------------------
validating dataset ....passed
Writting process B597201DE8012E3FA1C87C29BD198987_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B597201DE8012E3FA1C87C29BD198987_1... done.
Writting process B597201DE8012E3FA1C87C29BD198987_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB597201DE8012E3FA1C87C29BD198987.report
Scheduling successful
submit!!!
jobs = 131
day = 160 run = 15160047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160047/*.root.log: No such file or directory
187
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:12:41 PDT] Dataset size is 187 files
Removing files not on site LBL
[2017.09.05 22:12:41 PDT] Dataset size is 187 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:12:42 PDT] Dataset size is 187 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:12:42 PDT] Started with 187 files, current size is 187files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:12:42 PDT] Dataset size is 187 files
----------------------------------------------------
validating dataset ....passed
Writting process 30B91C6FB19FD7C74DA23B6490037B9C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 30B91C6FB19FD7C74DA23B6490037B9C_1... done.
Writting process 30B91C6FB19FD7C74DA23B6490037B9C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched30B91C6FB19FD7C74DA23B6490037B9C.report
Scheduling successful
submit!!!
jobs = 126
day = 160 run = 15160048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15160048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15160048/*.root.log: No such file or directory
104
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:13:52 PDT] Dataset size is 104 files
Removing files not on site LBL
[2017.09.05 22:13:53 PDT] Dataset size is 104 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:13:53 PDT] Dataset size is 104 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:13:54 PDT] Started with 104 files, current size is 104files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:13:54 PDT] Dataset size is 104 files
----------------------------------------------------
validating dataset ....passed
Writting process CCA999C7EA7909E547506F2129AE7FAE_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CCA999C7EA7909E547506F2129AE7FAE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCCA999C7EA7909E547506F2129AE7FAE.report
Scheduling successful
submit!!!
Job submission for day 160 finished!
161
jobs = 131
day = 161 run = 15161005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161005/*.root.log: No such file or directory
179
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:15:07 PDT] Dataset size is 179 files
Removing files not on site LBL
[2017.09.05 22:15:07 PDT] Dataset size is 179 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:15:07 PDT] Dataset size is 179 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:15:08 PDT] Started with 179 files, current size is 179files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:15:08 PDT] Dataset size is 179 files
----------------------------------------------------
validating dataset ....passed
Writting process E8DC6EE58B9B11FCE2C81A276EEDB620_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E8DC6EE58B9B11FCE2C81A276EEDB620_1... done.
Writting process E8DC6EE58B9B11FCE2C81A276EEDB620_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE8DC6EE58B9B11FCE2C81A276EEDB620.report
Scheduling successful
submit!!!
jobs = 132
day = 161 run = 15161006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161006/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:16:20 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 22:16:20 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:16:20 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:16:20 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:16:21 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process 40A72EA764168A429C6E719504D407D0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 40A72EA764168A429C6E719504D407D0_1... done.
Writting process 40A72EA764168A429C6E719504D407D0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched40A72EA764168A429C6E719504D407D0.report
Scheduling successful
submit!!!
jobs = 132
day = 161 run = 15161007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161007/*.root.log: No such file or directory
160
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:17:33 PDT] Dataset size is 160 files
Removing files not on site LBL
[2017.09.05 22:17:33 PDT] Dataset size is 160 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:17:33 PDT] Dataset size is 160 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:17:34 PDT] Started with 160 files, current size is 160files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:17:34 PDT] Dataset size is 160 files
----------------------------------------------------
validating dataset ....passed
Writting process 120F0AD1F20A0CF360DDF0315810E2F4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 120F0AD1F20A0CF360DDF0315810E2F4_1... done.
Writting process 120F0AD1F20A0CF360DDF0315810E2F4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched120F0AD1F20A0CF360DDF0315810E2F4.report
Scheduling successful
submit!!!
jobs = 128
day = 161 run = 15161008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161008/*.root.log: No such file or directory
162
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:18:45 PDT] Dataset size is 162 files
Removing files not on site LBL
[2017.09.05 22:18:46 PDT] Dataset size is 162 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:18:46 PDT] Dataset size is 162 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:18:46 PDT] Started with 162 files, current size is 162files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:18:47 PDT] Dataset size is 162 files
----------------------------------------------------
validating dataset ....passed
Writting process 5070C6894DE6C7E253403A61EF6C2BC4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5070C6894DE6C7E253403A61EF6C2BC4_1... done.
Writting process 5070C6894DE6C7E253403A61EF6C2BC4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5070C6894DE6C7E253403A61EF6C2BC4.report
Scheduling successful
submit!!!
jobs = 127
day = 161 run = 15161009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161009/*.root.log: No such file or directory
161
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:19:59 PDT] Dataset size is 161 files
Removing files not on site LBL
[2017.09.05 22:20:00 PDT] Dataset size is 161 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:20:00 PDT] Dataset size is 161 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:20:00 PDT] Started with 161 files, current size is 161files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:20:00 PDT] Dataset size is 161 files
----------------------------------------------------
validating dataset ....passed
Writting process 48E03C661B19FA33A718826E18EB74B0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 48E03C661B19FA33A718826E18EB74B0_1... done.
Writting process 48E03C661B19FA33A718826E18EB74B0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched48E03C661B19FA33A718826E18EB74B0.report
Scheduling successful
submit!!!
jobs = 125
day = 161 run = 15161010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161010/*.root.log: No such file or directory
143
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:21:12 PDT] Dataset size is 143 files
Removing files not on site LBL
[2017.09.05 22:21:12 PDT] Dataset size is 143 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:21:13 PDT] Dataset size is 143 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:21:14 PDT] Started with 143 files, current size is 143files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:21:14 PDT] Dataset size is 143 files
----------------------------------------------------
validating dataset ....passed
Writting process 0A6101E7DCBEC79CC4D7F23D198A0F11_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0A6101E7DCBEC79CC4D7F23D198A0F11_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0A6101E7DCBEC79CC4D7F23D198A0F11.report
Scheduling successful
submit!!!
jobs = 123
day = 161 run = 15161011
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161011/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161011/*.root.log: No such file or directory
162
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:22:25 PDT] Dataset size is 162 files
Removing files not on site LBL
[2017.09.05 22:22:25 PDT] Dataset size is 162 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:22:25 PDT] Dataset size is 162 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:22:25 PDT] Started with 162 files, current size is 162files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:22:25 PDT] Dataset size is 162 files
----------------------------------------------------
validating dataset ....passed
Writting process 0D67163FFF1F3983D5FE47A6464276AA_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0D67163FFF1F3983D5FE47A6464276AA_1... done.
Writting process 0D67163FFF1F3983D5FE47A6464276AA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0D67163FFF1F3983D5FE47A6464276AA.report
Scheduling successful
submit!!!
jobs = 122
day = 161 run = 15161012
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161012/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161012/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:23:37 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 22:23:37 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:23:37 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:23:37 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:23:37 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process 61E65E9C59E5E3444E16C744F31A7B27_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 61E65E9C59E5E3444E16C744F31A7B27_1... done.
Writting process 61E65E9C59E5E3444E16C744F31A7B27_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched61E65E9C59E5E3444E16C744F31A7B27.report
Scheduling successful
submit!!!
jobs = 122
day = 161 run = 15161013
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161013/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161013/*.root.log: No such file or directory
59
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:24:45 PDT] Dataset size is 59 files
Removing files not on site LBL
[2017.09.05 22:24:45 PDT] Dataset size is 59 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:24:45 PDT] Dataset size is 59 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:24:45 PDT] Started with 59 files, current size is 59files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:24:45 PDT] Dataset size is 59 files
----------------------------------------------------
validating dataset ....passed
Writting process 35AD672E4F28694D284639FB8B89EBC3_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched35AD672E4F28694D284639FB8B89EBC3.report
Scheduling successful
submit!!!
jobs = 120
day = 161 run = 15161014
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161014/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161014/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:25:56 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 22:25:56 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:25:56 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:25:56 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:25:56 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process 4A1A0A7D781C7B386304E70079F975B4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4A1A0A7D781C7B386304E70079F975B4_1... done.
Writting process 4A1A0A7D781C7B386304E70079F975B4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4A1A0A7D781C7B386304E70079F975B4.report
Scheduling successful
submit!!!
jobs = 120
day = 161 run = 15161015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161015/*.root.log: No such file or directory
251
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:27:10 PDT] Dataset size is 251 files
Removing files not on site LBL
[2017.09.05 22:27:10 PDT] Dataset size is 251 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:27:10 PDT] Dataset size is 251 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:27:10 PDT] Started with 251 files, current size is 251files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:27:10 PDT] Dataset size is 251 files
----------------------------------------------------
validating dataset ....passed
Writting process 2C066AFCFD640F6C8FB728535B1FD5A0_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2C066AFCFD640F6C8FB728535B1FD5A0_3... done.
Writting process 2C066AFCFD640F6C8FB728535B1FD5A0_2... done.
Writting process 2C066AFCFD640F6C8FB728535B1FD5A0_1... done.
Writting process 2C066AFCFD640F6C8FB728535B1FD5A0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2C066AFCFD640F6C8FB728535B1FD5A0.report
Scheduling successful
submit!!!
jobs = 119
day = 161 run = 15161016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161016/*.root.log: No such file or directory
208
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:28:23 PDT] Dataset size is 208 files
Removing files not on site LBL
[2017.09.05 22:28:23 PDT] Dataset size is 208 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:28:23 PDT] Dataset size is 208 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:28:23 PDT] Started with 208 files, current size is 208files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:28:23 PDT] Dataset size is 208 files
----------------------------------------------------
validating dataset ....passed
Writting process 90CCD48A13FA655AC4CEC20949C0B9AB_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 90CCD48A13FA655AC4CEC20949C0B9AB_2... done.
Writting process 90CCD48A13FA655AC4CEC20949C0B9AB_1... done.
Writting process 90CCD48A13FA655AC4CEC20949C0B9AB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched90CCD48A13FA655AC4CEC20949C0B9AB.report
Scheduling successful
submit!!!
jobs = 122
day = 161 run = 15161017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161017/*.root.log: No such file or directory
60
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:29:31 PDT] Dataset size is 60 files
Removing files not on site LBL
[2017.09.05 22:29:31 PDT] Dataset size is 60 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:29:31 PDT] Dataset size is 60 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:29:31 PDT] Started with 60 files, current size is 60files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:29:31 PDT] Dataset size is 60 files
----------------------------------------------------
validating dataset ....passed
Writting process 8173DBEE9CDCAB1787D673E9CF546FD5_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8173DBEE9CDCAB1787D673E9CF546FD5.report
Scheduling successful
submit!!!
jobs = 120
day = 161 run = 15161018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161018/*.root.log: No such file or directory
196
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:30:42 PDT] Dataset size is 196 files
Removing files not on site LBL
[2017.09.05 22:30:42 PDT] Dataset size is 196 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:30:42 PDT] Dataset size is 196 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:30:43 PDT] Started with 196 files, current size is 196files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:30:43 PDT] Dataset size is 196 files
----------------------------------------------------
validating dataset ....passed
Writting process A7898E6B804BCA9038AF8BECE8E89068_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A7898E6B804BCA9038AF8BECE8E89068_1... done.
Writting process A7898E6B804BCA9038AF8BECE8E89068_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA7898E6B804BCA9038AF8BECE8E89068.report
Scheduling successful
submit!!!
jobs = 119
day = 161 run = 15161019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161019/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:31:55 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.05 22:31:55 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:31:55 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:31:55 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:31:55 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 7AF771CC52CA12DE89B6959130FABF82_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7AF771CC52CA12DE89B6959130FABF82_2... done.
Writting process 7AF771CC52CA12DE89B6959130FABF82_1... done.
Writting process 7AF771CC52CA12DE89B6959130FABF82_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7AF771CC52CA12DE89B6959130FABF82.report
Scheduling successful
submit!!!
jobs = 120
day = 161 run = 15161020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161020/*.root.log: No such file or directory
85
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:33:03 PDT] Dataset size is 85 files
Removing files not on site LBL
[2017.09.05 22:33:03 PDT] Dataset size is 85 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:33:03 PDT] Dataset size is 85 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:33:04 PDT] Started with 85 files, current size is 85files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:33:04 PDT] Dataset size is 85 files
----------------------------------------------------
validating dataset ....passed
Writting process 741242217DCC61F96A438BCC847C0103_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched741242217DCC61F96A438BCC847C0103.report
Scheduling successful
submit!!!
jobs = 119
day = 161 run = 15161021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161021/*.root.log: No such file or directory
213
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:34:16 PDT] Dataset size is 213 files
Removing files not on site LBL
[2017.09.05 22:34:16 PDT] Dataset size is 213 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:34:16 PDT] Dataset size is 213 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:34:16 PDT] Started with 213 files, current size is 213files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:34:16 PDT] Dataset size is 213 files
----------------------------------------------------
validating dataset ....passed
Writting process 0DC2E4740F0AA33213DB25FD28A89757_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0DC2E4740F0AA33213DB25FD28A89757_2... done.
Writting process 0DC2E4740F0AA33213DB25FD28A89757_1... done.
Writting process 0DC2E4740F0AA33213DB25FD28A89757_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0DC2E4740F0AA33213DB25FD28A89757.report
Scheduling successful
submit!!!
jobs = 120
day = 161 run = 15161022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161022/*.root.log: No such file or directory
46
46 46
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:35:24 PDT] Dataset size is 46 files
Removing files not on site LBL
[2017.09.05 22:35:24 PDT] Dataset size is 46 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:35:24 PDT] Dataset size is 46 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:35:24 PDT] Started with 46 files, current size is 46files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=46 ,maxSize=46 )
[2017.09.05 22:35:24 PDT] Dataset size is 46 files
----------------------------------------------------
validating dataset ....passed
Writting process AA795B632DD68B0F671FDDD59D94920C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAA795B632DD68B0F671FDDD59D94920C.report
Scheduling successful
submit!!!
jobs = 120
day = 161 run = 15161051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161051/*.root.log: No such file or directory
4
4 4
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:36:30 PDT] Dataset size is 4 files
Removing files not on site LBL
[2017.09.05 22:36:30 PDT] Dataset size is 4 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:36:30 PDT] Dataset size is 4 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:36:30 PDT] Started with 4 files, current size is 4files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=4 ,maxSize=4 )
[2017.09.05 22:36:30 PDT] Dataset size is 4 files
----------------------------------------------------
validating dataset ....passed
Writting process D9A97EAE0B61CACF8F06763A4AA7F17C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD9A97EAE0B61CACF8F06763A4AA7F17C.report
Scheduling successful
submit!!!
jobs = 117
day = 161 run = 15161056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161056/*.root.log: No such file or directory
33
33 33
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:37:37 PDT] Dataset size is 33 files
Removing files not on site LBL
[2017.09.05 22:37:37 PDT] Dataset size is 33 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:37:37 PDT] Dataset size is 33 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:37:37 PDT] Started with 33 files, current size is 33files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=33 ,maxSize=33 )
[2017.09.05 22:37:37 PDT] Dataset size is 33 files
----------------------------------------------------
validating dataset ....passed
Writting process E76EEA6E4A78891E94ED7CD6AE5EAF0B_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE76EEA6E4A78891E94ED7CD6AE5EAF0B.report
Scheduling successful
submit!!!
jobs = 113
day = 161 run = 15161059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161059/*.root.log: No such file or directory
92
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:38:45 PDT] Dataset size is 92 files
Removing files not on site LBL
[2017.09.05 22:38:45 PDT] Dataset size is 92 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:38:45 PDT] Dataset size is 92 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:38:46 PDT] Started with 92 files, current size is 92files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:38:46 PDT] Dataset size is 92 files
----------------------------------------------------
validating dataset ....passed
Writting process 6199C59AF3D4E14CFE3E71143DC8DF43_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6199C59AF3D4E14CFE3E71143DC8DF43.report
Scheduling successful
submit!!!
jobs = 108
day = 161 run = 15161060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161060/*.root.log: No such file or directory
150
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:39:56 PDT] Dataset size is 150 files
Removing files not on site LBL
[2017.09.05 22:39:56 PDT] Dataset size is 150 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:39:56 PDT] Dataset size is 150 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:39:56 PDT] Started with 150 files, current size is 150files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:39:56 PDT] Dataset size is 150 files
----------------------------------------------------
validating dataset ....passed
Writting process 500895A528F8F986A89F2E6743E2C0A8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 500895A528F8F986A89F2E6743E2C0A8_1... done.
Writting process 500895A528F8F986A89F2E6743E2C0A8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched500895A528F8F986A89F2E6743E2C0A8.report
Scheduling successful
submit!!!
jobs = 107
day = 161 run = 15161061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161061/*.root.log: No such file or directory
151
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:41:07 PDT] Dataset size is 151 files
Removing files not on site LBL
[2017.09.05 22:41:07 PDT] Dataset size is 151 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:41:07 PDT] Dataset size is 151 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:41:07 PDT] Started with 151 files, current size is 151files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:41:07 PDT] Dataset size is 151 files
----------------------------------------------------
validating dataset ....passed
Writting process 8093215CD28F43C57FC029358161ED68_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8093215CD28F43C57FC029358161ED68_1... done.
Writting process 8093215CD28F43C57FC029358161ED68_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8093215CD28F43C57FC029358161ED68.report
Scheduling successful
submit!!!
jobs = 107
day = 161 run = 15161062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161062/*.root.log: No such file or directory
182
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:42:18 PDT] Dataset size is 182 files
Removing files not on site LBL
[2017.09.05 22:42:18 PDT] Dataset size is 182 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:42:18 PDT] Dataset size is 182 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:42:18 PDT] Started with 182 files, current size is 182files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:42:18 PDT] Dataset size is 182 files
----------------------------------------------------
validating dataset ....passed
Writting process 3700964AABE912E37B5A6F514C484069_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3700964AABE912E37B5A6F514C484069_1... done.
Writting process 3700964AABE912E37B5A6F514C484069_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3700964AABE912E37B5A6F514C484069.report
Scheduling successful
submit!!!
jobs = 105
day = 161 run = 15161063
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161063/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161063/*.root.log: No such file or directory
51
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:43:26 PDT] Dataset size is 51 files
Removing files not on site LBL
[2017.09.05 22:43:26 PDT] Dataset size is 51 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:43:26 PDT] Dataset size is 51 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:43:26 PDT] Started with 51 files, current size is 51files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:43:26 PDT] Dataset size is 51 files
----------------------------------------------------
validating dataset ....passed
Writting process 439D59D65BA59B20FB8D93FB3B01AE70_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched439D59D65BA59B20FB8D93FB3B01AE70.report
Scheduling successful
submit!!!
jobs = 104
day = 161 run = 15161064
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161064/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161064/*.root.log: No such file or directory
165
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:44:37 PDT] Dataset size is 165 files
Removing files not on site LBL
[2017.09.05 22:44:37 PDT] Dataset size is 165 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:44:37 PDT] Dataset size is 165 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:44:37 PDT] Started with 165 files, current size is 165files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:44:37 PDT] Dataset size is 165 files
----------------------------------------------------
validating dataset ....passed
Writting process 708C57123263EDFE0E39ADAF732A64B3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 708C57123263EDFE0E39ADAF732A64B3_1... done.
Writting process 708C57123263EDFE0E39ADAF732A64B3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched708C57123263EDFE0E39ADAF732A64B3.report
Scheduling successful
submit!!!
jobs = 102
day = 161 run = 15161065
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161065/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161065/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:45:48 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 22:45:48 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:45:48 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:45:48 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:45:48 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process AC9AE4942BD1AA273E21DBA93D617F5A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process AC9AE4942BD1AA273E21DBA93D617F5A_1... done.
Writting process AC9AE4942BD1AA273E21DBA93D617F5A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAC9AE4942BD1AA273E21DBA93D617F5A.report
Scheduling successful
submit!!!
jobs = 101
day = 161 run = 15161066
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161066/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161066/*.root.log: No such file or directory
56
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:46:55 PDT] Dataset size is 56 files
Removing files not on site LBL
[2017.09.05 22:46:55 PDT] Dataset size is 56 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:46:55 PDT] Dataset size is 56 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:46:56 PDT] Started with 56 files, current size is 56files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:46:56 PDT] Dataset size is 56 files
----------------------------------------------------
validating dataset ....passed
Writting process D47F6F116E3BB6F84CBB7E5CB84DBD81_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD47F6F116E3BB6F84CBB7E5CB84DBD81.report
Scheduling successful
submit!!!
jobs = 100
day = 161 run = 15161067
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161067/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161067/*.root.log: No such file or directory
28
28 28
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:48:02 PDT] Dataset size is 28 files
Removing files not on site LBL
[2017.09.05 22:48:02 PDT] Dataset size is 28 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:48:02 PDT] Dataset size is 28 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:48:02 PDT] Started with 28 files, current size is 28files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=28 ,maxSize=28 )
[2017.09.05 22:48:03 PDT] Dataset size is 28 files
----------------------------------------------------
validating dataset ....passed
Writting process 23BBB180F57CA31AF1FF5335DF7CA362_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched23BBB180F57CA31AF1FF5335DF7CA362.report
Scheduling successful
submit!!!
jobs = 95
day = 161 run = 15161068
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161068/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161068/*.root.log: No such file or directory
184
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:49:14 PDT] Dataset size is 184 files
Removing files not on site LBL
[2017.09.05 22:49:14 PDT] Dataset size is 184 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:49:14 PDT] Dataset size is 184 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:49:14 PDT] Started with 184 files, current size is 184files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:49:14 PDT] Dataset size is 184 files
----------------------------------------------------
validating dataset ....passed
Writting process B842CD3F010EFF5247BCC83505023F1C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B842CD3F010EFF5247BCC83505023F1C_1... done.
Writting process B842CD3F010EFF5247BCC83505023F1C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB842CD3F010EFF5247BCC83505023F1C.report
Scheduling successful
submit!!!
jobs = 89
day = 161 run = 15161069
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161069/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161069/*.root.log: No such file or directory
167
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:50:25 PDT] Dataset size is 167 files
Removing files not on site LBL
[2017.09.05 22:50:25 PDT] Dataset size is 167 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:50:25 PDT] Dataset size is 167 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:50:25 PDT] Started with 167 files, current size is 167files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:50:25 PDT] Dataset size is 167 files
----------------------------------------------------
validating dataset ....passed
Writting process 269BECD71C464B9C456A85616F26C6E2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 269BECD71C464B9C456A85616F26C6E2_1... done.
Writting process 269BECD71C464B9C456A85616F26C6E2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched269BECD71C464B9C456A85616F26C6E2.report
Scheduling successful
submit!!!
jobs = 89
day = 161 run = 15161070
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161070/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161070/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:51:37 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.05 22:51:37 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:51:38 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:51:38 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:51:38 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process FEE7A940C98DEB2B5EA483AA8A28EB3E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process FEE7A940C98DEB2B5EA483AA8A28EB3E_2... done.
Writting process FEE7A940C98DEB2B5EA483AA8A28EB3E_1... done.
Writting process FEE7A940C98DEB2B5EA483AA8A28EB3E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedFEE7A940C98DEB2B5EA483AA8A28EB3E.report
Scheduling successful
submit!!!
jobs = 91
day = 161 run = 15161071
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161071/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161071/*.root.log: No such file or directory
212
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:52:50 PDT] Dataset size is 212 files
Removing files not on site LBL
[2017.09.05 22:52:50 PDT] Dataset size is 212 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:52:50 PDT] Dataset size is 212 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:52:50 PDT] Started with 212 files, current size is 212files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:52:50 PDT] Dataset size is 212 files
----------------------------------------------------
validating dataset ....passed
Writting process 4C064CDFD586464D4E0C2AADDFBC8712_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4C064CDFD586464D4E0C2AADDFBC8712_2... done.
Writting process 4C064CDFD586464D4E0C2AADDFBC8712_1... done.
Writting process 4C064CDFD586464D4E0C2AADDFBC8712_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4C064CDFD586464D4E0C2AADDFBC8712.report
Scheduling successful
submit!!!
jobs = 92
day = 161 run = 15161072
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15161072/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15161072/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:54:02 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.05 22:54:02 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:54:02 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:54:02 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:54:02 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process 1A5EA443876DBC0ED7DF48F0F2464F3A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1A5EA443876DBC0ED7DF48F0F2464F3A_1... done.
Writting process 1A5EA443876DBC0ED7DF48F0F2464F3A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1A5EA443876DBC0ED7DF48F0F2464F3A.report
Scheduling successful
submit!!!
Job submission for day 161 finished!
162
jobs = 93
day = 162 run = 15162001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162001/*.root.log: No such file or directory
136
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:55:12 PDT] Dataset size is 136 files
Removing files not on site LBL
[2017.09.05 22:55:12 PDT] Dataset size is 136 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:55:12 PDT] Dataset size is 136 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:55:12 PDT] Started with 136 files, current size is 136files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:55:12 PDT] Dataset size is 136 files
----------------------------------------------------
validating dataset ....passed
Writting process D5649C30EF79F80957EFEE975FA1E9DF_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D5649C30EF79F80957EFEE975FA1E9DF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD5649C30EF79F80957EFEE975FA1E9DF.report
Scheduling successful
submit!!!
jobs = 94
day = 162 run = 15162015
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162015/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162015/*.root.log: No such file or directory
41
41 41
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:56:20 PDT] Dataset size is 41 files
Removing files not on site LBL
[2017.09.05 22:56:20 PDT] Dataset size is 41 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:56:20 PDT] Dataset size is 41 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:56:20 PDT] Started with 41 files, current size is 41files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=41 ,maxSize=41 )
[2017.09.05 22:56:20 PDT] Dataset size is 41 files
----------------------------------------------------
validating dataset ....passed
Writting process F63306A8587B42E99179B02230270E4D_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF63306A8587B42E99179B02230270E4D.report
Scheduling successful
submit!!!
jobs = 94
day = 162 run = 15162016
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162016/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162016/*.root.log: No such file or directory
160
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:57:31 PDT] Dataset size is 160 files
Removing files not on site LBL
[2017.09.05 22:57:31 PDT] Dataset size is 160 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:57:31 PDT] Dataset size is 160 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:57:31 PDT] Started with 160 files, current size is 160files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:57:31 PDT] Dataset size is 160 files
----------------------------------------------------
validating dataset ....passed
Writting process B149FD8CF5D18AEA24780EC6607B9800_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B149FD8CF5D18AEA24780EC6607B9800_1... done.
Writting process B149FD8CF5D18AEA24780EC6607B9800_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB149FD8CF5D18AEA24780EC6607B9800.report
Scheduling successful
submit!!!
jobs = 94
day = 162 run = 15162017
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162017/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162017/*.root.log: No such file or directory
146
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:58:41 PDT] Dataset size is 146 files
Removing files not on site LBL
[2017.09.05 22:58:41 PDT] Dataset size is 146 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:58:41 PDT] Dataset size is 146 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:58:42 PDT] Started with 146 files, current size is 146files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:58:42 PDT] Dataset size is 146 files
----------------------------------------------------
validating dataset ....passed
Writting process B4BB634DC9A4BCBAA9D84BF701F5694E_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B4BB634DC9A4BCBAA9D84BF701F5694E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB4BB634DC9A4BCBAA9D84BF701F5694E.report
Scheduling successful
submit!!!
jobs = 89
day = 162 run = 15162018
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162018/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162018/*.root.log: No such file or directory
163
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 22:59:52 PDT] Dataset size is 163 files
Removing files not on site LBL
[2017.09.05 22:59:52 PDT] Dataset size is 163 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 22:59:52 PDT] Dataset size is 163 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 22:59:52 PDT] Started with 163 files, current size is 163files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 22:59:53 PDT] Dataset size is 163 files
----------------------------------------------------
validating dataset ....passed
Writting process 51EB8F45C21E4B6F5DFA5523A69B1884_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 51EB8F45C21E4B6F5DFA5523A69B1884_1... done.
Writting process 51EB8F45C21E4B6F5DFA5523A69B1884_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched51EB8F45C21E4B6F5DFA5523A69B1884.report
Scheduling successful
submit!!!
jobs = 89
day = 162 run = 15162019
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162019/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162019/*.root.log: No such file or directory
41
41 41
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:01:01 PDT] Dataset size is 41 files
Removing files not on site LBL
[2017.09.05 23:01:01 PDT] Dataset size is 41 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:01:01 PDT] Dataset size is 41 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:01:01 PDT] Started with 41 files, current size is 41files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=41 ,maxSize=41 )
[2017.09.05 23:01:01 PDT] Dataset size is 41 files
----------------------------------------------------
validating dataset ....passed
Writting process 7008429ED75C9A637913F4F3A6CCD265_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7008429ED75C9A637913F4F3A6CCD265.report
Scheduling successful
submit!!!
jobs = 90
day = 162 run = 15162020
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162020/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162020/*.root.log: No such file or directory
173
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:02:12 PDT] Dataset size is 173 files
Removing files not on site LBL
[2017.09.05 23:02:12 PDT] Dataset size is 173 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:02:12 PDT] Dataset size is 173 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:02:12 PDT] Started with 173 files, current size is 173files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:02:12 PDT] Dataset size is 173 files
----------------------------------------------------
validating dataset ....passed
Writting process 82269C6F0EE51718C5726EFA93B952E3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 82269C6F0EE51718C5726EFA93B952E3_1... done.
Writting process 82269C6F0EE51718C5726EFA93B952E3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched82269C6F0EE51718C5726EFA93B952E3.report
Scheduling successful
submit!!!
jobs = 86
day = 162 run = 15162021
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162021/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162021/*.root.log: No such file or directory
164
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:03:23 PDT] Dataset size is 164 files
Removing files not on site LBL
[2017.09.05 23:03:23 PDT] Dataset size is 164 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:03:23 PDT] Dataset size is 164 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:03:23 PDT] Started with 164 files, current size is 164files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:03:24 PDT] Dataset size is 164 files
----------------------------------------------------
validating dataset ....passed
Writting process 1382F8ED9EF62221F65E9619586061B0_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1382F8ED9EF62221F65E9619586061B0_1... done.
Writting process 1382F8ED9EF62221F65E9619586061B0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1382F8ED9EF62221F65E9619586061B0.report
Scheduling successful
submit!!!
jobs = 85
day = 162 run = 15162022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162022/*.root.log: No such file or directory
164
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:04:34 PDT] Dataset size is 164 files
Removing files not on site LBL
[2017.09.05 23:04:34 PDT] Dataset size is 164 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:04:34 PDT] Dataset size is 164 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:04:35 PDT] Started with 164 files, current size is 164files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:04:35 PDT] Dataset size is 164 files
----------------------------------------------------
validating dataset ....passed
Writting process 6ED9A2BA5825EDF3CE0E7770118F76E7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6ED9A2BA5825EDF3CE0E7770118F76E7_1... done.
Writting process 6ED9A2BA5825EDF3CE0E7770118F76E7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6ED9A2BA5825EDF3CE0E7770118F76E7.report
Scheduling successful
submit!!!
jobs = 84
day = 162 run = 15162023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162023/*.root.log: No such file or directory
154
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:05:45 PDT] Dataset size is 154 files
Removing files not on site LBL
[2017.09.05 23:05:45 PDT] Dataset size is 154 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:05:45 PDT] Dataset size is 154 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:05:45 PDT] Started with 154 files, current size is 154files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:05:45 PDT] Dataset size is 154 files
----------------------------------------------------
validating dataset ....passed
Writting process 1C43F373EF39D54669064EEAE16DCAA3_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1C43F373EF39D54669064EEAE16DCAA3_1... done.
Writting process 1C43F373EF39D54669064EEAE16DCAA3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1C43F373EF39D54669064EEAE16DCAA3.report
Scheduling successful
submit!!!
jobs = 82
day = 162 run = 15162024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162024/*.root.log: No such file or directory
115
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:06:55 PDT] Dataset size is 115 files
Removing files not on site LBL
[2017.09.05 23:06:55 PDT] Dataset size is 115 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:06:55 PDT] Dataset size is 115 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:06:55 PDT] Started with 115 files, current size is 115files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:06:55 PDT] Dataset size is 115 files
----------------------------------------------------
validating dataset ....passed
Writting process 2A78F0F2BEB6E5DA1DFCC2F6377E6972_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2A78F0F2BEB6E5DA1DFCC2F6377E6972_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2A78F0F2BEB6E5DA1DFCC2F6377E6972.report
Scheduling successful
submit!!!
jobs = 81
day = 162 run = 15162025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162025/*.root.log: No such file or directory
169
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:08:06 PDT] Dataset size is 169 files
Removing files not on site LBL
[2017.09.05 23:08:06 PDT] Dataset size is 169 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:08:06 PDT] Dataset size is 169 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:08:06 PDT] Started with 169 files, current size is 169files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:08:07 PDT] Dataset size is 169 files
----------------------------------------------------
validating dataset ....passed
Writting process B6092863D58AC2910D3B16A964B1311E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B6092863D58AC2910D3B16A964B1311E_1... done.
Writting process B6092863D58AC2910D3B16A964B1311E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB6092863D58AC2910D3B16A964B1311E.report
Scheduling successful
submit!!!
jobs = 81
day = 162 run = 15162026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162026/*.root.log: No such file or directory
71
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:09:15 PDT] Dataset size is 71 files
Removing files not on site LBL
[2017.09.05 23:09:15 PDT] Dataset size is 71 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:09:15 PDT] Dataset size is 71 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:09:15 PDT] Started with 71 files, current size is 71files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:09:15 PDT] Dataset size is 71 files
----------------------------------------------------
validating dataset ....passed
Writting process D8B93A5E262E517DE06364A9C42646DA_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD8B93A5E262E517DE06364A9C42646DA.report
Scheduling successful
submit!!!
jobs = 84
day = 162 run = 15162027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162027/*.root.log: No such file or directory
215
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:10:28 PDT] Dataset size is 215 files
Removing files not on site LBL
[2017.09.05 23:10:28 PDT] Dataset size is 215 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:10:28 PDT] Dataset size is 215 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:10:28 PDT] Started with 215 files, current size is 215files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:10:28 PDT] Dataset size is 215 files
----------------------------------------------------
validating dataset ....passed
Writting process 64FEC051BCD5A971A81A428694AEF41A_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 64FEC051BCD5A971A81A428694AEF41A_2... done.
Writting process 64FEC051BCD5A971A81A428694AEF41A_1... done.
Writting process 64FEC051BCD5A971A81A428694AEF41A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched64FEC051BCD5A971A81A428694AEF41A.report
Scheduling successful
submit!!!
jobs = 88
day = 162 run = 15162028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162028/*.root.log: No such file or directory
195
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:11:40 PDT] Dataset size is 195 files
Removing files not on site LBL
[2017.09.05 23:11:40 PDT] Dataset size is 195 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:11:40 PDT] Dataset size is 195 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:11:40 PDT] Started with 195 files, current size is 195files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:11:40 PDT] Dataset size is 195 files
----------------------------------------------------
validating dataset ....passed
Writting process 1252F00EBC5A317E8D8685D9613EC0C9_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1252F00EBC5A317E8D8685D9613EC0C9_1... done.
Writting process 1252F00EBC5A317E8D8685D9613EC0C9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1252F00EBC5A317E8D8685D9613EC0C9.report
Scheduling successful
submit!!!
jobs = 93
day = 162 run = 15162029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162029/*.root.log: No such file or directory
210
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:12:53 PDT] Dataset size is 210 files
Removing files not on site LBL
[2017.09.05 23:12:53 PDT] Dataset size is 210 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:12:53 PDT] Dataset size is 210 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:12:54 PDT] Started with 210 files, current size is 210files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:12:55 PDT] Dataset size is 210 files
----------------------------------------------------
validating dataset ....passed
Writting process 5312C547AD71917B67A4CE0146359406_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5312C547AD71917B67A4CE0146359406_2... done.
Writting process 5312C547AD71917B67A4CE0146359406_1... done.
Writting process 5312C547AD71917B67A4CE0146359406_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5312C547AD71917B67A4CE0146359406.report
Scheduling successful
submit!!!
jobs = 94
day = 162 run = 15162030
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162030/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162030/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:14:07 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 23:14:07 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:14:07 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:14:07 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:14:07 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process BC962AD962880472F0BC2B8E2D9DD580_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BC962AD962880472F0BC2B8E2D9DD580_1... done.
Writting process BC962AD962880472F0BC2B8E2D9DD580_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBC962AD962880472F0BC2B8E2D9DD580.report
Scheduling successful
submit!!!
jobs = 97
day = 162 run = 15162031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162031/*.root.log: No such file or directory
57
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:15:15 PDT] Dataset size is 57 files
Removing files not on site LBL
[2017.09.05 23:15:15 PDT] Dataset size is 57 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:15:15 PDT] Dataset size is 57 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:15:15 PDT] Started with 57 files, current size is 57files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:15:15 PDT] Dataset size is 57 files
----------------------------------------------------
validating dataset ....passed
Writting process 86FD219E3C7AA3F1DD24FAE007800611_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched86FD219E3C7AA3F1DD24FAE007800611.report
Scheduling successful
submit!!!
jobs = 98
day = 162 run = 15162032
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162032/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162032/*.root.log: No such file or directory
196
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:16:27 PDT] Dataset size is 196 files
Removing files not on site LBL
[2017.09.05 23:16:27 PDT] Dataset size is 196 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:16:27 PDT] Dataset size is 196 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:16:27 PDT] Started with 196 files, current size is 196files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:16:27 PDT] Dataset size is 196 files
----------------------------------------------------
validating dataset ....passed
Writting process 58D472652BBDF007F3C809A020CC695B_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 58D472652BBDF007F3C809A020CC695B_1... done.
Writting process 58D472652BBDF007F3C809A020CC695B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched58D472652BBDF007F3C809A020CC695B.report
Scheduling successful
submit!!!
jobs = 97
day = 162 run = 15162047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162047/*.root.log: No such file or directory
31
31 31
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:17:34 PDT] Dataset size is 31 files
Removing files not on site LBL
[2017.09.05 23:17:34 PDT] Dataset size is 31 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:17:34 PDT] Dataset size is 31 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:17:34 PDT] Started with 31 files, current size is 31files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=31 ,maxSize=31 )
[2017.09.05 23:17:34 PDT] Dataset size is 31 files
----------------------------------------------------
validating dataset ....passed
Writting process 5D9077FD8A8C6E3A5224857B10A5321C_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5D9077FD8A8C6E3A5224857B10A5321C.report
Scheduling successful
submit!!!
jobs = 96
day = 162 run = 15162048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162048/*.root.log: No such file or directory
176
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:18:45 PDT] Dataset size is 176 files
Removing files not on site LBL
[2017.09.05 23:18:45 PDT] Dataset size is 176 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:18:45 PDT] Dataset size is 176 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:18:45 PDT] Started with 176 files, current size is 176files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:18:45 PDT] Dataset size is 176 files
----------------------------------------------------
validating dataset ....passed
Writting process ED71D4B3791AA4DC4C60AA05C6EC99D8_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ED71D4B3791AA4DC4C60AA05C6EC99D8_1... done.
Writting process ED71D4B3791AA4DC4C60AA05C6EC99D8_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedED71D4B3791AA4DC4C60AA05C6EC99D8.report
Scheduling successful
submit!!!
jobs = 93
day = 162 run = 15162049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162049/*.root.log: No such file or directory
172
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:19:57 PDT] Dataset size is 172 files
Removing files not on site LBL
[2017.09.05 23:19:57 PDT] Dataset size is 172 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:19:57 PDT] Dataset size is 172 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:19:57 PDT] Started with 172 files, current size is 172files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:19:57 PDT] Dataset size is 172 files
----------------------------------------------------
validating dataset ....passed
Writting process 17BB7C57C28466E8120D3E12CD54E8EB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 17BB7C57C28466E8120D3E12CD54E8EB_1... done.
Writting process 17BB7C57C28466E8120D3E12CD54E8EB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched17BB7C57C28466E8120D3E12CD54E8EB.report
Scheduling successful
submit!!!
jobs = 94
day = 162 run = 15162050
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162050/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162050/*.root.log: No such file or directory
156
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:21:08 PDT] Dataset size is 156 files
Removing files not on site LBL
[2017.09.05 23:21:08 PDT] Dataset size is 156 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:21:08 PDT] Dataset size is 156 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:21:08 PDT] Started with 156 files, current size is 156files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:21:08 PDT] Dataset size is 156 files
----------------------------------------------------
validating dataset ....passed
Writting process D5A2C8B4488C165C0204C50B9E7C6521_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D5A2C8B4488C165C0204C50B9E7C6521_1... done.
Writting process D5A2C8B4488C165C0204C50B9E7C6521_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD5A2C8B4488C165C0204C50B9E7C6521.report
Scheduling successful
submit!!!
jobs = 93
day = 162 run = 15162051
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162051/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162051/*.root.log: No such file or directory
109
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:22:17 PDT] Dataset size is 109 files
Removing files not on site LBL
[2017.09.05 23:22:17 PDT] Dataset size is 109 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:22:17 PDT] Dataset size is 109 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:22:18 PDT] Started with 109 files, current size is 109files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:22:18 PDT] Dataset size is 109 files
----------------------------------------------------
validating dataset ....passed
Writting process BE441216E8B2AF9A6BB8C0F81D4B3244_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BE441216E8B2AF9A6BB8C0F81D4B3244_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBE441216E8B2AF9A6BB8C0F81D4B3244.report
Scheduling successful
submit!!!
jobs = 93
day = 162 run = 15162053
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162053/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162053/*.root.log: No such file or directory
46
46 46
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:23:25 PDT] Dataset size is 46 files
Removing files not on site LBL
[2017.09.05 23:23:25 PDT] Dataset size is 46 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:23:25 PDT] Dataset size is 46 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:23:25 PDT] Started with 46 files, current size is 46files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=46 ,maxSize=46 )
[2017.09.05 23:23:25 PDT] Dataset size is 46 files
----------------------------------------------------
validating dataset ....passed
Writting process A5C5BB9B3F716B2175293D918F00A660_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA5C5BB9B3F716B2175293D918F00A660.report
Scheduling successful
submit!!!
jobs = 91
day = 162 run = 15162054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162054/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:24:37 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.05 23:24:37 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:24:37 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:24:37 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:24:37 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 9616606256DE6B32ED2EE5EEB0555AEA_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9616606256DE6B32ED2EE5EEB0555AEA_1... done.
Writting process 9616606256DE6B32ED2EE5EEB0555AEA_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9616606256DE6B32ED2EE5EEB0555AEA.report
Scheduling successful
submit!!!
jobs = 89
day = 162 run = 15162055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15162055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15162055/*.root.log: No such file or directory
153
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:25:47 PDT] Dataset size is 153 files
Removing files not on site LBL
[2017.09.05 23:25:47 PDT] Dataset size is 153 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:25:47 PDT] Dataset size is 153 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:25:47 PDT] Started with 153 files, current size is 153files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:25:48 PDT] Dataset size is 153 files
----------------------------------------------------
validating dataset ....passed
Writting process 987DD485D21C0D2A269DDF1F6B9AE062_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 987DD485D21C0D2A269DDF1F6B9AE062_1... done.
Writting process 987DD485D21C0D2A269DDF1F6B9AE062_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched987DD485D21C0D2A269DDF1F6B9AE062.report
Scheduling successful
submit!!!
Job submission for day 162 finished!
163
jobs = 92
day = 163 run = 15163001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163001/*.root.log: No such file or directory
177
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:26:59 PDT] Dataset size is 177 files
Removing files not on site LBL
[2017.09.05 23:26:59 PDT] Dataset size is 177 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:26:59 PDT] Dataset size is 177 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:26:59 PDT] Started with 177 files, current size is 177files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:26:59 PDT] Dataset size is 177 files
----------------------------------------------------
validating dataset ....passed
Writting process 083123127941F58FF3ED4ECB72AEC9C7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 083123127941F58FF3ED4ECB72AEC9C7_1... done.
Writting process 083123127941F58FF3ED4ECB72AEC9C7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched083123127941F58FF3ED4ECB72AEC9C7.report
Scheduling successful
submit!!!
jobs = 94
day = 163 run = 15163002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163002/*.root.log: No such file or directory
175
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:28:11 PDT] Dataset size is 175 files
Removing files not on site LBL
[2017.09.05 23:28:11 PDT] Dataset size is 175 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:28:11 PDT] Dataset size is 175 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:28:11 PDT] Started with 175 files, current size is 175files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:28:11 PDT] Dataset size is 175 files
----------------------------------------------------
validating dataset ....passed
Writting process C547EA6D9E844D50F218DCBA61B6BC72_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C547EA6D9E844D50F218DCBA61B6BC72_1... done.
Writting process C547EA6D9E844D50F218DCBA61B6BC72_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC547EA6D9E844D50F218DCBA61B6BC72.report
Scheduling successful
submit!!!
jobs = 97
day = 163 run = 15163003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163003/*.root.log: No such file or directory
85
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:29:20 PDT] Dataset size is 85 files
Removing files not on site LBL
[2017.09.05 23:29:20 PDT] Dataset size is 85 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:29:20 PDT] Dataset size is 85 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:29:20 PDT] Started with 85 files, current size is 85files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:29:20 PDT] Dataset size is 85 files
----------------------------------------------------
validating dataset ....passed
Writting process 06EC8803323644419E3AF75A47F6EE3F_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched06EC8803323644419E3AF75A47F6EE3F.report
Scheduling successful
submit!!!
jobs = 100
day = 163 run = 15163004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163004/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:30:32 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.05 23:30:32 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:30:32 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:30:33 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:30:33 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process C54C5DA1C705BBA5F84EFB555F7CEBAC_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C54C5DA1C705BBA5F84EFB555F7CEBAC_1... done.
Writting process C54C5DA1C705BBA5F84EFB555F7CEBAC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC54C5DA1C705BBA5F84EFB555F7CEBAC.report
Scheduling successful
submit!!!
jobs = 100
day = 163 run = 15163005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163005/*.root.log: No such file or directory
156
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:31:44 PDT] Dataset size is 156 files
Removing files not on site LBL
[2017.09.05 23:31:44 PDT] Dataset size is 156 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:31:44 PDT] Dataset size is 156 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:31:44 PDT] Started with 156 files, current size is 156files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:31:44 PDT] Dataset size is 156 files
----------------------------------------------------
validating dataset ....passed
Writting process BAFD338DDAC55D6708DEDA5A0A37D207_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BAFD338DDAC55D6708DEDA5A0A37D207_1... done.
Writting process BAFD338DDAC55D6708DEDA5A0A37D207_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBAFD338DDAC55D6708DEDA5A0A37D207.report
Scheduling successful
submit!!!
jobs = 104
day = 163 run = 15163006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163006/*.root.log: No such file or directory
200
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:32:56 PDT] Dataset size is 200 files
Removing files not on site LBL
[2017.09.05 23:32:56 PDT] Dataset size is 200 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:32:56 PDT] Dataset size is 200 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:32:56 PDT] Started with 200 files, current size is 200files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:32:56 PDT] Dataset size is 200 files
----------------------------------------------------
validating dataset ....passed
Writting process CA7F69E6629F146845800A33FFE0C44C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CA7F69E6629F146845800A33FFE0C44C_2... done.
Writting process CA7F69E6629F146845800A33FFE0C44C_1... done.
Writting process CA7F69E6629F146845800A33FFE0C44C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCA7F69E6629F146845800A33FFE0C44C.report
Scheduling successful
submit!!!
jobs = 108
day = 163 run = 15163007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163007/*.root.log: No such file or directory
201
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:34:08 PDT] Dataset size is 201 files
Removing files not on site LBL
[2017.09.05 23:34:09 PDT] Dataset size is 201 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:34:09 PDT] Dataset size is 201 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:34:09 PDT] Started with 201 files, current size is 201files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:34:09 PDT] Dataset size is 201 files
----------------------------------------------------
validating dataset ....passed
Writting process 893534B468B887251BED11D9BCDA8542_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 893534B468B887251BED11D9BCDA8542_2... done.
Writting process 893534B468B887251BED11D9BCDA8542_1... done.
Writting process 893534B468B887251BED11D9BCDA8542_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched893534B468B887251BED11D9BCDA8542.report
Scheduling successful
submit!!!
jobs = 112
day = 163 run = 15163008
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163008/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163008/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:35:20 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.05 23:35:20 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:35:20 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:35:21 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:35:21 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process 46504FFA524B45FA7DC41549B410D10D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 46504FFA524B45FA7DC41549B410D10D_1... done.
Writting process 46504FFA524B45FA7DC41549B410D10D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched46504FFA524B45FA7DC41549B410D10D.report
Scheduling successful
submit!!!
jobs = 115
day = 163 run = 15163009
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163009/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163009/*.root.log: No such file or directory
203
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:36:33 PDT] Dataset size is 203 files
Removing files not on site LBL
[2017.09.05 23:36:33 PDT] Dataset size is 203 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:36:33 PDT] Dataset size is 203 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:36:33 PDT] Started with 203 files, current size is 203files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:36:33 PDT] Dataset size is 203 files
----------------------------------------------------
validating dataset ....passed
Writting process 6BA844F8220D28331D19A0A9A2EF9152_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 6BA844F8220D28331D19A0A9A2EF9152_2... done.
Writting process 6BA844F8220D28331D19A0A9A2EF9152_1... done.
Writting process 6BA844F8220D28331D19A0A9A2EF9152_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6BA844F8220D28331D19A0A9A2EF9152.report
Scheduling successful
submit!!!
jobs = 117
day = 163 run = 15163010
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163010/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163010/*.root.log: No such file or directory
213
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:37:45 PDT] Dataset size is 213 files
Removing files not on site LBL
[2017.09.05 23:37:45 PDT] Dataset size is 213 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:37:46 PDT] Dataset size is 213 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:37:46 PDT] Started with 213 files, current size is 213files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:37:46 PDT] Dataset size is 213 files
----------------------------------------------------
validating dataset ....passed
Writting process E3987E33E7DEC1E55D5A00212291B00C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process E3987E33E7DEC1E55D5A00212291B00C_2... done.
Writting process E3987E33E7DEC1E55D5A00212291B00C_1... done.
Writting process E3987E33E7DEC1E55D5A00212291B00C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedE3987E33E7DEC1E55D5A00212291B00C.report
Scheduling successful
submit!!!
jobs = 122
day = 163 run = 15163022
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163022/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163022/*.root.log: No such file or directory
44
44 44
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:38:54 PDT] Dataset size is 44 files
Removing files not on site LBL
[2017.09.05 23:38:54 PDT] Dataset size is 44 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:38:54 PDT] Dataset size is 44 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:38:54 PDT] Started with 44 files, current size is 44files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=44 ,maxSize=44 )
[2017.09.05 23:38:54 PDT] Dataset size is 44 files
----------------------------------------------------
validating dataset ....passed
Writting process C594B75E7696D2DA82CF76772172F3CD_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC594B75E7696D2DA82CF76772172F3CD.report
Scheduling successful
submit!!!
jobs = 120
day = 163 run = 15163023
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163023/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163023/*.root.log: No such file or directory
157
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:40:05 PDT] Dataset size is 157 files
Removing files not on site LBL
[2017.09.05 23:40:05 PDT] Dataset size is 157 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:40:05 PDT] Dataset size is 157 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:40:05 PDT] Started with 157 files, current size is 157files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:40:05 PDT] Dataset size is 157 files
----------------------------------------------------
validating dataset ....passed
Writting process 2C177B9BDB79375EE6A701829428D8E6_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2C177B9BDB79375EE6A701829428D8E6_1... done.
Writting process 2C177B9BDB79375EE6A701829428D8E6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2C177B9BDB79375EE6A701829428D8E6.report
Scheduling successful
submit!!!
jobs = 122
day = 163 run = 15163024
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163024/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163024/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:41:17 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 23:41:17 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:41:17 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:41:17 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:41:17 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process B0C7543DB3DD9C524561403B05D8B3DE_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B0C7543DB3DD9C524561403B05D8B3DE_1... done.
Writting process B0C7543DB3DD9C524561403B05D8B3DE_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB0C7543DB3DD9C524561403B05D8B3DE.report
Scheduling successful
submit!!!
jobs = 124
day = 163 run = 15163025
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163025/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163025/*.root.log: No such file or directory
129
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:42:28 PDT] Dataset size is 129 files
Removing files not on site LBL
[2017.09.05 23:42:28 PDT] Dataset size is 129 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:42:28 PDT] Dataset size is 129 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:42:28 PDT] Started with 129 files, current size is 129files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:42:28 PDT] Dataset size is 129 files
----------------------------------------------------
validating dataset ....passed
Writting process ACEC2249126D206BCFEA6213CE98D07C_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process ACEC2249126D206BCFEA6213CE98D07C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedACEC2249126D206BCFEA6213CE98D07C.report
Scheduling successful
submit!!!
jobs = 126
day = 163 run = 15163026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163026/*.root.log: No such file or directory
151
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:43:38 PDT] Dataset size is 151 files
Removing files not on site LBL
[2017.09.05 23:43:39 PDT] Dataset size is 151 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:43:39 PDT] Dataset size is 151 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:43:39 PDT] Started with 151 files, current size is 151files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:43:39 PDT] Dataset size is 151 files
----------------------------------------------------
validating dataset ....passed
Writting process D499B6DFC02339B47AA97BCCB9CBFE32_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D499B6DFC02339B47AA97BCCB9CBFE32_1... done.
Writting process D499B6DFC02339B47AA97BCCB9CBFE32_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD499B6DFC02339B47AA97BCCB9CBFE32.report
Scheduling successful
submit!!!
jobs = 126
day = 163 run = 15163027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163027/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:44:50 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 23:44:50 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:44:50 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:44:51 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:44:51 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process 5DB4B71D68E3604967984E610D060DD1_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5DB4B71D68E3604967984E610D060DD1_1... done.
Writting process 5DB4B71D68E3604967984E610D060DD1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5DB4B71D68E3604967984E610D060DD1.report
Scheduling successful
submit!!!
jobs = 125
day = 163 run = 15163028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163028/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:46:02 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.05 23:46:02 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:46:02 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:46:03 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:46:03 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process A57E3F593EBECD158D64FA068B6CB5D7_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A57E3F593EBECD158D64FA068B6CB5D7_1... done.
Writting process A57E3F593EBECD158D64FA068B6CB5D7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA57E3F593EBECD158D64FA068B6CB5D7.report
Scheduling successful
submit!!!
jobs = 123
day = 163 run = 15163029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163029/*.root.log: No such file or directory
192
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:47:15 PDT] Dataset size is 192 files
Removing files not on site LBL
[2017.09.05 23:47:15 PDT] Dataset size is 192 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:47:15 PDT] Dataset size is 192 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:47:15 PDT] Started with 192 files, current size is 192files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:47:15 PDT] Dataset size is 192 files
----------------------------------------------------
validating dataset ....passed
Writting process 0A0397C94720A9DFDCA6E36DD4C44AF5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0A0397C94720A9DFDCA6E36DD4C44AF5_1... done.
Writting process 0A0397C94720A9DFDCA6E36DD4C44AF5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0A0397C94720A9DFDCA6E36DD4C44AF5.report
Scheduling successful
submit!!!
jobs = 129
day = 163 run = 15163033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163033/*.root.log: No such file or directory
57
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:48:23 PDT] Dataset size is 57 files
Removing files not on site LBL
[2017.09.05 23:48:23 PDT] Dataset size is 57 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:48:23 PDT] Dataset size is 57 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:48:24 PDT] Started with 57 files, current size is 57files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:48:24 PDT] Dataset size is 57 files
----------------------------------------------------
validating dataset ....passed
Writting process BD68D83C7AF0BB1FB2075A75AA0E274D_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBD68D83C7AF0BB1FB2075A75AA0E274D.report
Scheduling successful
submit!!!
jobs = 128
day = 163 run = 15163034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163034/*.root.log: No such file or directory
174
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:49:35 PDT] Dataset size is 174 files
Removing files not on site LBL
[2017.09.05 23:49:35 PDT] Dataset size is 174 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:49:35 PDT] Dataset size is 174 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:49:36 PDT] Started with 174 files, current size is 174files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:49:36 PDT] Dataset size is 174 files
----------------------------------------------------
validating dataset ....passed
Writting process 7BD8DBE6CB81FF7131AF7C71E4EBCE5A_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7BD8DBE6CB81FF7131AF7C71E4EBCE5A_1... done.
Writting process 7BD8DBE6CB81FF7131AF7C71E4EBCE5A_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7BD8DBE6CB81FF7131AF7C71E4EBCE5A.report
Scheduling successful
submit!!!
jobs = 131
day = 163 run = 15163035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163035/*.root.log: No such file or directory
141
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:50:46 PDT] Dataset size is 141 files
Removing files not on site LBL
[2017.09.05 23:50:46 PDT] Dataset size is 141 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:50:46 PDT] Dataset size is 141 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:50:46 PDT] Started with 141 files, current size is 141files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:50:46 PDT] Dataset size is 141 files
----------------------------------------------------
validating dataset ....passed
Writting process BFCFECBC02AC94818FCFA350E1ABA90B_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process BFCFECBC02AC94818FCFA350E1ABA90B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBFCFECBC02AC94818FCFA350E1ABA90B.report
Scheduling successful
submit!!!
jobs = 133
day = 163 run = 15163054
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163054/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163054/*.root.log: No such file or directory
33
33 33
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:51:53 PDT] Dataset size is 33 files
Removing files not on site LBL
[2017.09.05 23:51:53 PDT] Dataset size is 33 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:51:53 PDT] Dataset size is 33 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:51:54 PDT] Started with 33 files, current size is 33files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=33 ,maxSize=33 )
[2017.09.05 23:51:54 PDT] Dataset size is 33 files
----------------------------------------------------
validating dataset ....passed
Writting process F7CF665F4E89452E38FAA6752CA3D447_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF7CF665F4E89452E38FAA6752CA3D447.report
Scheduling successful
submit!!!
jobs = 130
day = 163 run = 15163055
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163055/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163055/*.root.log: No such file or directory
183
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:53:06 PDT] Dataset size is 183 files
Removing files not on site LBL
[2017.09.05 23:53:06 PDT] Dataset size is 183 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:53:06 PDT] Dataset size is 183 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:53:06 PDT] Started with 183 files, current size is 183files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:53:06 PDT] Dataset size is 183 files
----------------------------------------------------
validating dataset ....passed
Writting process 5BE16BFD81A908A4B6C67F15FAFAF47C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5BE16BFD81A908A4B6C67F15FAFAF47C_1... done.
Writting process 5BE16BFD81A908A4B6C67F15FAFAF47C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5BE16BFD81A908A4B6C67F15FAFAF47C.report
Scheduling successful
submit!!!
jobs = 130
day = 163 run = 15163056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163056/*.root.log: No such file or directory
208
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:54:18 PDT] Dataset size is 208 files
Removing files not on site LBL
[2017.09.05 23:54:18 PDT] Dataset size is 208 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:54:18 PDT] Dataset size is 208 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:54:18 PDT] Started with 208 files, current size is 208files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:54:18 PDT] Dataset size is 208 files
----------------------------------------------------
validating dataset ....passed
Writting process F192A16A73A67C84A9F9E45B756FD012_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F192A16A73A67C84A9F9E45B756FD012_2... done.
Writting process F192A16A73A67C84A9F9E45B756FD012_1... done.
Writting process F192A16A73A67C84A9F9E45B756FD012_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF192A16A73A67C84A9F9E45B756FD012.report
Scheduling successful
submit!!!
jobs = 128
day = 163 run = 15163057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163057/*.root.log: No such file or directory
180
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:55:30 PDT] Dataset size is 180 files
Removing files not on site LBL
[2017.09.05 23:55:30 PDT] Dataset size is 180 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:55:30 PDT] Dataset size is 180 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:55:30 PDT] Started with 180 files, current size is 180files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:55:30 PDT] Dataset size is 180 files
----------------------------------------------------
validating dataset ....passed
Writting process CE460636C289DEA3A8CFAB9227668C98_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CE460636C289DEA3A8CFAB9227668C98_1... done.
Writting process CE460636C289DEA3A8CFAB9227668C98_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCE460636C289DEA3A8CFAB9227668C98.report
Scheduling successful
submit!!!
jobs = 127
day = 163 run = 15163058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163058/*.root.log: No such file or directory
56
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:56:38 PDT] Dataset size is 56 files
Removing files not on site LBL
[2017.09.05 23:56:38 PDT] Dataset size is 56 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:56:38 PDT] Dataset size is 56 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:56:38 PDT] Started with 56 files, current size is 56files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:56:38 PDT] Dataset size is 56 files
----------------------------------------------------
validating dataset ....passed
Writting process 6D5CF3A2F0BD61BD3063CDF369BA12C8_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6D5CF3A2F0BD61BD3063CDF369BA12C8.report
Scheduling successful
submit!!!
jobs = 134
day = 163 run = 15163059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163059/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:57:51 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.05 23:57:51 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:57:51 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:57:51 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:57:51 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 2D95BF40B8E681149BC6AA613B88C314_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2D95BF40B8E681149BC6AA613B88C314_2... done.
Writting process 2D95BF40B8E681149BC6AA613B88C314_1... done.
Writting process 2D95BF40B8E681149BC6AA613B88C314_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2D95BF40B8E681149BC6AA613B88C314.report
Scheduling successful
submit!!!
jobs = 137
day = 163 run = 15163060
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163060/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163060/*.root.log: No such file or directory
223
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.05 23:59:04 PDT] Dataset size is 223 files
Removing files not on site LBL
[2017.09.05 23:59:04 PDT] Dataset size is 223 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.05 23:59:04 PDT] Dataset size is 223 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.05 23:59:04 PDT] Started with 223 files, current size is 223files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.05 23:59:04 PDT] Dataset size is 223 files
----------------------------------------------------
validating dataset ....passed
Writting process 25B31CDA115C5B30F2689C234243FA12_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 25B31CDA115C5B30F2689C234243FA12_2... done.
Writting process 25B31CDA115C5B30F2689C234243FA12_1... done.
Writting process 25B31CDA115C5B30F2689C234243FA12_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched25B31CDA115C5B30F2689C234243FA12.report
Scheduling successful
submit!!!
jobs = 140
day = 163 run = 15163061
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163061/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163061/*.root.log: No such file or directory
216
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:00:18 PDT] Dataset size is 216 files
Removing files not on site LBL
[2017.09.06 00:00:18 PDT] Dataset size is 216 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:00:18 PDT] Dataset size is 216 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:00:18 PDT] Started with 216 files, current size is 216files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:00:18 PDT] Dataset size is 216 files
----------------------------------------------------
validating dataset ....passed
Writting process 00C03580245B3824FADCE05513002A9D_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 00C03580245B3824FADCE05513002A9D_2... done.
Writting process 00C03580245B3824FADCE05513002A9D_1... done.
Writting process 00C03580245B3824FADCE05513002A9D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched00C03580245B3824FADCE05513002A9D.report
Scheduling successful
submit!!!
jobs = 138
day = 163 run = 15163062
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15163062/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15163062/*.root.log: No such file or directory
192
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:01:32 PDT] Dataset size is 192 files
Removing files not on site LBL
[2017.09.06 00:01:32 PDT] Dataset size is 192 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:01:32 PDT] Dataset size is 192 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:01:32 PDT] Started with 192 files, current size is 192files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:01:32 PDT] Dataset size is 192 files
----------------------------------------------------
validating dataset ....passed
Writting process 9922096EB800DD88F1DD4C3593D3F47C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9922096EB800DD88F1DD4C3593D3F47C_1... done.
Writting process 9922096EB800DD88F1DD4C3593D3F47C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9922096EB800DD88F1DD4C3593D3F47C.report
Scheduling successful
submit!!!
Job submission for day 163 finished!
164
jobs = 139
day = 164 run = 15164001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164001/*.root.log: No such file or directory
102
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:02:41 PDT] Dataset size is 102 files
Removing files not on site LBL
[2017.09.06 00:02:42 PDT] Dataset size is 102 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:02:42 PDT] Dataset size is 102 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:02:42 PDT] Started with 102 files, current size is 102files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:02:42 PDT] Dataset size is 102 files
----------------------------------------------------
validating dataset ....passed
Writting process 1FE6C935F5F385B8749D5B8268C145E3_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1FE6C935F5F385B8749D5B8268C145E3_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1FE6C935F5F385B8749D5B8268C145E3.report
Scheduling successful
submit!!!
jobs = 138
day = 164 run = 15164002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164002/*.root.log: No such file or directory
229
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:03:55 PDT] Dataset size is 229 files
Removing files not on site LBL
[2017.09.06 00:03:55 PDT] Dataset size is 229 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:03:55 PDT] Dataset size is 229 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:03:55 PDT] Started with 229 files, current size is 229files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:03:55 PDT] Dataset size is 229 files
----------------------------------------------------
validating dataset ....passed
Writting process 73CE98A08F7117E6B3BD50516FA956B0_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 73CE98A08F7117E6B3BD50516FA956B0_2... done.
Writting process 73CE98A08F7117E6B3BD50516FA956B0_1... done.
Writting process 73CE98A08F7117E6B3BD50516FA956B0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched73CE98A08F7117E6B3BD50516FA956B0.report
Scheduling successful
submit!!!
jobs = 139
day = 164 run = 15164003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164003/*.root.log: No such file or directory
204
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:05:08 PDT] Dataset size is 204 files
Removing files not on site LBL
[2017.09.06 00:05:08 PDT] Dataset size is 204 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:05:08 PDT] Dataset size is 204 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:05:09 PDT] Started with 204 files, current size is 204files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:05:09 PDT] Dataset size is 204 files
----------------------------------------------------
validating dataset ....passed
Writting process 7BD87DC906F628A3D7C7C294A9C387C6_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 7BD87DC906F628A3D7C7C294A9C387C6_2... done.
Writting process 7BD87DC906F628A3D7C7C294A9C387C6_1... done.
Writting process 7BD87DC906F628A3D7C7C294A9C387C6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched7BD87DC906F628A3D7C7C294A9C387C6.report
Scheduling successful
submit!!!
jobs = 142
day = 164 run = 15164033
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164033/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164033/*.root.log: No such file or directory
54
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:06:16 PDT] Dataset size is 54 files
Removing files not on site LBL
[2017.09.06 00:06:16 PDT] Dataset size is 54 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:06:16 PDT] Dataset size is 54 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:06:18 PDT] Started with 54 files, current size is 54files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:06:18 PDT] Dataset size is 54 files
----------------------------------------------------
validating dataset ....passed
Writting process 22337C34C2F0AEE0BE2DED35229093B7_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched22337C34C2F0AEE0BE2DED35229093B7.report
Scheduling successful
submit!!!
jobs = 142
day = 164 run = 15164036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164036/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:07:30 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.06 00:07:31 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:07:31 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:07:32 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:07:32 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process 718C549DB5949214A9BFA170CA72AA5D_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 718C549DB5949214A9BFA170CA72AA5D_1... done.
Writting process 718C549DB5949214A9BFA170CA72AA5D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched718C549DB5949214A9BFA170CA72AA5D.report
Scheduling successful
submit!!!
jobs = 142
day = 164 run = 15164037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164037/*.root.log: No such file or directory
194
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:08:44 PDT] Dataset size is 194 files
Removing files not on site LBL
[2017.09.06 00:08:44 PDT] Dataset size is 194 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:08:44 PDT] Dataset size is 194 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:08:44 PDT] Started with 194 files, current size is 194files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:08:44 PDT] Dataset size is 194 files
----------------------------------------------------
validating dataset ....passed
Writting process 1AB960D520CD9CC1E6086341193CC6F4_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1AB960D520CD9CC1E6086341193CC6F4_1... done.
Writting process 1AB960D520CD9CC1E6086341193CC6F4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1AB960D520CD9CC1E6086341193CC6F4.report
Scheduling successful
submit!!!
jobs = 140
day = 164 run = 15164039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164039/*.root.log: No such file or directory
197
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:09:57 PDT] Dataset size is 197 files
Removing files not on site LBL
[2017.09.06 00:09:57 PDT] Dataset size is 197 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:09:57 PDT] Dataset size is 197 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:09:57 PDT] Started with 197 files, current size is 197files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:09:57 PDT] Dataset size is 197 files
----------------------------------------------------
validating dataset ....passed
Writting process 8C6AE78FDB9AD9DB6F63A53ADA4FFF90_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8C6AE78FDB9AD9DB6F63A53ADA4FFF90_1... done.
Writting process 8C6AE78FDB9AD9DB6F63A53ADA4FFF90_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8C6AE78FDB9AD9DB6F63A53ADA4FFF90.report
Scheduling successful
submit!!!
jobs = 135
day = 164 run = 15164040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164040/*.root.log: No such file or directory
207
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:11:09 PDT] Dataset size is 207 files
Removing files not on site LBL
[2017.09.06 00:11:10 PDT] Dataset size is 207 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:11:10 PDT] Dataset size is 207 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:11:10 PDT] Started with 207 files, current size is 207files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:11:10 PDT] Dataset size is 207 files
----------------------------------------------------
validating dataset ....passed
Writting process 1835EF6A2DF6A6541D652E697D593BFC_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 1835EF6A2DF6A6541D652E697D593BFC_2... done.
Writting process 1835EF6A2DF6A6541D652E697D593BFC_1... done.
Writting process 1835EF6A2DF6A6541D652E697D593BFC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched1835EF6A2DF6A6541D652E697D593BFC.report
Scheduling successful
submit!!!
jobs = 138
day = 164 run = 15164041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164041/*.root.log: No such file or directory
213
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:12:22 PDT] Dataset size is 213 files
Removing files not on site LBL
[2017.09.06 00:12:22 PDT] Dataset size is 213 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:12:22 PDT] Dataset size is 213 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:12:23 PDT] Started with 213 files, current size is 213files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:12:23 PDT] Dataset size is 213 files
----------------------------------------------------
validating dataset ....passed
Writting process 76DBCAC4CBC2019ECE3E6F592B948CA4_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 76DBCAC4CBC2019ECE3E6F592B948CA4_2... done.
Writting process 76DBCAC4CBC2019ECE3E6F592B948CA4_1... done.
Writting process 76DBCAC4CBC2019ECE3E6F592B948CA4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched76DBCAC4CBC2019ECE3E6F592B948CA4.report
Scheduling successful
submit!!!
jobs = 135
day = 164 run = 15164042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164042/*.root.log: No such file or directory
227
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:13:36 PDT] Dataset size is 227 files
Removing files not on site LBL
[2017.09.06 00:13:36 PDT] Dataset size is 227 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:13:36 PDT] Dataset size is 227 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:13:36 PDT] Started with 227 files, current size is 227files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:13:36 PDT] Dataset size is 227 files
----------------------------------------------------
validating dataset ....passed
Writting process 771990BAB0772CEA7E23664A62F2F2B9_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 771990BAB0772CEA7E23664A62F2F2B9_2... done.
Writting process 771990BAB0772CEA7E23664A62F2F2B9_1... done.
Writting process 771990BAB0772CEA7E23664A62F2F2B9_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched771990BAB0772CEA7E23664A62F2F2B9.report
Scheduling successful
submit!!!
jobs = 141
day = 164 run = 15164043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164043/*.root.log: No such file or directory
213
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:14:49 PDT] Dataset size is 213 files
Removing files not on site LBL
[2017.09.06 00:14:49 PDT] Dataset size is 213 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:14:50 PDT] Dataset size is 213 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:14:50 PDT] Started with 213 files, current size is 213files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:14:50 PDT] Dataset size is 213 files
----------------------------------------------------
validating dataset ....passed
Writting process 4204C8B52A6A6135C8588303A042CC1B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4204C8B52A6A6135C8588303A042CC1B_2... done.
Writting process 4204C8B52A6A6135C8588303A042CC1B_1... done.
Writting process 4204C8B52A6A6135C8588303A042CC1B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4204C8B52A6A6135C8588303A042CC1B.report
Scheduling successful
submit!!!
jobs = 141
day = 164 run = 15164044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164044/*.root.log: No such file or directory
236
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:16:03 PDT] Dataset size is 236 files
Removing files not on site LBL
[2017.09.06 00:16:03 PDT] Dataset size is 236 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:16:03 PDT] Dataset size is 236 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:16:03 PDT] Started with 236 files, current size is 236files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:16:03 PDT] Dataset size is 236 files
----------------------------------------------------
validating dataset ....passed
Writting process D14E26AD5AC72D119E8BED0D1A80291C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D14E26AD5AC72D119E8BED0D1A80291C_2... done.
Writting process D14E26AD5AC72D119E8BED0D1A80291C_1... done.
Writting process D14E26AD5AC72D119E8BED0D1A80291C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD14E26AD5AC72D119E8BED0D1A80291C.report
Scheduling successful
submit!!!
jobs = 143
day = 164 run = 15164045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164045/*.root.log: No such file or directory
238
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:17:17 PDT] Dataset size is 238 files
Removing files not on site LBL
[2017.09.06 00:17:17 PDT] Dataset size is 238 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:17:17 PDT] Dataset size is 238 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:17:18 PDT] Started with 238 files, current size is 238files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:17:18 PDT] Dataset size is 238 files
----------------------------------------------------
validating dataset ....passed
Writting process 74F354479C24A7AEFD4DCFB28C57ECD2_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 74F354479C24A7AEFD4DCFB28C57ECD2_2... done.
Writting process 74F354479C24A7AEFD4DCFB28C57ECD2_1... done.
Writting process 74F354479C24A7AEFD4DCFB28C57ECD2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched74F354479C24A7AEFD4DCFB28C57ECD2.report
Scheduling successful
submit!!!
jobs = 145
day = 164 run = 15164046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164046/*.root.log: No such file or directory
54
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:18:26 PDT] Dataset size is 54 files
Removing files not on site LBL
[2017.09.06 00:18:26 PDT] Dataset size is 54 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:18:27 PDT] Dataset size is 54 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:18:27 PDT] Started with 54 files, current size is 54files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:18:27 PDT] Dataset size is 54 files
----------------------------------------------------
validating dataset ....passed
Writting process 258F9925E497EFCF8F68BC5D76224565_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched258F9925E497EFCF8F68BC5D76224565.report
Scheduling successful
submit!!!
jobs = 144
day = 164 run = 15164047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164047/*.root.log: No such file or directory
224
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:19:40 PDT] Dataset size is 224 files
Removing files not on site LBL
[2017.09.06 00:19:40 PDT] Dataset size is 224 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:19:40 PDT] Dataset size is 224 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:19:40 PDT] Started with 224 files, current size is 224files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:19:40 PDT] Dataset size is 224 files
----------------------------------------------------
validating dataset ....passed
Writting process DF2C990113C73F90E64BB352186BD18C_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process DF2C990113C73F90E64BB352186BD18C_2... done.
Writting process DF2C990113C73F90E64BB352186BD18C_1... done.
Writting process DF2C990113C73F90E64BB352186BD18C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDF2C990113C73F90E64BB352186BD18C.report
Scheduling successful
submit!!!
jobs = 143
day = 164 run = 15164048
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164048/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164048/*.root.log: No such file or directory
31
31 31
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:20:47 PDT] Dataset size is 31 files
Removing files not on site LBL
[2017.09.06 00:20:47 PDT] Dataset size is 31 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:20:47 PDT] Dataset size is 31 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:20:48 PDT] Started with 31 files, current size is 31files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=31 ,maxSize=31 )
[2017.09.06 00:20:48 PDT] Dataset size is 31 files
----------------------------------------------------
validating dataset ....passed
Writting process 5245B1551CF179BDA567C953FF393FEF_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5245B1551CF179BDA567C953FF393FEF.report
Scheduling successful
submit!!!
jobs = 138
day = 164 run = 15164049
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164049/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164049/*.root.log: No such file or directory
217
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:22:00 PDT] Dataset size is 217 files
Removing files not on site LBL
[2017.09.06 00:22:00 PDT] Dataset size is 217 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:22:00 PDT] Dataset size is 217 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:22:00 PDT] Started with 217 files, current size is 217files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:22:01 PDT] Dataset size is 217 files
----------------------------------------------------
validating dataset ....passed
Writting process CE8AC3928BF899C8850C30D72ECA23F7_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CE8AC3928BF899C8850C30D72ECA23F7_2... done.
Writting process CE8AC3928BF899C8850C30D72ECA23F7_1... done.
Writting process CE8AC3928BF899C8850C30D72ECA23F7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCE8AC3928BF899C8850C30D72ECA23F7.report
Scheduling successful
submit!!!
jobs = 138
day = 164 run = 15164067
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164067/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164067/*.root.log: No such file or directory
19
19 19
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:23:07 PDT] Dataset size is 19 files
Removing files not on site LBL
[2017.09.06 00:23:07 PDT] Dataset size is 19 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:23:07 PDT] Dataset size is 19 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:23:08 PDT] Started with 19 files, current size is 19files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=19 ,maxSize=19 )
[2017.09.06 00:23:08 PDT] Dataset size is 19 files
----------------------------------------------------
validating dataset ....passed
Writting process BC2DFE7F5EFDF0FC276C4413BE5023D1_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedBC2DFE7F5EFDF0FC276C4413BE5023D1.report
Scheduling successful
submit!!!
jobs = 137
day = 164 run = 15164068
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164068/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164068/*.root.log: No such file or directory
194
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:24:21 PDT] Dataset size is 194 files
Removing files not on site LBL
[2017.09.06 00:24:21 PDT] Dataset size is 194 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:24:21 PDT] Dataset size is 194 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:24:21 PDT] Started with 194 files, current size is 194files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:24:21 PDT] Dataset size is 194 files
----------------------------------------------------
validating dataset ....passed
Writting process A12B7749FB68ADC77C38E2E6C7867B17_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process A12B7749FB68ADC77C38E2E6C7867B17_1... done.
Writting process A12B7749FB68ADC77C38E2E6C7867B17_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedA12B7749FB68ADC77C38E2E6C7867B17.report
Scheduling successful
submit!!!
jobs = 133
day = 164 run = 15164069
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164069/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164069/*.root.log: No such file or directory
131
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:25:31 PDT] Dataset size is 131 files
Removing files not on site LBL
[2017.09.06 00:25:31 PDT] Dataset size is 131 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:25:31 PDT] Dataset size is 131 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:25:31 PDT] Started with 131 files, current size is 131files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:25:31 PDT] Dataset size is 131 files
----------------------------------------------------
validating dataset ....passed
Writting process 029022066684B0C10F83493AF1DBBD31_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 029022066684B0C10F83493AF1DBBD31_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched029022066684B0C10F83493AF1DBBD31.report
Scheduling successful
submit!!!
jobs = 129
day = 164 run = 15164070
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164070/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164070/*.root.log: No such file or directory
188
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:26:43 PDT] Dataset size is 188 files
Removing files not on site LBL
[2017.09.06 00:26:43 PDT] Dataset size is 188 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:26:43 PDT] Dataset size is 188 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:26:44 PDT] Started with 188 files, current size is 188files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:26:44 PDT] Dataset size is 188 files
----------------------------------------------------
validating dataset ....passed
Writting process D224074702C8E26AE15FC56962199DA2_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process D224074702C8E26AE15FC56962199DA2_1... done.
Writting process D224074702C8E26AE15FC56962199DA2_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD224074702C8E26AE15FC56962199DA2.report
Scheduling successful
submit!!!
jobs = 126
day = 164 run = 15164071
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15164071/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15164071/*.root.log: No such file or directory
193
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:27:55 PDT] Dataset size is 193 files
Removing files not on site LBL
[2017.09.06 00:27:56 PDT] Dataset size is 193 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:27:56 PDT] Dataset size is 193 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:27:56 PDT] Started with 193 files, current size is 193files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:27:56 PDT] Dataset size is 193 files
----------------------------------------------------
validating dataset ....passed
Writting process B1E8F1DDD6393AE5F8CC4064B3271136_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process B1E8F1DDD6393AE5F8CC4064B3271136_1... done.
Writting process B1E8F1DDD6393AE5F8CC4064B3271136_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedB1E8F1DDD6393AE5F8CC4064B3271136.report
Scheduling successful
submit!!!
Job submission for day 164 finished!
165
jobs = 124
day = 165 run = 15165001
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165001/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165001/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:29:09 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.06 00:29:09 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:29:09 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:29:09 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:29:09 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 67C70F17BA83BE74DED0AE1068FB5021_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 67C70F17BA83BE74DED0AE1068FB5021_2... done.
Writting process 67C70F17BA83BE74DED0AE1068FB5021_1... done.
Writting process 67C70F17BA83BE74DED0AE1068FB5021_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched67C70F17BA83BE74DED0AE1068FB5021.report
Scheduling successful
submit!!!
jobs = 123
day = 165 run = 15165002
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165002/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165002/*.root.log: No such file or directory
221
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:30:23 PDT] Dataset size is 221 files
Removing files not on site LBL
[2017.09.06 00:30:23 PDT] Dataset size is 221 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:30:23 PDT] Dataset size is 221 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:30:23 PDT] Started with 221 files, current size is 221files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:30:23 PDT] Dataset size is 221 files
----------------------------------------------------
validating dataset ....passed
Writting process 5403447CA2049EB483B1DC98F171A88E_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 5403447CA2049EB483B1DC98F171A88E_2... done.
Writting process 5403447CA2049EB483B1DC98F171A88E_1... done.
Writting process 5403447CA2049EB483B1DC98F171A88E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched5403447CA2049EB483B1DC98F171A88E.report
Scheduling successful
submit!!!
jobs = 118
day = 165 run = 15165003
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165003/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165003/*.root.log: No such file or directory
214
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:31:36 PDT] Dataset size is 214 files
Removing files not on site LBL
[2017.09.06 00:31:36 PDT] Dataset size is 214 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:31:36 PDT] Dataset size is 214 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:31:36 PDT] Started with 214 files, current size is 214files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:31:36 PDT] Dataset size is 214 files
----------------------------------------------------
validating dataset ....passed
Writting process F6E85977509EBD741E839E280C7231A0_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F6E85977509EBD741E839E280C7231A0_2... done.
Writting process F6E85977509EBD741E839E280C7231A0_1... done.
Writting process F6E85977509EBD741E839E280C7231A0_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF6E85977509EBD741E839E280C7231A0.report
Scheduling successful
submit!!!
jobs = 118
day = 165 run = 15165026
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165026/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165026/*.root.log: No such file or directory
207
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:32:48 PDT] Dataset size is 207 files
Removing files not on site LBL
[2017.09.06 00:32:48 PDT] Dataset size is 207 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:32:48 PDT] Dataset size is 207 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:32:49 PDT] Started with 207 files, current size is 207files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:32:49 PDT] Dataset size is 207 files
----------------------------------------------------
validating dataset ....passed
Writting process EA70ACDFD2F5F62105275137108BA3EC_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process EA70ACDFD2F5F62105275137108BA3EC_2... done.
Writting process EA70ACDFD2F5F62105275137108BA3EC_1... done.
Writting process EA70ACDFD2F5F62105275137108BA3EC_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedEA70ACDFD2F5F62105275137108BA3EC.report
Scheduling successful
submit!!!
jobs = 114
day = 165 run = 15165027
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165027/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165027/*.root.log: No such file or directory
206
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:34:01 PDT] Dataset size is 206 files
Removing files not on site LBL
[2017.09.06 00:34:01 PDT] Dataset size is 206 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:34:01 PDT] Dataset size is 206 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:34:01 PDT] Started with 206 files, current size is 206files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:34:02 PDT] Dataset size is 206 files
----------------------------------------------------
validating dataset ....passed
Writting process 9B7EA855C28798A79C5C91859F676AF4_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9B7EA855C28798A79C5C91859F676AF4_2... done.
Writting process 9B7EA855C28798A79C5C91859F676AF4_1... done.
Writting process 9B7EA855C28798A79C5C91859F676AF4_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9B7EA855C28798A79C5C91859F676AF4.report
Scheduling successful
submit!!!
jobs = 112
day = 165 run = 15165028
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165028/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165028/*.root.log: No such file or directory
186
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:35:13 PDT] Dataset size is 186 files
Removing files not on site LBL
[2017.09.06 00:35:13 PDT] Dataset size is 186 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:35:13 PDT] Dataset size is 186 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:35:13 PDT] Started with 186 files, current size is 186files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:35:13 PDT] Dataset size is 186 files
----------------------------------------------------
validating dataset ....passed
Writting process 97C8413E505DD059966A09E1C870AC67_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 97C8413E505DD059966A09E1C870AC67_1... done.
Writting process 97C8413E505DD059966A09E1C870AC67_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched97C8413E505DD059966A09E1C870AC67.report
Scheduling successful
submit!!!
jobs = 111
day = 165 run = 15165029
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165029/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165029/*.root.log: No such file or directory
202
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:36:26 PDT] Dataset size is 202 files
Removing files not on site LBL
[2017.09.06 00:36:26 PDT] Dataset size is 202 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:36:26 PDT] Dataset size is 202 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:36:26 PDT] Started with 202 files, current size is 202files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:36:26 PDT] Dataset size is 202 files
----------------------------------------------------
validating dataset ....passed
Writting process 2747B7A0C24E175C14BC36E222771A0D_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2747B7A0C24E175C14BC36E222771A0D_2... done.
Writting process 2747B7A0C24E175C14BC36E222771A0D_1... done.
Writting process 2747B7A0C24E175C14BC36E222771A0D_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2747B7A0C24E175C14BC36E222771A0D.report
Scheduling successful
submit!!!
jobs = 112
day = 165 run = 15165031
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165031/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165031/*.root.log: No such file or directory
113
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:37:36 PDT] Dataset size is 113 files
Removing files not on site LBL
[2017.09.06 00:37:36 PDT] Dataset size is 113 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:37:36 PDT] Dataset size is 113 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:37:36 PDT] Started with 113 files, current size is 113files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:37:36 PDT] Dataset size is 113 files
----------------------------------------------------
validating dataset ....passed
Writting process 13FA1DC6144B8135DA82082D7BD3EB17_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 13FA1DC6144B8135DA82082D7BD3EB17_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched13FA1DC6144B8135DA82082D7BD3EB17.report
Scheduling successful
submit!!!
jobs = 116
day = 165 run = 15165034
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165034/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165034/*.root.log: No such file or directory
171
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:38:47 PDT] Dataset size is 171 files
Removing files not on site LBL
[2017.09.06 00:38:47 PDT] Dataset size is 171 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:38:47 PDT] Dataset size is 171 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:38:47 PDT] Started with 171 files, current size is 171files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:38:47 PDT] Dataset size is 171 files
----------------------------------------------------
validating dataset ....passed
Writting process 2CF55F6F54FD5032DF8077190A635CFF_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2CF55F6F54FD5032DF8077190A635CFF_1... done.
Writting process 2CF55F6F54FD5032DF8077190A635CFF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2CF55F6F54FD5032DF8077190A635CFF.report
Scheduling successful
submit!!!
jobs = 133
day = 165 run = 15165035
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165035/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165035/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:40:00 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.06 00:40:00 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:40:00 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:40:00 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:40:00 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process 889277D5D081A565749BF00D20A276AD_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 889277D5D081A565749BF00D20A276AD_2... done.
Writting process 889277D5D081A565749BF00D20A276AD_1... done.
Writting process 889277D5D081A565749BF00D20A276AD_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched889277D5D081A565749BF00D20A276AD.report
Scheduling successful
submit!!!
jobs = 144
day = 165 run = 15165036
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165036/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165036/*.root.log: No such file or directory
201
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:41:13 PDT] Dataset size is 201 files
Removing files not on site LBL
[2017.09.06 00:41:13 PDT] Dataset size is 201 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:41:13 PDT] Dataset size is 201 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:41:13 PDT] Started with 201 files, current size is 201files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:41:13 PDT] Dataset size is 201 files
----------------------------------------------------
validating dataset ....passed
Writting process 4D3BFD58537CA35F5630A39BFE67D6B7_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4D3BFD58537CA35F5630A39BFE67D6B7_2... done.
Writting process 4D3BFD58537CA35F5630A39BFE67D6B7_1... done.
Writting process 4D3BFD58537CA35F5630A39BFE67D6B7_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4D3BFD58537CA35F5630A39BFE67D6B7.report
Scheduling successful
submit!!!
jobs = 147
day = 165 run = 15165037
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165037/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165037/*.root.log: No such file or directory
166
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:42:24 PDT] Dataset size is 166 files
Removing files not on site LBL
[2017.09.06 00:42:24 PDT] Dataset size is 166 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:42:24 PDT] Dataset size is 166 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:42:25 PDT] Started with 166 files, current size is 166files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:42:25 PDT] Dataset size is 166 files
----------------------------------------------------
validating dataset ....passed
Writting process 953278E4472B63409367972A51D909A5_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 953278E4472B63409367972A51D909A5_1... done.
Writting process 953278E4472B63409367972A51D909A5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched953278E4472B63409367972A51D909A5.report
Scheduling successful
submit!!!
jobs = 148
day = 165 run = 15165038
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165038/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165038/*.root.log: No such file or directory
245
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:43:38 PDT] Dataset size is 245 files
Removing files not on site LBL
[2017.09.06 00:43:38 PDT] Dataset size is 245 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:43:38 PDT] Dataset size is 245 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:43:39 PDT] Started with 245 files, current size is 245files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:43:39 PDT] Dataset size is 245 files
----------------------------------------------------
validating dataset ....passed
Writting process 00FD1F95DA839D6F0967B6B86DA6E5EF_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 00FD1F95DA839D6F0967B6B86DA6E5EF_2... done.
Writting process 00FD1F95DA839D6F0967B6B86DA6E5EF_1... done.
Writting process 00FD1F95DA839D6F0967B6B86DA6E5EF_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched00FD1F95DA839D6F0967B6B86DA6E5EF.report
Scheduling successful
submit!!!
jobs = 145
day = 165 run = 15165039
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165039/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165039/*.root.log: No such file or directory
36
36 36
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:44:46 PDT] Dataset size is 36 files
Removing files not on site LBL
[2017.09.06 00:44:46 PDT] Dataset size is 36 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:44:46 PDT] Dataset size is 36 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:44:46 PDT] Started with 36 files, current size is 36files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=36 ,maxSize=36 )
[2017.09.06 00:44:46 PDT] Dataset size is 36 files
----------------------------------------------------
validating dataset ....passed
Writting process 6903A159911BBFD75FBD436AA072BA49_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched6903A159911BBFD75FBD436AA072BA49.report
Scheduling successful
submit!!!
jobs = 144
day = 165 run = 15165040
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165040/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165040/*.root.log: No such file or directory
247
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:46:00 PDT] Dataset size is 247 files
Removing files not on site LBL
[2017.09.06 00:46:00 PDT] Dataset size is 247 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:46:00 PDT] Dataset size is 247 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:46:00 PDT] Started with 247 files, current size is 247files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:46:00 PDT] Dataset size is 247 files
----------------------------------------------------
validating dataset ....passed
Writting process 3443A70525D0239CFDE9999FBFF7AC96_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3443A70525D0239CFDE9999FBFF7AC96_2... done.
Writting process 3443A70525D0239CFDE9999FBFF7AC96_1... done.
Writting process 3443A70525D0239CFDE9999FBFF7AC96_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3443A70525D0239CFDE9999FBFF7AC96.report
Scheduling successful
submit!!!
jobs = 141
day = 165 run = 15165041
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165041/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165041/*.root.log: No such file or directory
220
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:47:13 PDT] Dataset size is 220 files
Removing files not on site LBL
[2017.09.06 00:47:13 PDT] Dataset size is 220 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:47:13 PDT] Dataset size is 220 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:47:13 PDT] Started with 220 files, current size is 220files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:47:13 PDT] Dataset size is 220 files
----------------------------------------------------
validating dataset ....passed
Writting process 0AF8A02E2F22E759CA6957B994B1EBA6_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 0AF8A02E2F22E759CA6957B994B1EBA6_2... done.
Writting process 0AF8A02E2F22E759CA6957B994B1EBA6_1... done.
Writting process 0AF8A02E2F22E759CA6957B994B1EBA6_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched0AF8A02E2F22E759CA6957B994B1EBA6.report
Scheduling successful
submit!!!
jobs = 134
day = 165 run = 15165042
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165042/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165042/*.root.log: No such file or directory
240
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:48:26 PDT] Dataset size is 240 files
Removing files not on site LBL
[2017.09.06 00:48:26 PDT] Dataset size is 240 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:48:26 PDT] Dataset size is 240 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:48:26 PDT] Started with 240 files, current size is 240files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:48:26 PDT] Dataset size is 240 files
----------------------------------------------------
validating dataset ....passed
Writting process C22BB26B1708838E206EB4C09C4C10EB_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C22BB26B1708838E206EB4C09C4C10EB_2... done.
Writting process C22BB26B1708838E206EB4C09C4C10EB_1... done.
Writting process C22BB26B1708838E206EB4C09C4C10EB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC22BB26B1708838E206EB4C09C4C10EB.report
Scheduling successful
submit!!!
jobs = 126
day = 165 run = 15165043
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165043/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165043/*.root.log: No such file or directory
258
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:49:41 PDT] Dataset size is 258 files
Removing files not on site LBL
[2017.09.06 00:49:41 PDT] Dataset size is 258 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:49:41 PDT] Dataset size is 258 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:49:42 PDT] Started with 258 files, current size is 258files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:49:42 PDT] Dataset size is 258 files
----------------------------------------------------
validating dataset ....passed
Writting process 235EC1E94CEC8E9445406F41682266D1_4.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 235EC1E94CEC8E9445406F41682266D1_3... done.
Writting process 235EC1E94CEC8E9445406F41682266D1_2... done.
Writting process 235EC1E94CEC8E9445406F41682266D1_1... done.
Writting process 235EC1E94CEC8E9445406F41682266D1_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched235EC1E94CEC8E9445406F41682266D1.report
Scheduling successful
submit!!!
jobs = 123
day = 165 run = 15165044
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165044/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165044/*.root.log: No such file or directory
135
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:50:53 PDT] Dataset size is 135 files
Removing files not on site LBL
[2017.09.06 00:50:53 PDT] Dataset size is 135 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:50:53 PDT] Dataset size is 135 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:50:53 PDT] Started with 135 files, current size is 135files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:50:53 PDT] Dataset size is 135 files
----------------------------------------------------
validating dataset ....passed
Writting process F521CE86922B5F88DB85BF0BAD25723C_1.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process F521CE86922B5F88DB85BF0BAD25723C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedF521CE86922B5F88DB85BF0BAD25723C.report
Scheduling successful
submit!!!
jobs = 137
day = 165 run = 15165045
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165045/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165045/*.root.log: No such file or directory
59
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:52:01 PDT] Dataset size is 59 files
Removing files not on site LBL
[2017.09.06 00:52:01 PDT] Dataset size is 59 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:52:01 PDT] Dataset size is 59 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:52:01 PDT] Started with 59 files, current size is 59files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:52:01 PDT] Dataset size is 59 files
----------------------------------------------------
validating dataset ....passed
Writting process D66F1326533328BE1648DFC0E6C452C2_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedD66F1326533328BE1648DFC0E6C452C2.report
Scheduling successful
submit!!!
jobs = 136
day = 165 run = 15165046
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165046/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165046/*.root.log: No such file or directory
205
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:53:14 PDT] Dataset size is 205 files
Removing files not on site LBL
[2017.09.06 00:53:14 PDT] Dataset size is 205 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:53:14 PDT] Dataset size is 205 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:53:14 PDT] Started with 205 files, current size is 205files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:53:14 PDT] Dataset size is 205 files
----------------------------------------------------
validating dataset ....passed
Writting process 2B494A1F4B0B37D40C2DCD00FBBEE37B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 2B494A1F4B0B37D40C2DCD00FBBEE37B_2... done.
Writting process 2B494A1F4B0B37D40C2DCD00FBBEE37B_1... done.
Writting process 2B494A1F4B0B37D40C2DCD00FBBEE37B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched2B494A1F4B0B37D40C2DCD00FBBEE37B.report
Scheduling successful
submit!!!
jobs = 140
day = 165 run = 15165047
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165047/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165047/*.root.log: No such file or directory
87
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:54:23 PDT] Dataset size is 87 files
Removing files not on site LBL
[2017.09.06 00:54:23 PDT] Dataset size is 87 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:54:23 PDT] Dataset size is 87 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:54:23 PDT] Started with 87 files, current size is 87files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:54:23 PDT] Dataset size is 87 files
----------------------------------------------------
validating dataset ....passed
Writting process AEB438825AE688E684534BAE75698332_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedAEB438825AE688E684534BAE75698332.report
Scheduling successful
submit!!!
jobs = 137
day = 165 run = 15165056
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165056/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165056/*.root.log: No such file or directory
31
31 31
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:55:30 PDT] Dataset size is 31 files
Removing files not on site LBL
[2017.09.06 00:55:30 PDT] Dataset size is 31 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:55:30 PDT] Dataset size is 31 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:55:31 PDT] Started with 31 files, current size is 31files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=31 ,maxSize=31 )
[2017.09.06 00:55:31 PDT] Dataset size is 31 files
----------------------------------------------------
validating dataset ....passed
Writting process DBE46B49A62C7C3B8AF8DA1F1D15F43F_0.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedDBE46B49A62C7C3B8AF8DA1F1D15F43F.report
Scheduling successful
submit!!!
jobs = 138
day = 165 run = 15165057
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165057/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165057/*.root.log: No such file or directory
170
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:56:42 PDT] Dataset size is 170 files
Removing files not on site LBL
[2017.09.06 00:56:42 PDT] Dataset size is 170 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:56:42 PDT] Dataset size is 170 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:56:42 PDT] Started with 170 files, current size is 170files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:56:42 PDT] Dataset size is 170 files
----------------------------------------------------
validating dataset ....passed
Writting process 9ABA33AA546555C7C30CC2765EAA9615_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 9ABA33AA546555C7C30CC2765EAA9615_1... done.
Writting process 9ABA33AA546555C7C30CC2765EAA9615_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched9ABA33AA546555C7C30CC2765EAA9615.report
Scheduling successful
submit!!!
jobs = 140
day = 165 run = 15165058
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165058/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165058/*.root.log: No such file or directory
189
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:57:54 PDT] Dataset size is 189 files
Removing files not on site LBL
[2017.09.06 00:57:54 PDT] Dataset size is 189 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:57:54 PDT] Dataset size is 189 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:57:54 PDT] Started with 189 files, current size is 189files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:57:54 PDT] Dataset size is 189 files
----------------------------------------------------
validating dataset ....passed
Writting process 8DE0383B031B290B0AA16C04703FA11C_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 8DE0383B031B290B0AA16C04703FA11C_1... done.
Writting process 8DE0383B031B290B0AA16C04703FA11C_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched8DE0383B031B290B0AA16C04703FA11C.report
Scheduling successful
submit!!!
jobs = 143
day = 165 run = 15165059
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15165059/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15165059/*.root.log: No such file or directory
185
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 00:59:06 PDT] Dataset size is 185 files
Removing files not on site LBL
[2017.09.06 00:59:06 PDT] Dataset size is 185 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 00:59:06 PDT] Dataset size is 185 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 00:59:06 PDT] Started with 185 files, current size is 185files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 00:59:06 PDT] Dataset size is 185 files
----------------------------------------------------
validating dataset ....passed
Writting process C5C2669AF7941C2B57E4B557A5C355FB_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process C5C2669AF7941C2B57E4B557A5C355FB_1... done.
Writting process C5C2669AF7941C2B57E4B557A5C355FB_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedC5C2669AF7941C2B57E4B557A5C355FB.report
Scheduling successful
submit!!!
Job submission for day 165 finished!
166
jobs = 145
day = 166 run = 15166004
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15166004/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15166004/*.root.log: No such file or directory
199
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 01:00:20 PDT] Dataset size is 199 files
Removing files not on site LBL
[2017.09.06 01:00:20 PDT] Dataset size is 199 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 01:00:20 PDT] Dataset size is 199 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 01:00:20 PDT] Started with 199 files, current size is 199files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 01:00:20 PDT] Dataset size is 199 files
----------------------------------------------------
validating dataset ....passed
Writting process CA1DA45698B31EDFE5F8292FC33FBE9E_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process CA1DA45698B31EDFE5F8292FC33FBE9E_1... done.
Writting process CA1DA45698B31EDFE5F8292FC33FBE9E_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/schedCA1DA45698B31EDFE5F8292FC33FBE9E.report
Scheduling successful
submit!!!
jobs = 146
day = 166 run = 15166005
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15166005/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15166005/*.root.log: No such file or directory
198
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 01:01:34 PDT] Dataset size is 198 files
Removing files not on site LBL
[2017.09.06 01:01:34 PDT] Dataset size is 198 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 01:01:34 PDT] Dataset size is 198 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 01:01:34 PDT] Started with 198 files, current size is 198files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 01:01:34 PDT] Dataset size is 198 files
----------------------------------------------------
validating dataset ....passed
Writting process 4A3F01A462DE95054F1C15C25DAD5853_2.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4A3F01A462DE95054F1C15C25DAD5853_1... done.
Writting process 4A3F01A462DE95054F1C15C25DAD5853_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4A3F01A462DE95054F1C15C25DAD5853.report
Scheduling successful
submit!!!
jobs = 147
day = 166 run = 15166006
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15166006/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15166006/*.root.log: No such file or directory
212
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 01:02:47 PDT] Dataset size is 212 files
Removing files not on site LBL
[2017.09.06 01:02:47 PDT] Dataset size is 212 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 01:02:47 PDT] Dataset size is 212 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 01:02:47 PDT] Started with 212 files, current size is 212files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 01:02:47 PDT] Dataset size is 212 files
----------------------------------------------------
validating dataset ....passed
Writting process 3F2301BB9ACE6AFF74938BAEB0B5EA6B_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 3F2301BB9ACE6AFF74938BAEB0B5EA6B_2... done.
Writting process 3F2301BB9ACE6AFF74938BAEB0B5EA6B_1... done.
Writting process 3F2301BB9ACE6AFF74938BAEB0B5EA6B_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched3F2301BB9ACE6AFF74938BAEB0B5EA6B.report
Scheduling successful
submit!!!
jobs = 147
day = 166 run = 15166007
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/out/out_mb/15166007/*.anaTree.root: No such file or directory
ls: cannot access /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/log/log_mb/15166007/*.root.log: No such file or directory
226
50 100
STAR Template Scheduler 0.1 (/common/star/star64/packages/scripts/star-submit)

STAR Unified Meta Scheduler 1.10.24
Your Log file can be found at: /project/projectdirs/star/star_sched/xiao00.log
Reading request description file : schedTemplateExp.xml
Analyzing XML...XML OK
[2017.09.06 01:04:00 PDT] Dataset size is 226 files
Removing files not on site LBL
[2017.09.06 01:04:00 PDT] Dataset size is 226 files
-------Processing recovered dataset for paths-------
Removing HPSS files as not accessible in syntax=paths
[2017.09.06 01:04:00 PDT] Dataset size is 226 files
Skipping (Removing RCRS node files) no such files
Dropping files with duplicate LFN (files that are the same)
[2017.09.06 01:04:01 PDT] Started with 226 files, current size is 226files, 0 duplicate files dropped.
Skipping (Sorting by node) all NFS files
Skipping (Splitting by node) all NFS files
Splitting dataset entries by size (minSize=50 ,maxSize=100 )
[2017.09.06 01:04:01 PDT] Dataset size is 226 files
----------------------------------------------------
validating dataset ....passed
Writting process 4BBAFE45D29ADCC14C38B18C795EBFF5_3.

Warning : The zip Sandbox package LocalPackage.zip already exist in this directory, it will not be recreated. If you have made changes to the files you are sandboxing please delete LocalPackage.zip and resubmit the request else the existing package will be used.

.. done.
Writting process 4BBAFE45D29ADCC14C38B18C795EBFF5_2... done.
Writting process 4BBAFE45D29ADCC14C38B18C795EBFF5_1... done.
Writting process 4BBAFE45D29ADCC14C38B18C795EBFF5_0... done.
Submitting array.. done.
Wrote scheduling report to : /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/submit/mb/sched4BBAFE45D29ADCC14C38B18C795EBFF5.report
Scheduling successful
submit!!!
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166007.lis: No such file or directory
cp: cannot create regular file `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_submitted_15166007.lis': No such file or directory
./submitAnaTreePDSF.sh: line 100: cd: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job: No such file or directory
jobs = 148
day = 166 run = 15166008
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166008.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166008.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166008.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166008.lis: No such file or directory
0
no input filelist for run 15166008, skip...
jobs = 148
day = 166 run = 15166009
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166009.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166009.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166009.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166009.lis: No such file or directory
0
no input filelist for run 15166009, skip...
jobs = 148
day = 166 run = 15166010
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166010.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166010.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166010.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166010.lis: No such file or directory
0
no input filelist for run 15166010, skip...
jobs = 148
day = 166 run = 15166014
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166014.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166014.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166014.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166014.lis: No such file or directory
0
no input filelist for run 15166014, skip...
jobs = 148
day = 166 run = 15166015
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166015.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166015.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166015.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166015.lis: No such file or directory
0
no input filelist for run 15166015, skip...
jobs = 148
day = 166 run = 15166016
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166016.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166016.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166016.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166016.lis: No such file or directory
0
no input filelist for run 15166016, skip...
jobs = 148
day = 166 run = 15166017
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166017.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166017.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166017.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166017.lis: No such file or directory
0
no input filelist for run 15166017, skip...
jobs = 148
day = 166 run = 15166029
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166029.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166029.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166029.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166029.lis: No such file or directory
0
no input filelist for run 15166029, skip...
jobs = 148
day = 166 run = 15166030
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166030.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166030.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166030.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166030.lis: No such file or directory
0
no input filelist for run 15166030, skip...
jobs = 148
day = 166 run = 15166031
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166031.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166031.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166031.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166031.lis: No such file or directory
0
no input filelist for run 15166031, skip...
jobs = 148
day = 166 run = 15166032
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166032.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166032.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166032.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166032.lis: No such file or directory
0
no input filelist for run 15166032, skip...
jobs = 148
day = 166 run = 15166033
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166033.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166033.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166033.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166033.lis: No such file or directory
0
no input filelist for run 15166033, skip...
jobs = 148
day = 166 run = 15166034
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166034.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166034.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166034.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166034.lis: No such file or directory
0
no input filelist for run 15166034, skip...
jobs = 148
day = 166 run = 15166035
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166035.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166035.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166035.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166035.lis: No such file or directory
0
no input filelist for run 15166035, skip...
jobs = 148
day = 166 run = 15166036
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166036.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166036.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166036.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166036.lis: No such file or directory
0
no input filelist for run 15166036, skip...
jobs = 148
day = 166 run = 15166037
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166037.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166037.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166037.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166037.lis: No such file or directory
0
no input filelist for run 15166037, skip...
jobs = 148
day = 166 run = 15166038
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166038.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166038.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166038.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166038.lis: No such file or directory
0
no input filelist for run 15166038, skip...
jobs = 148
day = 166 run = 15166039
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166039.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166039.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166039.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166039.lis: No such file or directory
0
no input filelist for run 15166039, skip...
jobs = 148
day = 166 run = 15166040
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166040.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166040.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166040.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166040.lis: No such file or directory
0
no input filelist for run 15166040, skip...
jobs = 148
day = 166 run = 15166041
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166041.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166041.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166041.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166041.lis: No such file or directory
0
no input filelist for run 15166041, skip...
jobs = 148
day = 166 run = 15166042
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166042.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166042.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166042.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166042.lis: No such file or directory
0
no input filelist for run 15166042, skip...
jobs = 148
day = 166 run = 15166043
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166043.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166043.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166043.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166043.lis: No such file or directory
0
no input filelist for run 15166043, skip...
jobs = 148
day = 166 run = 15166044
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166044.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166044.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166044.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166044.lis: No such file or directory
0
no input filelist for run 15166044, skip...
jobs = 148
day = 166 run = 15166045
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166045.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166045.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166045.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166045.lis: No such file or directory
0
no input filelist for run 15166045, skip...
jobs = 148
day = 166 run = 15166046
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166046.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166046.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166046.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166046.lis: No such file or directory
0
no input filelist for run 15166046, skip...
jobs = 148
day = 166 run = 15166047
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 129: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_PicoDst_15166047.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 135: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_anaTree_15166047.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 141: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_log_15166047.lis: No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
cp: cannot stat `/global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/blank': No such file or directory
./submitAnaTreePDSF.sh: line 158: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/diffPicoDstAnaTreeByRun.sh: No such file or directory
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/fileList/mb/run_tobeSubmitted_15166047.lis: No such file or directory
0
no input filelist for run 15166047, skip...
Job submission for day 166 finished!
167
cat: /global/homes/x/xiao00/pwg_disk/AuAu14/PicoReader/Submit_Job/List/day167.lis: No such file or directory
Job submission for day 167 finished!
